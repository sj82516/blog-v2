<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>資料庫 on Yuanchieh</title><link>https://yuanchieh.page/categories/%E8%B3%87%E6%96%99%E5%BA%AB/</link><description>Recent content in 資料庫 on Yuanchieh</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 05 May 2023 00:21:40 +0000</lastBuildDate><atom:link href="https://yuanchieh.page/categories/%E8%B3%87%E6%96%99%E5%BA%AB/index.xml" rel="self" type="application/rss+xml"/><item><title>MongoDB Clustered Collection 與 Benchmark 實驗</title><link>https://yuanchieh.page/posts/2023/2023-05-05-mongodb-clustered-collection-%E8%88%87-benchmark-%E5%AF%A6%E9%A9%97/</link><pubDate>Fri, 05 May 2023 00:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2023/2023-05-05-mongodb-clustered-collection-%E8%88%87-benchmark-%E5%AF%A6%E9%A9%97/</guid><description>&lt;p>最近看到一篇很不錯的文章&lt;a class="link" href="https://medium.com/@hnasr/mongodb-internal-architecture-9a32f1403d6f" target="_blank" rel="noopener"
>MongoDB internal Architecture&lt;/a>，主要在描述 MongoDB Storage Engine 的演進&lt;/p>
&lt;p>其中在 5.3 比較大的改變是引入了 &lt;code>Clustered Collection&lt;/code> 調整了 Storage Engine 儲存的機制，這也連帶影響 MongoDB 在 Collection 上的效能表現，以下從文章中摘要 Storage Engine 演進，並透過 Benchmark 去驗證看看實際的表現&lt;/p>
&lt;h2 id="mongodb-storage-engine-演進">MongoDB Storage Engine 演進&lt;/h2>
&lt;h3 id="mmapv1">MMAPv1&lt;/h3>
&lt;p>最一開始 MongoDB 的 Storage Engine 是 MMAPv1，採用 B+Tree 架構以 &lt;code>_id&lt;/code> 為 primary key，leaf node 儲存 &lt;code>DiskLoc&lt;/code> 直接指向儲存於硬碟上的位置(透過 file name + offset)
&lt;img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M_5Io7l_SDSP_HSeH1iYaQ.png"
loading="lazy"
>&lt;/p>
&lt;p>MMAPv1 的優點是查詢速度很快，只需要 O(logN) 在 B+Tree 找到 leaf node + O(1) 去硬碟讀取資料即可&lt;/p>
&lt;p>但有幾個重大缺點&lt;/p>
&lt;ol>
&lt;li>因為是儲存實際 Disk 位置，所以當 &lt;code>document 因為 insert / update / delete 而改變 Disk 位置&lt;/code> 時，就需要大規模的改寫 DiskLoc 造成效能的影響&lt;/li>
&lt;li>儲存時沒有壓縮&lt;/li>
&lt;li>一開始只提供 database level / collection level 的 lock，這也導致在 parallel 執行上效率不高&lt;/li>
&lt;/ol>
&lt;p>最終在 &lt;a class="link" href="https://www.mongodb.com/docs/v6.0/release-notes/4.2-compatibility/" target="_blank" rel="noopener"
>MongoDB v4.2 就全面移除了&lt;/a>&lt;/p>
&lt;h3 id="wiredtiger">WiredTiger&lt;/h3>
&lt;p>MongoDB 在 2014 年收購了 &lt;a class="link" href="https://source.wiredtiger.com/11.0.0/index.html" target="_blank" rel="noopener"
>WiredTiger&lt;/a> 這個 Storage Engine，並於 3.0 加入於 3.2 變成預設的 Storage Engine&lt;/p>
&lt;p>在儲存上同樣是採用 B+Tree 結構，但這時候 &lt;code>_id&lt;/code> 不是 Clustered Index Key 而是在內部 &lt;code>WiredTiger 會自動為每個 document 設定 recordId 當作儲存排序的依據&lt;/code>&lt;/p>
&lt;p>所以 &lt;code>_id&lt;/code> 跟其他 secondary index 相同，都是先在自己的 B+Tree 上查找，找到對應的 recordId 後再去 &lt;code>recordId Clustered Index&lt;/code> 搜尋&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*urhOmzoY-JvXggjwRm9V-w.png"
loading="lazy"
>&lt;/p>
&lt;p>也因此 WiredTiger 的缺點是查詢變慢一些，因為需要搜尋兩次 B+Tree 才能去 Disk 撈資料&lt;/p>
&lt;p>但有幾項優點&lt;/p>
&lt;ol>
&lt;li>Insert、Update、Delete 效能比 MMAPv1 穩定&lt;/li>
&lt;li>提供 document level lock，大幅改善 parallel 效能&lt;/li>
&lt;li>壓縮 BSON 在儲存，減少 Disk 用量代表可放進 buffer pool 的資料筆數也增加&lt;/li>
&lt;/ol>
&lt;p>根據這篇文章 &lt;a class="link" href="http://smalldatum.blogspot.com/2015/07/linkbench-for-mysql-mongodb-with-cached.html" target="_blank" rel="noopener"
>Linkbench for MySQL &amp;amp; MongoDB with a cached database&lt;/a> 的實驗可以看到 MongoDB WiredTiger 在查詢與寫入都吊打其他的 Storage Engine
&lt;img src="http://3.bp.blogspot.com/-Hrkm07TpHYY/VZqVFtZrgaI/AAAAAAAABm4/LQEN2-HfQDw/s1600/image%2B%25288%2529.png"
loading="lazy"
>&lt;/p>
&lt;p>有趣的是 MySQL 寫入、查詢吊打 MongoDB XD&lt;br>
在單機的環境下看起來老牌 RDBMS 比較厲害，只是實際選擇還需要再考量到 scalability 等狀況&lt;/p>
&lt;h3 id="wiredtiger-clustered-collection-原理">WiredTiger Clustered Collection 原理&lt;/h3>
&lt;p>接著到了 MongoDB 5.3 的 Clustered Collection，剛剛有提到實際內部儲存依據是用 &lt;code>recordId&lt;/code> 排序，那如果直接拿 &lt;code>_id 當作 Clustered Index 的 key&lt;/code> 是不是就能更加速寫入跟查詢的效率？這正是 Clustered Collection 所採用的方式，直接拿 _id 當作 Clustered Index&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zOQO6cVCj9PJ-HOWP6zmfw.png"
loading="lazy"
>&lt;/p>
&lt;p>根據官方文件，在建立 Clustered Collection 就必須指定用 _id 建立，同時必須是 unique&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-ruby" data-lang="ruby">&lt;span class="line">&lt;span class="cl">&lt;span class="n">client&lt;/span>&lt;span class="o">[&lt;/span>&lt;span class="s2">&amp;#34;collection&amp;#34;&lt;/span>&lt;span class="o">].&lt;/span>&lt;span class="n">create&lt;/span>&lt;span class="p">({&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="ss">:clustered_index&lt;/span> &lt;span class="o">=&amp;gt;&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="ss">:key&lt;/span> &lt;span class="o">=&amp;gt;&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="ss">:_id&lt;/span> &lt;span class="o">=&amp;gt;&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="ss">:unique&lt;/span> &lt;span class="o">=&amp;gt;&lt;/span> &lt;span class="kp">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">})&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>根據&lt;a class="link" href="https://www.mongodb.com/docs/upcoming/core/clustered-collections/" target="_blank" rel="noopener"
>文件 Clustered Collections&lt;/a>所述有幾個優點&lt;/p>
&lt;ol>
&lt;li>大幅度增加 _id 搜尋速度，尤其是 range scan 上，因為少了一次去查找 recordId index&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>Faster queries on clustered collections without needing a secondary index, such as queries with range scans and equality comparisons on the clustered index key.&lt;/p>
&lt;/blockquote>
&lt;ol start="2">
&lt;li>增加 CRUD 的效能&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>Clustered collections have additional performance improvements for inserts, updates, deletes, and queries.&lt;/p>
&lt;/blockquote>
&lt;p>但也不是全然沒有壞處&lt;/p>
&lt;ol>
&lt;li>Secondary Index leaf node 會儲存 Clustered Index 的 key，而因為前面提到原本 collection Clustered Index 是用 recordId(8byte)，而 _id 預設是 12byte，所以就直接影響了 Secondary Index 的 size (增加約 20%)&lt;/li>
&lt;li>&lt;code>_id 是用戶可以預設，如果設錯可能會讓效能變差&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>整體來說目前 MongoDB Clustered Collection 儲存方式有點接近 MySQL，同樣都是&lt;/p>
&lt;ol>
&lt;li>指定 Primary Key 當作 Clustered Index 影響實際儲存的方式&lt;/li>
&lt;li>Secondary Index leaf node 指向 Clsutered Index&lt;/li>
&lt;/ol>
&lt;p>同樣的如果 _id 是採用 UUID 等亂序，也同樣會有效能上的影響，這部分可以參考 &lt;a class="link" href="https://www.percona.com/blog/uuids-are-popular-but-bad-for-performance-lets-discuss/" target="_blank" rel="noopener"
>UUIDs are Popular, but Bad for Performance — Let’s Discuss&lt;/a>，這點後續 benchmark 會驗證&lt;/p>
&lt;h2 id="benchmark">Benchmark&lt;/h2>
&lt;p>透過以下幾個實驗來實際檢驗一下 MongoDB v6.0.5 Clustered Collection 的效能&lt;/p>
&lt;ol>
&lt;li>比對 CRUD 在 Clustered Collection vs 一般 Collection 差異&lt;br>
預期 CRUD 在 Clustered Collection 應該要較好&lt;/li>
&lt;li>針對 Secondary Index，比較實際大小與效能&lt;br>
預期 Secondary Index 在 Clustered Collection 儲存空間要比較大，如果尺寸沒有大到記憶體塞不下的狀況，效能部分預期是差不多&lt;/li>
&lt;li>_id 改用 UUID 對於寫入效能的影響&lt;br>
預期 Clustered Collection 會有比較差的表現，因為底層儲存結構的關係&lt;/li>
&lt;/ol>
&lt;p>相關程式碼在 &lt;a class="link" href="https://github.com/sj82516/mongodb-bm-cluster-collection" target="_blank" rel="noopener"
>sj82516/mongodb-bm-cluster-collection&lt;/a>&lt;/p>
&lt;h3 id="insert-比較">Insert 比較&lt;/h3>
&lt;p>&lt;img src="https://yuanchieh.page/post/2023/img/0505/insert.png"
loading="lazy"
>&lt;/p>
&lt;p>實驗每個 iteration 準備 100 萬筆資料並用 insert_many 批次寫入 1000 筆，總共插入 2000 萬筆；實驗組是 clustered collection 但對照組不是&lt;/p>
&lt;p>從圖表來看 Clustered Collection 有稍微比較好但沒有到非常明顯的變化&lt;/p>
&lt;h3 id="search-比較">Search 比較&lt;/h3>
&lt;p>測試過程有發現一個 MongoDB 的 bug &lt;a class="link" href="https://jira.mongodb.org/browse/SERVER-76905" target="_blank" rel="noopener"
>Performance Issue about Clustered Collection : where there are more than one _id search condition, the search would fallback to COLLSCAN&lt;/a>，主要是 find 條件中有多個 _id 時 index 會沒有吃到 clustered index 導致查詢非常慢&lt;/p>
&lt;p>但有趣的是 secondary index 目前測試是沒有這個問題的&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> user system total real
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">cluster search 1.011011 0.095830 1.106841 ( 27.275139)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">normal search 0.405232 0.034662 0.439894 ( 0.449653)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> user system total real
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">cluster email search 0.417697 0.035939 0.453636 ( 0.556692)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">normal email search 0.407986 0.027175 0.435161 ( 0.487835)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>可以看到 cluster search 慢到爆，delete_many 有同樣的 issue&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/2023/img/0505/index_issue.png"
loading="lazy"
>
本來以為是不是 driver 問題，但實際用 Mongo Compass 官方 GUI tool 去分析查詢，確實發現只要 $in 裡面的條件超過一筆就會變成 COLLSCAN&lt;/p>
&lt;h3 id="secondary-index-大小">Secondary Index 大小&lt;/h3>
&lt;p>&lt;img src="https://yuanchieh.page/post/2023/img/0505/sec.png"
loading="lazy"
>&lt;/p>
&lt;p>可以看出同樣的 documents 下 Secondary Index 在 Clustered Index 確實變大快 25%&lt;/p>
&lt;h3 id="uuid-寫入的影響">UUID 寫入的影響&lt;/h3>
&lt;p>&lt;img src="https://yuanchieh.page/post/2023/img/0505/uuid.png"
loading="lazy"
>&lt;br>
實驗每個 iteration 準備 100 萬筆資料並用 insert_many 批次寫入 1000 筆，兩個 collection 都是 clustered collection，實驗組 _id 設定為 UUID&lt;/p>
&lt;p>可以看到 UUID 對於效能的負面影響十分巨大&lt;/p>
&lt;h2 id="延伸閱讀">延伸閱讀&lt;/h2>
&lt;p>以下是我在閱讀時想到的一些額外問題，覺得蠻有趣也順便記錄一下&lt;/p>
&lt;h3 id="為什麼-wiredtiger-一開始不支援-clustered-index">為什麼 WiredTiger 一開始不支援 Clustered Index&lt;/h3>
&lt;p>既然有這麼大的好處，為什麼一開始不支援呢？在這個 google group discuss 有稍微帶到 &lt;a class="link" href="https://groups.google.com/g/mongodb-dev/c/8dhOvNx9mBY" target="_blank" rel="noopener"
>Purpose of a separate index storage for primary id for MongoDB&lt;/a>&lt;/p>
&lt;p>理解起來比較像技術債，一開始 MMAPv1 是使用 DiscLoc，後來 WiredTiger 改成用 RecordId 而不是直接綁死 Disk 位置&lt;/p>
&lt;blockquote>
&lt;p>the origin of this decision was the MMAPv1 storage engine. There, indexes would map keys to &lt;code>'DiskLoc' values, containing a pair of 32-bit integers representing the file number in the database and offset in that file.&lt;/code> Since then we have replaced DiskLoc by a RecordId that does not represent a physical location, but rather a logical document number.&lt;/p>
&lt;/blockquote>
&lt;p>另外就是 MongoDB 對於 Primary Key 使用有額外的用途，包含 Sharding，所以實作比想像中複雜
另外也有提到即使有效能上的提升但對於 Secondary Index 是有負面影響&lt;/p>
&lt;blockquote>
&lt;p>we could gain efficiency (both time and space) by using the primary key directly to index the data. However, as MongoDB puts few restrictions on the primary key, it is common for these primary keys to have a non-trivial size. &lt;code>This in turn means that all secondary indexes become less efficient. Some users have many indexes, so they'd be negatively affected by such a change.&lt;/code> &amp;hellip;&amp;hellip;&lt;/p>
&lt;/blockquote>
&lt;h2 id="結語">結語&lt;/h2>
&lt;p>整體來說 Clustered Collection 寫入效能確實有好上一些，搜尋部分因為有 bug 暫時還不確定，而 Secondary Index 體積會有感的變大；目前整題評估下來不建議採用 Clustered Collection，些微的效益比不上這些風險與副作用&lt;/p></description></item><item><title>【MySQL】Lock 與 Index 關係和 Deadlock 分析</title><link>https://yuanchieh.page/posts/2022/2022-04-25-mysqllock-%E8%88%87-index-%E9%97%9C%E4%BF%82%E5%92%8C-deadlock-%E5%88%86%E6%9E%90/</link><pubDate>Mon, 25 Apr 2022 01:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2022/2022-04-25-mysqllock-%E8%88%87-index-%E9%97%9C%E4%BF%82%E5%92%8C-deadlock-%E5%88%86%E6%9E%90/</guid><description>&lt;p>關於 MySQL Lock 來來回回寫了也有幾篇，每次看都有不同的發現，這次為了準備公司內部分享，重新再翻閱一次又找到一些新的有趣發現，以下將盡可能完整的解析 MySQL Lock 與 Index 的關係，怎樣的查詢會拿到怎樣的鎖，以及怎樣的查詢又可能互相 Deadlock&lt;/p>
&lt;p>文章主要受啟發於 &lt;a class="link" href="https://www.aneasystone.com/archives/2018/04/solving-dead-locks-four.html" target="_blank" rel="noopener"
>解决死锁之路（终结篇） - 再见死锁&lt;/a>，對應的實驗可以看程式碼 &lt;a class="link" href="https://github.com/sj82516/mysql-deadlock-test" target="_blank" rel="noopener"
>sj82516/mysql-deadlock-test&lt;/a>，先說結論，&lt;code>在 DML (更新、刪除、插入)的操作中，Lock 會與套用的 Index 有關&lt;/code>，在 MySQL 中 Index 有幾種&lt;/p>
&lt;ol>
&lt;li>Clustered Index:&lt;br>
通常是 Primary Key&lt;/li>
&lt;li>Unique Secondary Index:&lt;br>
如果沒有 Primary Key，則 Unique Secondary Index 會是 Clustered Index，行為與 Clustered Index 雷同，不額外贅述&lt;/li>
&lt;li>Non Unique Secondary Index&lt;/li>
&lt;/ol>
&lt;p>以下將重點分析 Clustered Index / Non Unique Secondary Index 對於 MySQL 操作有什麼不同的影響，在 Read Committed 簡稱 RC) 與 Repeatable Read (簡稱 RR) 下又有怎樣的不同行為，實驗預設是 5.7 + Repeatable Read (MySQL 預設)&lt;/p>
&lt;h2 id="clustered-index">Clustered Index&lt;/h2>
&lt;p>先來一題簡單的暖身題，以下兩個 Transaction 為什麼會 Deadlock
&lt;img src="https://yuanchieh.page/post/2022/img/0425/01.png"
loading="lazy"
>
要滿足 Deadlock 需要有四個條件&lt;/p>
&lt;ul>
&lt;li>no preemption&lt;/li>
&lt;li>hold and wait&lt;/li>
&lt;li>mutual exclusion&lt;/li>
&lt;li>circular waiting&lt;/li>
&lt;/ul>
&lt;p>在上面的案例中，MySQL 在 RR 下要 update 會先取得 exclusive lock，兩個 Transaction 手上都拿了對方想要的資源卻也不都會先放開手上的鎖，導致 Deadlock
&lt;img src="https://yuanchieh.page/post/2022/img/0425/01_2.png"
loading="lazy"
>&lt;/p>
&lt;p>直接從圖片很容易看出彼此 Deadlock，但正式環境中多筆 Transaction 交雜，該如何找出 Deadlock 呢？&lt;/p>
&lt;h3 id="1-如何-debug-deadlock">1. 如何 Debug Deadlock&lt;/h3>
&lt;p>MySQL 有幾個相關參數&lt;/p>
&lt;ol>
&lt;li>&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_deadlock_detect" target="_blank" rel="noopener"
>innodb_deadlock_detect&lt;/a>: 是否偵測 deadlock，預設開啟&lt;/li>
&lt;li>&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_lock_wait_timeout" target="_blank" rel="noopener"
>innodb_lock_wait_timeout&lt;/a>: 如果沒有開啟 Deadlock detect，建議設定較短的 wait timeout 否則會一直等到&lt;/li>
&lt;li>&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_print_all_deadlocks" target="_blank" rel="noopener"
>innodb_print_all_deadlocks&lt;/a>: 將所有 Deadlock 錯誤輸出至 error log&lt;/li>
&lt;/ol>
&lt;p>如果沒有輸出 Deadlock error，可以用 &lt;code>&amp;gt; SHOW ENGINE INNODB STATUS&lt;/code> 輸出，其中有兩個區塊 deadlock 顯示最近一筆 deadlock 錯誤，transaction 則會顯示目前在等待 lock 的 transaction&lt;/p>
&lt;h4 id="11-實際閱讀-deadlock">1.1 實際閱讀 Deadlock&lt;/h4>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-md" data-lang="md">&lt;span class="line">&lt;span class="cl">LATEST DETECTED DEADLOCK
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">------------------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2022-04-26 09:33:29 0x40de5bc700
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* (1) TRANSACTION:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">TRANSACTION 9597, ACTIVE 3 sec starting index read
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mysql tables in use 1, locked 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LOCK WAIT 3 lock struct(s), heap size 1136, 2 row lock(s), undo log entries 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">MySQL thread id 1034, OS thread handle 278338676480, query id 14980 172.17.0.1 root updating
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="sb">`UPDATE teachers SET teachers.age = 10 WHERE teachers.id = 5`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* (1) WAITING FOR THIS LOCK TO BE GRANTED:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RECORD LOCKS space id 275 page no 3 n bits 72 index PRIMARY of table test.teachers trx id 9597 lock_mode X locks rec but not gap waiting
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Record lock, heap no 3 PHYSICAL RECORD: n_fields 6; compact format; info bits 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0: len 8; hex 8000000000000005; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 1: len 6; hex 00000000257c; asc %|;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2: len 7; hex 23000001c017d1; asc # ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 3: len 1; hex 62; asc b;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 4: len 4; hex 80000010; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 5: SQL NULL;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* (2) TRANSACTION:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">TRANSACTION 9596, ACTIVE 3 sec starting index read
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mysql tables in use 1, locked 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">3 lock struct(s), heap size 1136, 2 row lock(s), undo log entries 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">MySQL thread id 1033, OS thread handle 278608463616, query id 14979 172.17.0.1 root updating
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="sb">`UPDATE teachers SET teachers.age = 6 WHERE teachers.id = 1`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* (2) HOLDS THE LOCK(S):
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RECORD LOCKS space id 275 page no 3 n bits 72 index PRIMARY of table test.teachers trx id 9596 lock_mode X locks rec but not gap
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Record lock, heap no 3 PHYSICAL RECORD: n_fields 6; compact format; info bits 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0: len 8; hex 8000000000000005; asc ;; -&amp;gt; index，用 16 進位表示，這邊是指 id: 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 1: len 6; hex 00000000257c; asc %|;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2: len 7; hex 23000001c017d1; asc # ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 3: len 1; hex 62; asc b;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 4: len 4; hex 80000010; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 5: SQL NULL;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* (2) WAITING FOR THIS LOCK TO BE GRANTED:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RECORD LOCKS space id 275 page no 3 n bits 72 index PRIMARY of table test.teachers trx id 9596 &lt;span class="sb">`lock_mode X locks rec but not gap waiting`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Record lock, heap no 2 PHYSICAL RECORD: n_fields 6; compact format; info bits 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0: len 8; hex 8000000000000001; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 1: len 6; hex 00000000257d; asc %};;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2: len 7; hex 22000001cc02e5; asc &amp;#34; ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 3: len 1; hex 61; asc a;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 4: len 4; hex 8000000f; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 5: SQL NULL;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* WE ROLL BACK TRANSACTION (2)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">------------
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>這部分內容參考 &lt;a class="link" href="https://juejin.cn/post/6844903943516979213" target="_blank" rel="noopener"
>MySQL死锁问题如何分析&lt;/a>，重點看這一段&lt;/p>
&lt;blockquote>
&lt;p>RECORD LOCKS space id 275 page no 3 n bits 72 index PRIMARY of table test.teachers trx id 9596 lock_mode X locks rec but not gap waiting &lt;code>專指 row lock&lt;/code>&lt;br>
Record lock, heap no 2 PHYSICAL RECORD: n_fields 6; compact format; info bits 0
0: len 8; hex 8000000000000001; asc ;; &lt;code>-&amp;gt; index，用 16 進位表示，這邊是指 id: 1&lt;/code>&lt;/p>
&lt;/blockquote>
&lt;p>，我們可以從 log 中看出操作 / 手上的 lock / 等待的 lock / &lt;code>Lock 在哪一個 row&lt;/code>&lt;/p>
&lt;h3 id="2-取得-lock-的順序性">2. 取得 Lock 的順序性&lt;/h3>
&lt;p>如果查詢的條件命中多筆，那 Lock 會怎麼取得呢？ 接著看以下案例
&lt;img src="https://yuanchieh.page/post/2022/img/0425/02.png"
loading="lazy"
>&lt;/p>
&lt;p>根據 &lt;a class="link" href="https://dev.mysql.com/doc/refman/5.7/en/update.html" target="_blank" rel="noopener"
>MySQL 文件&lt;/a>，會根據 Order By 的指定條件與 Index 本身順序性一行一行鎖起來&lt;/p>
&lt;blockquote>
&lt;p>If an UPDATE statement includes an ORDER BY clause, the rows &lt;code>are updated in the order specified by the clause&lt;/code>. This can be useful in certain situations that might otherwise result in an error. Suppose that a table t contains a column id that has a unique index. The following statement could fail with a duplicate-key error, depending on the order in which rows are updated&lt;/p>
&lt;/blockquote>
&lt;p>從 Deadlock Log 可以清楚看到 id 2 / id 5 被互相鎖住&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-md" data-lang="md">&lt;span class="line">&lt;span class="cl">*** (1) WAITING FOR THIS LOCK TO BE GRANTED:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RECORD LOCKS space id 278 page no 3 n bits 72 index PRIMARY of table test.teachers trx id 9676 lock_mode X waiting
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Record lock, heap no 2 PHYSICAL RECORD: n_fields 6; compact format; info bits 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0: len 8; hex &lt;span class="sb">`8000000000000002`&lt;/span>; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* (2) WAITING FOR THIS LOCK TO BE GRANTED:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RECORD LOCKS space id 278 page no 3 n bits 72 index PRIMARY of table test.teachers trx id 9675 lock_mode X waiting
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Record lock, heap no 3 PHYSICAL RECORD: n_fields 6; compact format; info bits 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0: len 8; hex &lt;span class="sb">`8000000000000005`&lt;/span>; asc ;;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h4 id="21-建立-index-時決定順序">2.1 建立 Index 時決定順序&lt;/h4>
&lt;p>當&lt;a class="link" href="https://dev.mysql.com/doc/refman/5.7/en/create-index.html" target="_blank" rel="noopener"
>建立 MySQL Index&lt;/a> 也可以指定順序，但需要注意 MySQL 5.7 會忽視 (全部都是 asc) 只有在 MySQL 8.0 以上才支援，所以以下案例只發生在 MySQL 8.0&lt;/p>
&lt;p>我們可以透過 &lt;code>USE INDEX()&lt;/code> 指定執行時的 Index
&lt;img src="https://yuanchieh.page/post/2022/img/0425/02_01.png"
loading="lazy"
>&lt;/p>
&lt;blockquote>
&lt;p>(5.7 文件) A key_part specification can end with ASC or DESC. These keywords are permitted for future extensions for specifying ascending or descending index value storage. Currently, they &lt;code>are parsed but ignored&lt;/code>; index values are always stored in ascending order.&lt;/p>
&lt;/blockquote>
&lt;h4 id="22-恰巧兩個-index-順序相仿">2.2 恰巧兩個 Index 順序相仿&lt;/h4>
&lt;p>2.1 案例中我們很刻意讓 Index 同一個欄位欄位但順序剛好相反，但如果是兩個不同 Index 而資料寫入時讓順序恰好相反呢？
在建立資料時，id 跟 name 的順序剛好相反，也就是&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-md" data-lang="md">&lt;span class="line">&lt;span class="cl">id1 &amp;gt; id2 &lt;span class="err">&amp;amp;&amp;amp;&lt;/span> name1 &lt;span class="p">&amp;lt;&lt;/span> &lt;span class="nt">name2&lt;/span>&lt;span class="err">，&lt;/span>&lt;span class="na">例如&lt;/span> &lt;span class="err">(&lt;/span>&lt;span class="na">1&lt;/span>&lt;span class="err">,&lt;/span> &lt;span class="err">&amp;#34;&lt;/span>&lt;span class="na">zz&lt;/span>&lt;span class="err">&amp;#34;)&lt;/span> &lt;span class="err">(&lt;/span>&lt;span class="na">2&lt;/span>&lt;span class="err">,&lt;/span> &lt;span class="err">&amp;#34;&lt;/span>&lt;span class="na">zx&lt;/span>&lt;span class="err">&amp;#34;)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>這樣也會發生 Deadlock!&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/2022/img/0425/02_02.png"
loading="lazy"
>&lt;/p>
&lt;h3 id="3-查詢沒有命中--gap-lock">3. 查詢沒有命中 : Gap Lock&lt;/h3>
&lt;p>如果查詢沒有命中，此時 MySQL 在 RR 情況下會取得 Gap Lock，所謂的 Gap 是在已存在欄位之間的縫隙，為了避免幻讀 MySQL 會鎖住 Gap 不讓其他 Transaction 插入資料&lt;/p>
&lt;p>這邊特別介紹兩個鎖定區間的 Lock，分別是 Gap Lock / Insert Intention Lock&lt;/p>
&lt;ol>
&lt;li>Insert Intention Lock 故名思義是是插入前會鎖定該區間&lt;/li>
&lt;li>這兩種 Lock 特別在於不會排擠自己人，例如 &lt;code>Gap Lock 不會阻擋 Gap Lock&lt;/code> / &lt;code>Insert Intention Lock 不會阻擋 Insert intention Lock&lt;/code>，但是 &lt;code>Insert Intention Lock 跟 Gap Lock 互斥&lt;/code>，原因是區間可能很大，為了提升性能，在同一個區間可以同時插入新資料，如果真的有違反 Unique Key 則會有原本的重複性檢查阻擋，Update 也是&lt;/li>
&lt;/ol>
&lt;p>有一個場景是「我們希望更新某一筆資料，發現資料不在則寫入」，如以下範例則會造成 Deadlock
&lt;img src="https://yuanchieh.page/post/2022/img/0425/03.png"
loading="lazy"
>&lt;/p>
&lt;p>因為 id 6 / 10 在 update 時都取得了 Gap Lock，接著要 Insert 取得 Insert Intention Lock 卻因為雙方都還握有 Gap Lock 而無法寫入，讓我們看具體的 Deadlock 細節&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-md" data-lang="md">&lt;span class="line">&lt;span class="cl">*** (1) WAITING FOR THIS LOCK TO BE GRANTED:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RECORD LOCKS space id 279 page no 3 n bits 72 index PRIMARY of table test.teachers trx id 9700 &lt;span class="sb">`lock_mode X insert intention waiting`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0: len 8; hex 73757072656d756d; asc &lt;span class="sb">`supremum`&lt;/span>;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* (2) HOLDS THE LOCK(S):
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RECORD LOCKS space id 279 page no 3 n bits 72 index PRIMARY of table test.teachers trx id 9699 &lt;span class="sb">`lock_mode X`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0: len 8; hex 73757072656d756d; asc &lt;span class="sb">`supremum`&lt;/span>;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* (2) WAITING FOR THIS LOCK TO BE GRANTED:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RECORD LOCKS space id 279 page no 3 n bits 72 index PRIMARY of table test.teachers trx id 9699 lock_mode X insert intention waiting
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0: len 8; hex 73757072656d756d; asc supremum;;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>可以看到雙方都在等 &lt;code>lock_mode X insert intention waiting&lt;/code>，指定的 row 是 &lt;code>supermum&lt;/code> 這是代表最後一個區間，區間大致長以下這般&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-md" data-lang="md">&lt;span class="line">&lt;span class="cl">(negative infinity, 第一筆]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(第一筆, 第二筆]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">....
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(最後一筆, positive infinity)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>所以同樣的 query 只是原始資料改變落在不同區間，就不會有 Deadlock 如以下
&lt;img src="https://yuanchieh.page/post/2022/img/0425/03_01.png"
loading="lazy"
>&lt;/p>
&lt;h3 id="4-範圍查詢鎖定找過的每筆資料即使條件不合">4. 範圍查詢：鎖定找過的每筆資料即使條件不合&lt;/h3>
&lt;p>接下來看一個 RR 蠻嚇人的一個特性，參考文件 &lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html" target="_blank" rel="noopener"
>15.7.2.1 Transaction Isolation Levels&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>&amp;ldquo;When using the default REPEATABLE READ isolation level, the first UPDATE acquires an x-lock on each row that it reads and &lt;code>does not release any of them&lt;/code>&lt;/p>
&lt;/blockquote>
&lt;p>也就是說 where condition 假使是範圍搜尋，RR 會把搜尋到的範圍全部鎖死，直到 transaction 結束!&lt;/p>
&lt;p>讓我們看以下案例
&lt;img src="https://yuanchieh.page/post/2022/img/0425/04.png"
loading="lazy"
>&lt;/p>
&lt;p>Update 的條件沒有命中但是&lt;code>全部都被 Lock&lt;/code>，要 update / insert 都不行，相對的&lt;/p>
&lt;blockquote>
&lt;p>RC 在檢查不符合條件就會 release，在做大規模的 Update / Delete 記得要用 RC 會比較好&lt;/p>
&lt;/blockquote>
&lt;h2 id="non-unique-index">Non Unique Index&lt;/h2>
&lt;p>上面的範例都是 Clustered Index，MySQL 支援 Secondary Index，其中 Unique Secondary Index 與 Clustered Index 行為類似，就不另外贅述，但是 Non Unique Index 要稍微留意&lt;/p>
&lt;h3 id="1-查詢命中依然會-gap-lock">1. 查詢命中：依然會 Gap Lock&lt;/h3>
&lt;p>在一開始的範例，如果 Clustered Index 查詢有命中只會鎖那一行 (ex. update id = 1)，但如果 Non Unique Index 即使完全命中，也會連同 Gap 一起鎖起來 (Next Key Lock)&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/2022/img/0425/05.png"
loading="lazy"
>
這邊 Lock 比較多，需注意 Secondary Index 會被鎖之外，對應的 Clustered Index 也會被鎖，這邊 age 鎖定 10 以及前面的區間，所以要插入 age: 9 就會失敗；運用上面的技巧，age 切換到不同區間就可以成功插入&lt;/p>
&lt;h2 id="foreign-key會有-share-lock">Foreign Key：會有 Share Lock&lt;/h2>
&lt;blockquote>
&lt;p>If a FOREIGN KEY constraint is defined on a table, any insert, update, or delete that requires the constraint condition to be checked sets shared record-level locks&lt;/p>
&lt;/blockquote>
&lt;p>更新欄位時 Foreign Key 也會被鎖住，之前有紀錄就不贅述 &lt;a class="link" href="https://yuanchieh.page/posts/2020/2020-12-26-mysql-deadlock-%E5%95%8F%E9%A1%8C%E6%8E%92%E6%9F%A5%E8%88%87%E8%99%95%E7%90%86/" target="_blank" rel="noopener"
>MySQL Deadlock 問題排查與處理&lt;/a>&lt;/p>
&lt;h2 id="總結與建議">總結與建議&lt;/h2>
&lt;p>幾點建議&lt;/p>
&lt;ol>
&lt;li>增加 Index 要仔細評估，Secondary Index 會造成寫入效能下降，體現於 lock 的使用&lt;/li>
&lt;li>如果是用 ORM，記得檢查 Query&lt;/li>
&lt;li>如果需要用 Secondary Index 改變欄位，建議可以用批次 (RoR 就是 find_in_batch)&lt;/li>
&lt;li>或是先篩選出 Primary Key (預設 select 不會有 lock)，再使用 Primary Key 當作修改條件避免 Gap Lock&lt;/li>
&lt;li>&lt;code>沒事就用 Read Committed&lt;/code>&lt;/li>
&lt;/ol>
&lt;h2 id="進階為什麼不要預設-read-committed-">進階：為什麼不要預設 Read Committed ?&lt;/h2>
&lt;p>既然 Repeatable Read 會有這麼多效能疑慮，更新時連 where 條件不符合的行都會鎖、還會有不預期的 Gap Lock，那為什麼預設不要改成 Read Committed ?&lt;/p>
&lt;p>在 PostgreSQL 確實如此，&lt;a class="link" href="https://www.postgresql.org/docs/7.2/xact-read-committed.html" target="_blank" rel="noopener"
>PQ 9.3. Read Committed Isolation Level&lt;/a>提到&lt;/p>
&lt;blockquote>
&lt;p>The partial transaction isolation provided by Read Committed level is adequate for many applications, and this level is fast and simple to use&lt;/p>
&lt;/blockquote>
&lt;p>我在查閱 MySQL 相關資料，也有查到 Percona 一篇文章提及 MySQL 預設應該要改成 Read Committed 比較好 &lt;a class="link" href="https://www.percona.com/blog/2015/01/14/mysql-performance-implications-of-innodb-isolation-modes/" target="_blank" rel="noopener"
>MySQL performance implications of InnoDB isolation modes&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>In general I think good practice is to use READ COMITTED isolation mode as default and change to REPEATABLE READ for those applications or transactions which require it.&lt;/p>
&lt;/blockquote>
&lt;p>那 MySQL 官方怎麼說，我找到一篇官方的 blog &lt;a class="link" href="https://dev.mysql.com/blog-archive/performance-impact-of-innodb-transaction-isolation-modes-in-mysql-5-7/" target="_blank" rel="noopener"
>Performance Impact of InnoDB Transaction Isolation Modes in MySQL 5.7&lt;/a> 建議到&lt;/p>
&lt;blockquote>
&lt;ul>
&lt;li>For short running queries and transactions, use the default level of REPEATABLE-READ.&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;ul>
&lt;li>For long running queries and transactions, use the level of READ-COMMITTED&lt;/li>
&lt;/ul>
&lt;p>裡面有另一篇文做了 Benchmark 非常有趣 &lt;a class="link" href="http://dimitrik.free.fr/blog/archives/2015/02/mysql-performance-impact-of-innodb-transaction-isolation-modes-in-mysql-57.html" target="_blank" rel="noopener"
>MySQL Performance : Impact of InnoDB Transaction Isolation Modes in MySQL 5.7&lt;/a>，從 MySQL 內部的 Lock 數量與操做 QPS 衡量不同 isolation level，我本來以為 Read Committed 在增刪查改會碾壓 Repeatable Read，但發現盡然沒有，反而因為 Read Committed 在每次 Read 都會產生新的 MVCC 版本而有更多的內部 Lock，非常有趣&lt;/p>
&lt;p>所以總結官方部落格建議，預設還是保留 RR 普遍效能反而更好，只有在長時間的 Job 再改成 RC 即可&lt;/p></description></item><item><title>【DDIA】03 - 資料庫儲存原理研究</title><link>https://yuanchieh.page/posts/2022/2022-04-02-ddia03-%E8%B3%87%E6%96%99%E5%BA%AB%E5%84%B2%E5%AD%98%E5%8E%9F%E7%90%86%E7%A0%94%E7%A9%B6/</link><pubDate>Sat, 02 Apr 2022 01:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2022/2022-04-02-ddia03-%E8%B3%87%E6%96%99%E5%BA%AB%E5%84%B2%E5%AD%98%E5%8E%9F%E7%90%86%E7%A0%94%E7%A9%B6/</guid><description>&lt;p>DDIA - 《Designing Data-Intensive Applications》，這本書值得有一個專門的縮寫 XD 在幾年前剛出社會時有先硬啃了大半部分，在往後的工作上這些觀念不斷的被使用上，一直很想再重新更深入理解這本書；&lt;br>
剛好最近要開始準備公司內部分享，分享一些關於資料庫的事情，重新翻閱這本書，並寫下讀書心得，以下內容包含圖片都是整理自相關資料&lt;/p>
&lt;p>以下將描述&lt;/p>
&lt;ul>
&lt;li>最簡單實作資料庫的方式&lt;/li>
&lt;li>SSLTable / B Tree 儲存方式與比較&lt;/li>
&lt;li>Column Storage&lt;/li>
&lt;/ul>
&lt;h2 id="storage-and-retrieval">Storage and Retrieval&lt;/h2>
&lt;p>資料庫最基本的核心功能&lt;/p>
&lt;ol>
&lt;li>給你一些資料，幫我保存 - storage&lt;/li>
&lt;li>我晚點跟你拿這些資料，記得給我 - retrieval&lt;/li>
&lt;/ol>
&lt;p>如果僅考慮這兩個功能，如何用最簡單的方式實作呢？&lt;/p>
&lt;h3 id="一-最簡單的資料庫---log-structured-storage">一. 最簡單的資料庫 - Log Structured Storage&lt;/h3>
&lt;p>今天實作一個 key-value DB，我們用兩個 bash command 就可以完成&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#!/bin/bash
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">&lt;/span>db_set&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">echo&lt;/span> &lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="nv">$1&lt;/span>&lt;span class="s2">,&lt;/span>&lt;span class="nv">$2&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span> &amp;gt;&amp;gt; database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">db_get&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> grep &lt;span class="s2">&amp;#34;^&lt;/span>&lt;span class="nv">$1&lt;/span>&lt;span class="s2">,&amp;#34;&lt;/span> database &lt;span class="p">|&lt;/span> sed -e &lt;span class="s2">&amp;#34;s/^&lt;/span>&lt;span class="nv">$1&lt;/span>&lt;span class="s2">,//&amp;#34;&lt;/span> &lt;span class="p">|&lt;/span> tail -n &lt;span class="m">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>呼叫 db_set 時，很單純一直把值 append 到檔案的最後；如果要取出，則從檔案的最後開始比對 key，回傳第一筆匹配的值，這樣就能解決同個 key 被更新多次的狀況&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">$ db_set &lt;span class="m">42&lt;/span> &lt;span class="s1">&amp;#39;hello word&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ db_get &lt;span class="m">42&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">hello world
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>如果我們考量寫入與讀取的效能&lt;/p>
&lt;ul>
&lt;li>寫入：非常好，因為是順序性寫入，基本上沒有比 append 更快的寫法，在非常多的應用程式中，也都用上 &lt;code>append only log&lt;/code>，如 MySQL binlog&lt;/li>
&lt;li>讀取：因為要從檔案最末端開始讀取，時間複雜度為 &lt;code>O(n)&lt;/code>，非常慢&lt;/li>
&lt;/ul>
&lt;h4 id="1-改善讀取效率---加上-index">1. 改善讀取效率 - 加上 Index&lt;/h4>
&lt;p>我們可以透過在 memory 中維護一份 Hash Table，在寫入時順便儲存 &lt;code>{ key:檔案位置 }&lt;/code>，這樣就能在查詢時用 O(1) 的時間找到 key&lt;/p>
&lt;blockquote>
&lt;p>但這帶來另一個限制，&lt;code>Hash Table 必須能完整放入 Memory&lt;/code>，如果今天 key size 超過，則 Index 無法被建立就會回到 O(n) 的查詢複雜度&lt;/p>
&lt;/blockquote>
&lt;h4 id="2-改善儲存效率---compact">2. 改善儲存效率 - Compact&lt;/h4>
&lt;p>思考另一個儲存問題，今天如果是同一個 key 被反覆儲存多次，以目前 append-only 的設計，他會被儲存很多筆，每次讀取只拿最後一筆，前面幾筆的資料空間就浪費了&lt;/p>
&lt;p>所以通常會搭配 Compact 設計，重新整理 log 把舊資料刪除，釋放儲存空間，實作上 &lt;code>會開新的檔案合併舊的檔案內容，並不會直接修改舊檔案&lt;/code>，這樣做的好處是寫入、讀取不會中斷，等到新的檔案完成後，再移除舊檔案&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/2022/img/0402/compact.png"
loading="lazy"
>&lt;/p>
&lt;h4 id="3-為什麼要用-append-而不是直接-update-">3. 為什麼要用 append 而不是直接 update ?&lt;/h4>
&lt;p>如果我直接改原本的資料，是不是就節省了 compact 的過程？原因在於硬碟順序寫入效能會比較好，即使 SSD 也是，這點後續補充&lt;/p>
&lt;h4 id="4-無可避免的缺點---range-search">4. 無可避免的缺點 - range search&lt;/h4>
&lt;p>如果要範圍搜尋，Hash Table 無法做到這件事，同樣的 disk 儲存方式也沒有排序，所以只能全部 Scan&lt;/p>
&lt;h4 id="5-real-world-sample-bitcask">5. Real World Sample: Bitcask&lt;/h4>
&lt;p>以上的方式聽起來簡單的過分，但這也是真實有在採用的作法，如 Riak 內的儲存引擎 Bitcask，Riak 是分散式 Key-Value DB&lt;br>
Bitcask 是用 Erlang 實作，&lt;a class="link" href="https://github.com/basho/bitcask" target="_blank" rel="noopener"
>原始碼&lt;/a> 有點看不懂，但有另一篇文章可以從 high level 角度去查證 &lt;a class="link" href="https://riak.com/assets/bitcask-intro.pdf" target="_blank" rel="noopener"
>Bitcask: A Log-Structured Hash Table for Fast Key/Value Data&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/2022/img/0402/disk.png"
loading="lazy"
>
儲存方面，bitcask 維護一個 active file 持續寫入，其餘會有多個 older file 只讀不寫，背景運行一個 merge process 持續合併多個 older file&lt;/p>
&lt;p>每筆資料有前綴 metadata，這些資料欄位的尺寸都是固定的，但是 key value 的長度可以是變動，透過 keysz / valuesz 知道對應長度；&lt;br>
其中 CRC 是 checksum，可以檢查資料寫入是否有誤&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/2022/img/0402/keydir.png"
loading="lazy"
>
bitcask 中的資料結構 &lt;code>keydir&lt;/code> 就是 hash table，保存 key 對應到 value 的儲存位置，這樣就能夠一次 Disk 查詢取出 value&lt;/p>
&lt;h4 id="6-不同面向考量">6. 不同面向考量&lt;/h4>
&lt;p>資料庫不單是讀寫，還需要考量其他面向的問題，讓我們一一檢視這樣的簡單設計&lt;/p>
&lt;ul>
&lt;li>Crash Recovery: 基本上不會有問題，因為檔案都是 append only，如果有問題可以透過 CRC 檢查，只是 keydir 要重建&lt;/li>
&lt;li>Restore: 直接複製檔案過去就好&lt;/li>
&lt;li>Heavy Load &amp;amp; High Volume: 當資料量變大或是 loading 變大時，預期 bitcask 的效能不會有太大差異，因為都是很簡單的 disk 與 memory 操作&lt;/li>
&lt;/ul>
&lt;h3 id="二-sstable-與-lsm-tree">二. SSTable 與 LSM Tree&lt;/h3>
&lt;p>上面提到 Log Structure 遇到 range search 效能會很差，那如果我們把資料排序後再寫入呢？&lt;br>
在計算機科學中，負責快速插入、查找、範圍搜尋的資料結構可以用 &lt;code>平衡樹&lt;/code>，插入與搜尋都是 O(logn)，如果是範圍搜尋則為 O(logn, k)&lt;/p>
&lt;p>實作上，當資料寫入時&lt;/p>
&lt;ol>
&lt;li>會先暫存到 memory 中，資料結構為平衡樹，此稱為 &lt;code>memtable&lt;/code>&lt;/li>
&lt;li>當 memtable 超過門檻，寫入硬碟，稱為 &lt;code>SSTable (Sorted String Table)&lt;/code>，後續資料寫入新的 memtable&lt;/li>
&lt;li>SSTable 同樣會在背景 compact，如 Log Structure&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://yuanchieh.page/post/2022/img/0402/sstable.png"
loading="lazy"
>&lt;/p>
&lt;blockquote>
&lt;p>到底儲存用 sorted 後的結果有什麼巨大的好處？又會有帶來什麼影響呢？&lt;/p>
&lt;/blockquote>
&lt;p>讓我們思考以下幾個細節&lt;/p>
&lt;h4 id="1-寫入最一開始是儲存在-memory-中如果-crash-會不會掉資料">1. 寫入最一開始是儲存在 memory 中，如果 crash 會不會掉資料？&lt;/h4>
&lt;p>會，所以寫入 memory 時同時會用 append log 方式寫入資料庫，借用 log structure 的智慧，當 crash recovery 從 log 復原即可&lt;/p>
&lt;h4 id="2sorted-後儲存結果的幾個好處">2.sorted 後儲存結果的幾個好處&lt;/h4>
&lt;p>除了剛剛說的支援更快的範圍查詢外，&lt;code>保存在 memory 中的 index 數量可以更少，讓 dataset 支援容量更大&lt;/code>，如上面圖示，SSTable 會以&lt;code>多筆資料為一個 block&lt;/code>保存，今天我要找 2，index tree 內沒有 2 沒關係，我可以找到 1 的檔案位置，接著把 block 讀取出來，這樣我就能透過 1 找到 2，能夠這樣找是因為 &lt;code>儲存有按照 index 排序&lt;/code>&lt;/p>
&lt;h4 id="3-compact-過程會不會很麻煩">3. compact 過程會不會很麻煩?&lt;/h4>
&lt;p>不會，如果有學過 merge sort，這個過程就是把兩個小的 block 從頭到尾 iterate 過就解決了，時間複雜度為 O(n+m)&lt;/p>
&lt;h4 id="4-查找不存在的-key-效率不好">4. 查找不存在的 key 效率不好&lt;/h4>
&lt;p>因為要找過每一個 SSTable 才能確定資料不存在，這邊可以利用 Bloom Filter 快速判斷，可以參考我之前的筆記 &lt;a class="link" href="https://yuanchieh.page/posts/2020/2020-11-17-sketch-data-structure-bloom-filter-%E4%BB%8B%E7%B4%B9%E8%88%87%E5%AF%A6%E4%BD%9C/" target="_blank" rel="noopener"
>Sketch Data Structure - Bloom Filter 介紹與實作&lt;/a>&lt;/p>
&lt;h4 id="5-real-world-sample-leveldb--rocksdb--bigtable">5. Real World Sample: LevelDB / RocksDB / BigTable&lt;/h4>
&lt;p>Google LevelDB 是用 SSTable 概念實作的 Key-Value DB，可以參考他的說明 &lt;a class="link" href="https://github.com/google/leveldb/blob/main/doc/impl.md" target="_blank" rel="noopener"
>LevelDB impl.md&lt;/a>，其中可以注意 compact 過程是有分等級的 (所以才叫 level DB)，避免一次性大量的 compact 發生導致硬碟效能吃不消，其中翻了一下 memtable 沒有看到是用什麼方式實作&lt;/p>
&lt;p>RocksDB 則是 Facebook 基於 LevelDB 所開發的，說明蠻完整的 &lt;a class="link" href="https://github.com/facebook/rocksdb/wiki/RocksDB-Overview" target="_blank" rel="noopener"
>RocksDB Overview&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>The memtable is an in-memory data structure - new writes are inserted into the &lt;code>memtable&lt;/code> and are optionally written to the logfile (aka. &lt;code>Write Ahead Log(WAL)&lt;/code>). The logfile is a sequentially-written file on storage. When the memtable fills up, it is flushed to a &lt;code>sstfile&lt;/code>&lt;/p>
&lt;/blockquote>
&lt;p>下方有提到一些 &lt;a class="link" href="https://github.com/facebook/rocksdb/wiki/MemTable" target="_blank" rel="noopener"
>memtable 實作與比較&lt;/a>，預設是 skiplist，感覺蠻有趣的，未來可以再深入研究&lt;/p>
&lt;p>另外還有 Google 的&lt;a class="link" href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/68a74a85e1662fe02ff3967497f31fda7f32225c.pdf" target="_blank" rel="noopener"
>Bigtable: A Distributed Storage System for Structured Data&lt;/a>，裡面也有提到很多相關的內容，未來待讀項目之一 (挖坑)&lt;/p>
&lt;p>以上 Log Structure 與 SSTable 都可稱為 &lt;code>LSMTree&lt;/code>，也就是 Log Structure and Merging Tree，透過 log 方式儲存並有持續 merge 的行為&lt;/p>
&lt;hr>
&lt;h3 id="三-b-tree">三. B Tree&lt;/h3>
&lt;p>B Tree 在資料庫儲存上是非常受歡迎的選項，如 MySQL / PostgreSQL 等，B Tree 也是平衡樹的一種，每一層保存指定數量的節點 (branching factor) 代表不同的範圍，並保存指向下一層的指針，最後在葉子節點 (leef node) 保存資料&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/2022/img/0402/b_tree.png"
loading="lazy"
>&lt;/p>
&lt;p>在 B Tree 的保存中，是以固定尺寸的 &lt;code>Page&lt;/code> 為單位，剛好對應到硬碟儲存方式也是以固定尺寸的區塊儲存，如果資料沒有塞滿 Page 則會造成一些破碎&lt;/p>
&lt;p>高度為 4 + brancing factor 為 5 + Page size 4 KB 的 B Tree 就能儲存 256 TB&lt;/p>
&lt;p>B Tree 與 SSTable 相似之處在於資料保存於硬碟都是排序過，但是 B Tree 會&lt;code>不斷修改已經持久化的檔案&lt;/code>，尤其是當 Page 內資料超過需要拆分 Page 並重新平衡時，會有比較多的硬碟操作，而 SSTable 只會一直寫入等到 compact 階段才合併產生新的檔案&lt;/p>
&lt;h3 id="b-tree-vs-sstable">B Tree vs SSTable&lt;/h3>
&lt;p>常理來說 SSTable 寫入會比較快，因為就是 append 上去而 B Tree 需要先寫 WAL 並等到 Page 刷新到硬碟上，這點在高寫入的系統下尤為重要；
另外 SSTable 會有 compact 過程，相比 B Tree Page 設計可以更有效使用磁碟空間&lt;/p>
&lt;p>而 B Tree 的好是讀取較快，因為 SSTable 的同一個 key 可能散落在多個 file 中需要每個都檢查；同時當遇上 compact 時效能會有比較大的衝擊，而 B Tree 相對會比較穩定&lt;/p>
&lt;h3 id="column-storage">Column Storage&lt;/h3>
&lt;p>上述偏 OLTP 的資料庫設計，資料是以 row 的方式儲存，但是在 OLAP 專門做分析上，往往我們需要的是 query 非常多的資料筆數但只分析其中一兩個欄位，例如撈出過去一年的銷售總額，如果資料是以 row 方式儲存，要把一整年的資料都拿出來過濾、篩選再總和，十分耗費資源&lt;/p>
&lt;p>在 OLAP 中，既然我們常常以 &lt;code>column&lt;/code> 為主，那改用 column 來當作儲存的依據是不是會比較好？ column storage 的概念就這樣延伸出來&lt;/p>
&lt;p>這樣做的最大好處&lt;code>非常好壓縮&lt;/code>，從欄位資料的 cardinality 來看，往往數量不多，例如數百萬筆資料中國家種類就那兩百個，所以可以用一些壓縮的技巧如 bitmap encoding，用 bitmap 代表某個特定值儲存，在讀取時可以用 bitwise 操作，對於 CPU 效率會好上許多；&lt;br>
所以儲存空間小、運算也很快&lt;/p>
&lt;h4 id="限制與應變">限制與應變&lt;/h4>
&lt;p>因為現在是每一個 column 都獨立儲存，那如果我想要讀取某一個 row 的所有 column 怎麼辦？&lt;br>
所以在儲存時每一個 column file 的 &lt;code>row order 都必須一樣&lt;/code>，這樣才能還原同一筆 row 的全部 column&lt;/p>
&lt;p>如果在儲存時希望有排序，例如分析資料通常會按照日期排序，可以套用之前 SSTable 概念，先用 memtable 排好序，寫入時再分成多個 column file 儲存&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/2022/img/0402/column.png"
loading="lazy"
>&lt;/p>
&lt;blockquote>
&lt;p>要注意 column-family database 與 column storage database 是不一樣的詞彙，如 Cassandra 在文件表明是以 &lt;code>row-based&lt;/code> 儲存，參考 &lt;a class="link" href="https://github.com/apache/cassandra" target="_blank" rel="noopener"
>Apache Cassandra is a highly-scalable partitioned row store&lt;/a>，但他被歸類在 column-family 中，至於為什麼這樣歸類可能是跟他的用途跟印象比較有關，網路上隨便一查都有一些錯誤的資訊，要在小心留意 (會不會我才是錯的 ?! 如果是歡迎留言讓我知道)&lt;/p>
&lt;/blockquote>
&lt;h3 id="結論">結論&lt;/h3>
&lt;p>知道資料庫怎麼儲存好像不會變成資料庫大師 XD 但對於未來在評估不同的資料庫時，又多一個可以驗證真偽的工具，尤其是在大營銷時代各種新的技術名詞持續被發明，但資料庫的本質就還是 storage and retrieval&lt;/p></description></item><item><title>《Effective SQL》讀後分享</title><link>https://yuanchieh.page/posts/2021/2021-11-14-effective-sql%E8%AE%80%E5%BE%8C%E5%88%86%E4%BA%AB/</link><pubDate>Sun, 14 Nov 2021 01:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2021/2021-11-14-effective-sql%E8%AE%80%E5%BE%8C%E5%88%86%E4%BA%AB/</guid><description>&lt;p>&lt;img src="https://cf-assets2.tenlong.com.tw/products/images/000/107/662/webp/ACL049900.webp?1525539256"
loading="lazy"
>
&lt;a class="link" href="https://www.tenlong.com.tw/products/9789864764358?list_name=lv" target="_blank" rel="noopener"
>天瓏購買連結&lt;/a>&lt;/p>
&lt;p>最近在幫公司處理 Data Pipeline，將資料送往 BigQuery 儲存，並開始了 SQL 煉獄，必須說平常開發寫的 Query 複雜度都不太高，比較注重資料表的設計與效能，而報表相關則需要更大量的關聯、去重、查詢效能等，所以特別買了《Effective SQL》拜讀一番，裡頭提供很多寫 SQL 的優化，以及關聯後各種的 Edge Case，如果你對於寫的 SQL 沒有足夠自信，那很推薦入手&lt;/p>
&lt;p>以下將整理幾點我覺得特別有啟發性的&lt;/p>
&lt;h2 id="關聯運算">關聯運算&lt;/h2>
&lt;p>在關聯運算中，包含了八種運算&lt;/p>
&lt;ol>
&lt;li>選擇：透過 where / having 過濾&lt;/li>
&lt;li>投影：透過 select / group by 選擇回傳欄位&lt;/li>
&lt;li>連接：透過 join 連接多張資料表&lt;/li>
&lt;li>交集：透過 interset 找出兩個集合的重疊 (MySQL 不支援)，也可以用 INNER JOIN，例如「找到同時買過 bike 與 sakteboard 的客戶」&lt;/li>
&lt;li>笛卡爾積：兩個集合的所有組合列舉，使用 CROSS JOIN&lt;/li>
&lt;li>聯集：合併兩個欄位相同的集合，透過 UNION&lt;/li>
&lt;li>除法：被除數集合中帶有全部除數集合的列，例如「某應徵者符合所以的工作條件」&lt;/li>
&lt;li>差集：一個集合減去另一個集合，可以透過 EXCEPT (MySQL 不支援)，但可以用 OUTER JOIN 再去檢查 null 值模擬&lt;/li>
&lt;/ol>
&lt;h3 id="作法-23-找出不相符或不存在的紀錄">作法 23: 找出不相符或不存在的紀錄&lt;/h3>
&lt;p>&lt;a class="link" href="https://www.db-fiddle.com/f/4WX7yN4GWRrA1wX7zb8AXv/2" target="_blank" rel="noopener"
>https://www.db-fiddle.com/f/4WX7yN4GWRrA1wX7zb8AXv/2&lt;/a>&lt;br>
主要可以使用 3 種方式&lt;/p>
&lt;ol>
&lt;li>使用 In&lt;/li>
&lt;li>使用 Exists&lt;/li>
&lt;li>使用 Left Join 並用 Where&lt;/li>
&lt;/ol>
&lt;p>前兩種搭配 subquery，exists 通常性能比 in 好因為只要 subquery 至少存在一列就能 return&lt;/p>
&lt;h3 id="作法-24-使用-case-解決問題的時機">作法 24: 使用 Case 解決問題的時機&lt;/h3>
&lt;p>&lt;a class="link" href="https://www.db-fiddle.com/f/knMFW8pMRiVa6yg22i59DB/0" target="_blank" rel="noopener"
>https://www.db-fiddle.com/f/knMFW8pMRiVa6yg22i59DB/0&lt;/a>&lt;br>
紀錄一下 Case 中 when 可以使用 subquery，這讓可能性增大很多，例如標記商品的熱銷程度，可以在 when 中加入 subquery 查詢販賣總數而不用先 outer join 再 select 一次&lt;/p>
&lt;h3 id="作法-25-解決多條件問題的技巧">作法 25: 解決多條件問題的技巧&lt;/h3>
&lt;p>當資料表需要關聯後再用多種條件篩選，要小心下條件的位置避免篩選錯誤，例如「要找出買過 skateboard 又同時買過 helmet / knee pad 的用戶」，需要使用多次 INNER JOIN 才能夠篩選出同時滿足多條件的查詢，要小心不能直接用 IN 會變成 &amp;ldquo;OR&amp;rdquo; 的條件&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">-- 這只會找到有買過任一商品的用戶
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="k">select&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">users&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">users&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">where&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">users&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">in&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">select&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">orders&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">user_id&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">orders&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">inner&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">join&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">products&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">on&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">products&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">orders&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">product_id&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">where&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">products&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">in&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;skateboard&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;helmet&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;knee pad&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>可以適時用 function 簡化重複的 SQL
&lt;a class="link" href="https://www.db-fiddle.com/f/vpB9hZgNGhnFPZo2FQrLhn/0" target="_blank" rel="noopener"
>https://www.db-fiddle.com/f/vpB9hZgNGhnFPZo2FQrLhn/0&lt;/a>&lt;/p>
&lt;h3 id="作法-26-需要完全符合時使用除法">作法 26: 需要完全符合時使用除法&lt;/h3>
&lt;p>&lt;a class="link" href="https://www.db-fiddle.com/f/sA2VfuFSxW9Lr4krdcUg29/1" target="_blank" rel="noopener"
>https://www.db-fiddle.com/f/sA2VfuFSxW9Lr4krdcUg29/1&lt;/a>
假設是一個求職網站，用戶需要找「滿足特定技能組合的職缺」，就需要用到除法的概念，可以用兩種方式&lt;/p>
&lt;h4 id="1-雙重否定">1. 雙重否定：&lt;/h4>
&lt;p>先看最內層 - 找出用戶所有的與所需技能樹相符合的技能，第一個否定式是找出所需技能樹中用戶有哪些不足的 (not exists)，第二層否定式 &lt;code>用戶沒有 (所需技能樹中不再(用戶所需的技能樹))&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">select&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">users&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">where&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">not&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">exists&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">select&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">prefered_skills&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">where&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">not&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">exists&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">select&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">users&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">as&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">u2&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">inner&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">join&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">user_skills&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">on&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">user_skills&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">user_id&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">u2&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">where&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">u2&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">users&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">and&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">user_skills&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">skill_id&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">prefered_skills&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">skill_id&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>邏輯上有點繞，假設所需技能樹需要 js / aws，而 user 只會 rails / aws，第一層會先篩選出 aws (rails 不再所需技能樹內)；第二步會篩選出 js (因為用戶沒有該技能)，第三步計算出 (用戶有缺少所需技能樹) 所以被過濾掉；&lt;br>
不過以上除了邏輯比較繞，還有一個缺點是 &lt;code>如果所需技能樹為空，則會回傳所有的行，因為第一層否定會是 all true&lt;/code>&lt;/p>
&lt;h4 id="2-使用-group-by-與-having">2. 使用 group by 與 having：&lt;/h4>
&lt;p>這個方法比想像中簡單，透過 LEFT JOIN 找出 user 目前與 prefered_skills 有幾個重複技能，最後直接比 count 是否相同就知道&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">select&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">users&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">count&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">prefered_skills&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">skill_id&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">as&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">prefered_skill_count&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">users&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">inner&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">join&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">user_skills&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">on&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">user_skills&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">user_id&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">users&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">left&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">join&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">prefered_skills&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">on&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">prefered_skills&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">skill_id&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">user_skills&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">skill_id&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">group&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">by&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">users&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">having&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">select&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">count&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">prefered_skills&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">prefered_skill_count&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="作法-33-不用-group-by-找出最大或最小值">作法 33: 不用 GROUP BY 找出最大或最小值&lt;/h3>
&lt;p>&lt;a class="link" href="https://www.db-fiddle.com/f/8TMwJykwSRc4Li4J9hbdyb/0" target="_blank" rel="noopener"
>https://www.db-fiddle.com/f/8TMwJykwSRc4Li4J9hbdyb/0&lt;/a>
這個提議很有趣也很實用，通常看到 MIN/MAX 很直覺就是用 GROUP BY 找出，但是 GROUP BY 後只會保留聚集的欄位而其他欄位資訊都會消失 (除非用 primary 當作 GROUP BY 條件但通常不會這麼用)，這邊作者給出另一個很棒的替代方案，&lt;code>使用 LEFT JOIN 找出極值&lt;/code>&lt;/p>
&lt;p>例如說今天有一個酒單 [類別, 產地國家, 酒精濃度]，我們希望「找出同一類別中最烈的酒同時顯示產地國家」
第一種是錯誤示範，會出現&lt;code>ER_WRONG_FIELD_WITH_GROUP&lt;/code> 的錯誤&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">select&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">max&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">alcohol&lt;/span>&lt;span class="p">),&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">category&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">country&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">beers&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">group&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">by&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">category&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>可以用 LEFT JOIN 方式，找到同一個種類中比當前欄位更高的酒精濃度，如果找不到 (where .. is null) 代表當前欄位就是最烈的啤酒&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">select&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">beers&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">left&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">join&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">beers&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">as&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">beers2&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">on&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">beers&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">category&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">beers2&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">category&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">and&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">beers&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">alcohol&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">beers2&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">alcohol&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">where&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">beers2&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">category&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">is&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">null&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>Subquery vs JOIN：
可以看到 Subquery 在很多時候可以與 JOIN 互相替換，不論是在篩選所關聯的資料表、計算加總等，那究竟兩者誰比較好？
網路上普遍說 JOIN 比較好，因為 DBMS 執行時比較容易優化，且 Subquery 每次都會執行；
但在這本書中卻沒有明講，有時候 Subquery 涉及的欄位少、可以透過索引加速時 (ex. 基於索引的 COUNT) 反而有可能會更快，最後看來還是要實際跑跑看用 EXPLAIN 才知道&lt;/p>
&lt;/blockquote>
&lt;h3 id="窗口函式">窗口函式&lt;/h3>
&lt;p>早期 SQL 沒有相鄰列的概念，只能用 GROUP BY 做彙整，而窗口函式提供了以當前行計算的類似加總方法，例如在某條件下該行的加總(SUM)、排行 (RANK)、前一筆 (LEAD) 等，可以做到以往很難實踐的功能例如同月跨年的營收成長比例&lt;/p>
&lt;p>透過 partition by month 讓窗口依照 month 分類，同時用 year 當作排序，取 lag 也就是前一筆的 revenue 就可以得到「去年同月」的資料&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">select&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">year&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">month&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">revenue&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">lag&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">revenue&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">over&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">partition&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">by&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">month&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">order&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">by&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">year&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">asc&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">as&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">increase&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">revenues&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>常用的還有 ROW_NUMBER / ROW_NUMBER 是單純的行數， RANK 則是按照順序排名，兩者的概念很接近，只有在有重複數值時 RANK 會出現相同的排名；但是當 RANK 相同排名出現後會斷層，如果希望是連續排名可以用 DENSE_RANK&lt;/p>
&lt;p>另外還有 RANGE，可以取前後一個範圍區間做動態彙整&lt;/p>
&lt;h2 id="總結">總結&lt;/h2>
&lt;p>SQL 寫起來也頗有挑戰性，要想辦法兼顧簡潔與性能需要一定的時間學習，還有一些進階的議題如階層化顯示等就先略過&lt;/p></description></item><item><title>MySQL Replication 與 RDS</title><link>https://yuanchieh.page/posts/2021/2021-10-10-mysql-replication-%E8%88%87-rds/</link><pubDate>Sun, 10 Oct 2021 01:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2021/2021-10-10-mysql-replication-%E8%88%87-rds/</guid><description>&lt;p>公司目前主要資料庫是 MySQL，為了資料分析有開啟新的 Read Replica 避免影響到正式環境，因為一些分析工具 (Metabase) 的限制，所以與同事在思考 &lt;code>Read Replica 如果只同步指定的資料表，同時保留寫入其他資料表的彈性該有多好 ?!&lt;/code>，查了一下 RDS 發現這是可以的 &lt;a class="link" href="https://aws.amazon.com/premiumsupport/knowledge-center/rds-read-replica/" target="_blank" rel="noopener"
>How can I perform write operations to my Amazon RDS for MariaDB or MySQL DB instance read replica?&lt;/a>，當時覺得十分的衝突，為什麼 &amp;ldquo;Read&amp;rdquo; Replica 可以 Write，也借此回到源頭理解 MySQL Replication 設定與機制，才發現這一切都是很合乎情理的&lt;/p>
&lt;p>以下都是以 MySQL v5.7 為主&lt;/p>
&lt;h2 id="mysql-replication">MySQL Replication&lt;/h2>
&lt;p>閱讀過 &lt;a class="link" href="https://dev.mysql.com/doc/refman/5.7/en/replication.html" target="_blank" rel="noopener"
>Chapter 16 Replication&lt;/a>，簡單整理幾個重點&lt;/p>
&lt;ol>
&lt;li>Source DB / Replica DB 都要指定 server_id&lt;/li>
&lt;li>Source DB 必須開啟 binlog，有三種格式可以選，後續補充&lt;/li>
&lt;li>Replica DB 可以透過 &lt;code>replication_do_table&lt;/code> 指定資料表同步&lt;/li>
&lt;li>Replica DB 可以指定多個 Source DB&lt;/li>
&lt;li>GTIDs 建議開啟，主要是幫助 binlog 的每一個操作都打上 id，方便確認同步進度；不開啟則是用 file 同步，需要紀錄同步的檔案名稱與位置，相對複雜些&lt;/li>
&lt;/ol>
&lt;p>binlog 會紀錄在 master 上的所有操作，而 replica 很單純就是拿到 binlog 把同樣的操作套用在自己身上，用這個角度思考，就可以理解為什麼 replica 同時保留寫入的功能很正常，只要不影響 master binlog 上的操作即可&lt;/p>
&lt;h3 id="binlog-format">binlog format&lt;/h3>
&lt;h4 id="1-statement">1. statement&lt;/h4>
&lt;p>binlog 直接紀錄 master 上 SQL 語句，所以 binlog 本身非常容易閱讀，在做系統操作檢查時，也可以很清楚看到每一個 SQL 操作 (audit)，好處是相對資料量小、好閱讀；缺點是有些 statement 是 undeterminsitic，也就是在 replica 上重新執行會有不同的結果，例如 UUID() / USER() 等一系列操作，有趣的是 RAND() / NOW() 這些看起來就是會有問題的反而不會有問題&lt;/p>
&lt;h4 id="2-row">2. row&lt;/h4>
&lt;p>不紀錄每一個 SQL，而是把 SQL 會影響到的欄位以 Row 的格式紀錄，例如 UPDATE 更新了 10 筆欄位就紀錄 10 筆，好處是重新執行保證結果一致 / 壞處是資料量很大、格式不易閱讀需要工具 decode、沒辦法看到原始的 SQL&lt;/p>
&lt;h4 id="3-mixed">3. mixed&lt;/h4>
&lt;p>結合 statement / row 的優點，只有遇上 undeterministic 的 statement 才會用 row 紀錄，這也是 RDS 預設的格式&lt;/p>
&lt;h2 id="實驗">實驗&lt;/h2>
&lt;p>完整實驗可以參考我的 Repo &lt;a class="link" href="https://github.com/sj82516/play-with-mysql-replication" target="_blank" rel="noopener"
>play-with-mysql-replication&lt;/a>，主要驗證了&lt;/p>
&lt;ol>
&lt;li>不要在同步的資料庫新增資料，否則會終止同步&lt;/li>
&lt;li>在非同步的資料庫做任合操作都沒問題&lt;/li>
&lt;li>在同步的資料庫，增加 Index、增加新的欄位、&lt;code>UPDATE 已經同步的資料&lt;/code>都沒問題&lt;/li>
&lt;li>如果是修改同步的資料庫欄位格式，例如 varchar(255) =&amp;gt; varchar(200)，在不超過欄位尺寸下，statement 同步正常、row 不能同步&lt;/li>
&lt;/ol>
&lt;p>RDS 上行為類似，差別在預設就不能有 Multi Source 的功能&lt;/p>
&lt;h2 id="結語">結語&lt;/h2>
&lt;p>使用託管服務如 RDS 代為管理 MySQL 蠻有趣的，大幅降低了管理的麻煩，但如果有什麼功能面的問題，回歸工具本身去探索反而可以看得更全面；&lt;br>
不過 RDS 還有而外跟 Aurora 做結合，可以製作 Aurora Read Replica，不確定有沒有別的行為差異，之後有機會再來研究&lt;/p></description></item><item><title>AWS Aurora 架構研究以及與自駕 MySQL 的差異</title><link>https://yuanchieh.page/posts/2021/2021-07-02-aws-aurora-%E6%9E%B6%E6%A7%8B%E7%A0%94%E7%A9%B6%E4%BB%A5%E5%8F%8A%E8%88%87%E8%87%AA%E9%A7%95-mysql-%E7%9A%84%E5%B7%AE%E7%95%B0/</link><pubDate>Fri, 02 Jul 2021 01:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2021/2021-07-02-aws-aurora-%E6%9E%B6%E6%A7%8B%E7%A0%94%E7%A9%B6%E4%BB%A5%E5%8F%8A%E8%88%87%E8%87%AA%E9%A7%95-mysql-%E7%9A%84%E5%B7%AE%E7%95%B0/</guid><description>&lt;p>公司使用 MySQL，近日遇到一些讀取的瓶頸，有了使用 AWS Aurora 的討論，剛好上一週看到 &lt;a class="link" href="https://plaid.com/blog/exploring-performance-differences-between-amazon-aurora-and-vanilla-mysql" target="_blank" rel="noopener"
>Exploring performance differences between Amazon Aurora and vanilla MySQL&lt;/a> 才赫然發現 AWS Aurora 底層儲存架構會影響使用場景，跟預期的自駕 MySQL 搭配 Replica 有不同的效果&lt;/p>
&lt;p>以下這篇將探討&lt;/p>
&lt;ol>
&lt;li>MySQL 儲存的基本原理&lt;/li>
&lt;li>Aurora 的儲存架構&lt;/li>
&lt;/ol>
&lt;p>資料源自於&lt;/p>
&lt;ol>
&lt;li>&lt;a class="link" href="https://plaid.com/blog/exploring-performance-differences-between-amazon-aurora-and-vanilla-mysql" target="_blank" rel="noopener"
>Exploring performance differences between Amazon Aurora and vanilla MySQL&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.amazon.science/publications/amazon-aurora-design-considerations-for-high-throughput-cloud-native-relational-databases" target="_blank" rel="noopener"
>Amazon Aurora: Design Considerations for High Throughput Cloud-native Relational Databases&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="mysql-儲存的基本原理">MySQL 儲存的基本原理&lt;/h2>
&lt;p>關聯式資料庫最基本要保障 ACID，其中 Durability 是最基本的核心功能，保證寫入成功的資料不會因為系統 crash 等問題而遺失，在 MySQL 寫入的流程大概是&lt;/p>
&lt;ol>
&lt;li>將更新寫入 Redo Log buffer (WAL)，等待 commit 確定就刷新到硬碟保存紀錄避免遺失資料&lt;/li>
&lt;li>如果資料有被讀取到 memory 中，則更新 Page 內容並標記為 dirty&lt;/li>
&lt;li>背景運行的程序在 checkpoint 時機觸發時將 dirty page 與 redo log 的內容更新於硬碟上的 data file&lt;/li>
&lt;/ol>
&lt;p>其中有幾個目的&lt;/p>
&lt;ol>
&lt;li>減少 disk I/O 並保障連續性寫入：&lt;br>
如果每一筆資料進來就馬上更新硬碟上的儲存，這會拖垮 DB 效能，所以 MySQL 讀寫時是以 &lt;code>page&lt;/code> 為單位，如果發現更新的 page 在記憶體中會標記為 dirty page，後續再 checkpoint 統一更新到硬碟中&lt;/li>
&lt;li>Redo Log 避免系統 Crash 而資料遺失：&lt;br>
為了避免資料遺失，所以會先寫入 Redo Log，所以又稱作 Write Ahead Log 先寫入 log 再操作，Redo Log 是一個順序性持續寫入的 Log，所以寫入效能比隨機性更新還要好，當系統 crash 後，會來檢查 Redo Log 中是否存在沒有更新到資料庫硬碟的資料；&lt;br>
具體寫入硬碟時機看 &lt;code>innodb_flush_log_at_trx_commit&lt;/code>，預設 1 為每一筆都及時寫入硬碟中&lt;/li>
&lt;li>定期同步到硬碟中：&lt;br>
每個操作都有先寫入 Redo Log，但這是為了災難復原而用，資料庫的資料會以 Page 形式儲存於硬碟中，所以定期到 checkpoint 會把 dirty page 從記憶體更新到硬碟中&lt;/li>
&lt;/ol>
&lt;h3 id="binlog">Binlog&lt;/h3>
&lt;p>Binlog 適用於系統異地恢復/建立 Replica，Binlog 不像 Redo Log 會保存所有的操作，只會保存對於資料有異動的行為，例如 update / delete 等&lt;/p>
&lt;p>寫入時機在 commit 完成時，會在 commit 結束前 / lock 釋放前寫入硬碟，避免資料異常，具體的寫入頻率要看 &lt;code>sync_binlog&lt;/code>，預設為 1 代表每一筆 commit 就寫一次，可以設定為 n 代表 n 筆 commit 才寫入但就會有遺失資料的風險&lt;/p>
&lt;h3 id="undo-log">Undo log&lt;/h3>
&lt;p>如果 isolation level 開到 repeatable read，則 MySQL 採用 MVCC，讓每個 transaction 只會讀取到自己 transaction 開始前的最新資料，而不被並行的 transaction 所影響&lt;/p>
&lt;p>之所以需要 undo log 是當 transaction rollback 時，需要知道自己要回滾的狀態，所以 undo log 必須保存到 transaction 執行完畢才可以刪除，長度會是 &lt;code>執行最久的 transaction&lt;/code>&lt;/p>
&lt;h2 id="aurora-架構">Aurora 架構&lt;/h2>
&lt;p>Aurora 是 AWS 基於雲端建構的關聯式資料庫服務，兼容於 MySQL / PostgreSQL，主要想解決幾個問題&lt;/p>
&lt;ol>
&lt;li>容錯能力：&lt;br>
硬碟可能會壞 / 主機可能會有問題 / 甚至 Data Center 都會出意外，尤其是在雲端分散式系統中，機器數增加帶來更高的出錯機會，Aurora 每一個 replica 都會對應 3 個 AZ 各 2 個 node 總共 6 個 node 儲存資料，大幅增加容錯能力&lt;/li>
&lt;li>擴展性：&lt;br>
傳統的資料庫架設於單一主機上，讀取會受限於 Disk I/O 的貧頸，Aurora 將 Compute / Storage 分離，可以針對需求獨立升級，並增加跨區域、跨 AZ 的 Read Replica&lt;/li>
&lt;/ol>
&lt;p>但有這麼多好處卻不用受到太多的性能影響，聽起來有點美好的不切實際，例如備份到多個儲存 node 就需要擔心資料一致性/效能的問題，除了原本的 Disk I/O 又多了一段 Network I/O，Aurora 在不同的地方作出了對應的調整&lt;/p>
&lt;h2 id="2-durability-at-scale">2. DURABILITY AT SCALE&lt;/h2>
&lt;h3 id="21-replication-and-correlated-failures">2.1 Replication and Correlated Failures&lt;/h3>
&lt;p>Aurora 跟很多分散式儲存的服務很像，採用多數讀寫的機制，只要確保&lt;/p>
&lt;ol>
&lt;li>Vw + Vr &amp;gt; V&lt;/li>
&lt;li>Vw &amp;gt; V / 2&lt;/li>
&lt;/ol>
&lt;p>V 代表節點數量，如果 Vw 寫入節點數量超過 1/2 節點都成功才成功，且 Vr 讀取數量是讀取多數則&lt;/p>
&lt;p>最基本的數量會取 3，則 Vw / Vr 只要有 2 個 node 存活則可以繼續運作，容錯率是 33%，但文件中說到 Aurora 選擇 6 個 node分散在 3 個 AZ，這樣可以預防一個 AZ 以及一個額外錯誤下讀取還不會中斷&lt;/p>
&lt;h3 id="22-segmented-storage">2.2 Segmented Storage&lt;/h3>
&lt;p>為了降低同時機器故障而導致破壞多數的可能，要盡可能降低 MTTF(平均錯誤時間)與 MTTR(平均復原時間)，Aurora 以 10GB 當作一個區段，產生 6 個備份並分散到 3 個 AZ 稱之為 PG(Protection Group)，一個 Storage Volume 就是由多個 PG 所組成，實體上就是由 EC2 加上一群分割的 SSD 組成，最大可支援到 64TB&lt;/p>
&lt;p>Segment 是最小獨立單位 (也就是會壞掉是獨立一個 Segment 壞)，AWS 會負責持續監控與復原，目前復原一個 Segment 約 10秒鐘 (網路帶寬為 10Gbps 下)，所以出現破壞多數的場景：兩個 node 在 10秒鐘內同時壞掉且一個 AZ 掛掉又不包含同時壞掉的 node 機率就微乎其微&lt;/p>
&lt;blockquote>
&lt;p>小結：這邊談的是 AWS 在持久性上的優化，將最小的儲存單位定在 10GB，讓復原速度變快 / 產生 6 組備份增加容錯&lt;/p>
&lt;/blockquote>
&lt;h2 id="the-log-is-the-database">THE LOG IS THE DATABASE&lt;/h2>
&lt;h3 id="31-the-burden-of-amplified-writes">3.1 The Burden of Amplified Writes&lt;/h3>
&lt;p>&lt;img src="https://yuanchieh.page/post/2021/img/0702/mysql-old.png"
loading="lazy"
>
先看第一版 Aurora 嘗試的架構 - 傳統的鏡像同步架構，一台 Primary Instance 負責寫入儲存於 EBS 並同時備份到另一份 EBS 中，有一台 Replica Instance 同步 Primary 的寫入並儲存於兩份 EBS 中，可以看到一個 MySQL 寫入最多會觸發五個 I/O binlog / redo log / frm(metadata) / double-write，要等到全部寫入結束才算是操作成功，這會拉長回應時間，更糟糕的是圖片中步驟 1,3,5 (為什麼有5?) 是同步且順序寫入&lt;/p>
&lt;h3 id="32-offloading-redo-processing-to-storage">3.2 Offloading Redo Processing to Storage&lt;/h3>
&lt;p>&lt;img src="https://yuanchieh.page/post/2021/img/0702/aurora.png"
loading="lazy"
>
相反的 Aurora 透過 Redo Log 同步，讓 Storage level 負責 Redo Log 寫入與更新 Data file，同時分送給 Replica 更新記憶體中 page 的資料；&lt;br>
不像過往 MySQL 需要在 Checkpoint / background / cache 空間不足時刷新資料到硬碟中，全部由 Storage Service 負責，大幅降低了 Network I/O&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/2021/img/0702/perf.png"
loading="lazy"
>
從 Benchmark 可以看到，每筆 Transaction 所需的 I/O 從 7.4 變成 0.9，完成的 Transaction 數也提升了 35 倍&lt;/p>
&lt;p>這同時也降低了復原的時間，傳統 DB 需要從 Redo Log 上一次的 checkpoint 開始逐條執行，但 Aurora 的復原是從 Storage level 向其他備份拉 Segment，復原速度可以在一分鐘以內&lt;/p>
&lt;h3 id="33-storage-service-design-points">3.3 Storage Service Design Points&lt;/h3>
&lt;p>Storage Service 核心設計要降低寫入請求的延遲，所以把大部分的儲存工作都移至背景執行，尤其是更好地利用 CPU 去換取 Disk 寫入時間，例如舊的 Page 要垃圾回收可以在背景用 CPU 執行而不要延遲前景在處理寫入請求，所以 Aurora 的背景運作不會影響前景，不同於傳統 DB 如果背景在 Checkpoint 刷新硬碟則會造成前景寫入的延遲&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/2021/img/0702/storage.png"
loading="lazy"
>
Storage Service 收到請求會執行&lt;/p>
&lt;ol>
&lt;li>放入 Memory 中&lt;/li>
&lt;li>寫入硬碟，寫入請求成功&lt;/li>
&lt;li>排序，並確認寫入紀錄是否有遺漏&lt;/li>
&lt;li>透過 gossip 跟其他節點要遺漏的紀錄&lt;/li>
&lt;li>更新到 page 中&lt;/li>
&lt;li>定期同步到 s3&lt;/li>
&lt;li>定期清除舊的 page&lt;/li>
&lt;li>定期檢查 page 的驗證碼&lt;/li>
&lt;/ol>
&lt;p>除了步驟 1, 2 會影響前景寫入，其餘步驟都可以非同步且於背景執行&lt;/p>
&lt;h2 id="4-the-log-marches-forward">4. THE LOG MARCHES FORWARD&lt;/h2>
&lt;p>接著要確保 rumtime、replica 都保持一致性，究竟是如何不使用昂貴的 2pc 卻又能保持一致性&lt;/p>
&lt;h3 id="41-solution-sketch-asynchronous-processing">4.1 Solution sketch: Asynchronous Processing&lt;/h3>
&lt;p>前面提過 Aurora 是透過 redo log 同步，每一筆 log 都有 持續遞增的 LCN (Log Sequence Number)，因為寫入成功只要多數的 node 同意即可，所以有些 node 可能會缺少幾個 log，可以透過 LCN 去跟其他 node 索取遺失的 log&lt;/p>
&lt;p>考量到多 transaction 的情況，每個 transaction 執行順序有所不同，在過程會陸續把 commit 送到 storage service 儲存 (到 complete) 階段，但如果發生了系統故障時，重新恢復後需要把沒有 commit 的 transaction 都 rollback，假設 DB 目前最高完成寫入的 LCN 稱為 VCL (Volume Complete LSN))，在復原中任何 LCN 高於 VCL 都會被遺棄，因為代表沒有被 complete&lt;/p>
&lt;p>更進階這些高於 VCL 的 LCN 會被標記成 CPL (Consistency Point LSNs)，接著定義出 VDL 為那些在低於 VCL 中最高的 CPL，例如 CPL 有 900,1000, 1100 但是 VCL 為 1007，則 VDL 為 1000，這代表 storage service complete 到 1007 但是持久化儲存到 1000&lt;/p>
&lt;blockquote>
&lt;p>這一整段沒有到非常理解，待之後慢慢思考&lt;/p>
&lt;/blockquote>
&lt;h3 id="42-normal-operation">4.2 Normal Operation&lt;/h3>
&lt;p>Aurora 會同時處理大量的寫入請求，每一筆 redo log 都會產生一個大於 VDL(被持久化保存的 LCN)的 LCN，但為了不要讓 LCN 的遞增遠大於 Storage Service 所能保存的速度，LSN Allocation Limit (LAL) 預設為 10萬筆，意即 Aurora 最多並行 10 萬筆進行中的 transaction 避免寫入速度跟不上&lt;/p>
&lt;p>每一個 PG 中的每一個 Segment 只會保存部分的 redo log，但會有一個 link 指向上一份 log 所在的 PG，這用來追蹤目前所完成最大的 LCN，並且在與其他 node gossip 時可以知道缺漏的 log&lt;/p>
&lt;h4 id="read">Read&lt;/h4>
&lt;p>如同大多數的 DB，Aurora 會在 buffer 中 cache page ，如果 cache miss 則從 disk 讀取，此時傳統 DB 會優先移除 dirty page 並寫回硬碟中；但 Aurora 並不需要刷新 dirty page (因為 storage service 已經獨立更新)，相反的是把 page LCN 大於等於 VDL 的 page 移除並讀取最新被持久化的page&lt;/p>
&lt;p>前面提到 Aurora 透過多數讀取確保一致性，但大多數時機並不需要，Aurora 會在 Page 讀取時紀錄 Page LCN 當作 read point，接著只要讀取的 storage node VDL 確定在 read point 之後，就代表該 node 有該 page 完整最新的資料，而且因為每個 segment 都有紀錄 LCN 與 link，所以能很快知道資料要到哪一個 segment 讀取&lt;/p>
&lt;p>同時每個 PG 會維護一份目前最低的 Protection Group Min Read Point LSN (PGMRPL)，這代表低於此數字的 LCN 的 page 都不會再被讀取，這樣垃圾回收就能移除過舊的 log&lt;/p>
&lt;h3 id="replica">Replica&lt;/h3>
&lt;p>一個 write node 可以搭配 16 個 read replica 並共用相同的 storage service，writer 會把 redo log 也同步給 reader，如果 log 有在 cache 中則更新，否則就直接丟棄&lt;/p>
&lt;p>因為 reader 跟 storage service 的 redo log 更新是錯開，所以 reader 在更新 log 時要確保 LCN 是小於等於 VDL / 如果 log 是 mini-transaction 的一部分則更新，確保跟所有的 database 看到相同內容&lt;/p>
&lt;p>預期 reader 的延遲會在 20ms 以內&lt;/p>
&lt;h3 id="43-recovery">4.3 Recovery&lt;/h3>
&lt;p>傳統 DB 在災難復原時，會去讀取 redo log 中還沒被 checkpoint 執行的 log，搭配 undo log 將失敗的 transaction rollback，但這執行過程蠻花時間，而 Aurora 沒有這方面困擾&lt;/p>
&lt;p>首先會檢查每一個 PG，找出讀取多數中可以確保已經完成的寫入多數紀錄 VDL，高於 VDL 的 LCN 全部捨棄，接著一樣需要透過 undo log 去 rollback，整個過程約 10秒以內&lt;/p>
&lt;h2 id="5-putting-it-all-together">5. PUTTING IT ALL TOGETHER&lt;/h2>
&lt;p>接著看完整的架構圖
&lt;img src="https://yuanchieh.page/post/2021/img/0702/architech.png"
loading="lazy"
>
社群版的 MySQL InnoDB 引擎在寫入操作時會修改 buffer 中的 page 與寫入 WAL redo log buffer，等到 commit 時再把 redo log buffer 寫入硬碟中；而被修改的 page 要則透過 double-write buffer 避免只更新部分 page，page 寫入會發生在背景 / checkpoint / cache 移除時；
此外還有一些 B+Tree 操作與相關的 mini trasaction (MTR) 如拆分、合併 B+Tree page 需要是原子性操作&lt;/p>
&lt;p>在 Aurora 版本中，redo log record 就代表每一個 MTR 操作，最新的一筆 log 被標記成 consistency point；Aurora 提供相同的 isolation level&lt;/p>
&lt;p>其餘就是架構的說明，以及各方面的性能表現，就不贅述了&lt;/p>
&lt;hr>
&lt;h2 id="aurora-對比-mysql-有什麼隱憂">Aurora 對比 MySQL 有什麼隱憂&lt;/h2>
&lt;p>因為 Aurora 如果 primary 跟 read replica 在同一個 region 下，則會共用 storage service，這也就代表 undo log 會是同一份，如果今天 read replica 有一筆執行非常久的 transaction，則 undo log 也會跟變大導致 primary 效能下降&lt;/p>
&lt;p>這個在傳統 MySQL 不會發生，因為如 3.1 提到 MySQL 是透過 binlog 同步各自的 MySQL 維護各自的 redo log / undo log 所以 read replica 不會有任何影響 primary 的時候&lt;/p>
&lt;p>最後作者指出有幾個解法&lt;/p>
&lt;ol>
&lt;li>調整 read replica 預設 isolation level 為 read commited，就不會用到 undo log(需注意預設為 repeatable read)&lt;/li>
&lt;li>Aurora 選擇 binlog relica，就跟傳統的 mysql 一樣&lt;/li>
&lt;li>拿在 S3 的備份資料，用其他大數據工具分析&lt;/li>
&lt;li>Aurora 支援 clone，備份一組新的設定&lt;/li>
&lt;/ol>
&lt;h2 id="結語">結語&lt;/h2>
&lt;p>翻整個 Aurora 架構有很多生硬的地方沒有完全搞懂，但是看到這種解 bug 追根究底到底層架構還是覺得很過癮，之後會持續的優化文章內容，如果有哪裡有建議跟指教再麻煩留言～&lt;/p></description></item><item><title>MySQL Deadlock 問題排查與處理</title><link>https://yuanchieh.page/posts/2020/2020-12-26_mysql-deadlock-%E5%95%8F%E9%A1%8C%E6%8E%92%E6%9F%A5%E8%88%87%E8%99%95%E7%90%86/</link><pubDate>Sat, 26 Dec 2020 08:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2020/2020-12-26_mysql-deadlock-%E5%95%8F%E9%A1%8C%E6%8E%92%E6%9F%A5%E8%88%87%E8%99%95%E7%90%86/</guid><description>&lt;p>寫了一個簡單的購物流程 SQL，在一個 transaction 中執行&lt;/p>
&lt;ol>
&lt;li>讀取 product 資訊：&lt;code>select * from product where id = 1&lt;/code>&lt;/li>
&lt;li>寫入新訂單 order 狀態: &lt;code>insert into orders (product_id) values (1)&lt;/code>&lt;/li>
&lt;li>更新 product 販售狀態：&lt;code>update product set sold=1 where id = 1&lt;/code>&lt;br>
其中 order table 的 product_id 是引用 product table 的 id 當做 foriegn key，並在併發的情況下執行，開始偶然遇到 Deadlock&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">Error&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">update&lt;/span> &lt;span class="err">`&lt;/span>&lt;span class="n">products&lt;/span>&lt;span class="err">`&lt;/span> &lt;span class="nb">set&lt;/span> &lt;span class="err">`&lt;/span>&lt;span class="n">sold&lt;/span>&lt;span class="err">`&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">34&lt;/span> &lt;span class="n">where&lt;/span> &lt;span class="err">`&lt;/span>&lt;span class="nb">id&lt;/span>&lt;span class="err">`&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;919&amp;#39;&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">Deadlock&lt;/span> &lt;span class="n">found&lt;/span> &lt;span class="n">when&lt;/span> &lt;span class="n">trying&lt;/span> &lt;span class="n">to&lt;/span> &lt;span class="n">get&lt;/span> &lt;span class="n">lock&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="k">try&lt;/span> &lt;span class="n">restarting&lt;/span> &lt;span class="n">transaction&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>當下覺得奇怪，第一印象中 Deadlock 只發生在兩個 Transaction 互相所需的欄位而無法釋放，如&lt;/p>
&lt;ol>
&lt;li>T1: lock(r1) , wait(r2)&lt;/li>
&lt;li>T2: lock(r2), wait(r1)&lt;br>
但明明我就一種 SQL 併發執行，怎麼也會有 Deadlock&lt;/li>
&lt;/ol>
&lt;p>以下開始排查原因&lt;/p>
&lt;h2 id="mysql-deadlock-說明">MySQL Deadlock 說明&lt;/h2>
&lt;p>讓我們來看一下官方文件 &lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/innodb-deadlocks.html" target="_blank" rel="noopener"
>15.7.5 Deadlocks in InnoDB&lt;/a>&lt;/p>
&lt;p>Deadlock 主要是多個 Transaction 手上握有對方需要的資源，在等待資源釋放的同時卻也不會釋放手上的資源，常發生在使用 update 卻順序剛好相反&lt;br>
如果 Deadlock 數量很少不太需要擔心，應用程式記得 retry 就好，但如果發生很頻繁就要檢查 SQL 的狀況&lt;/p>
&lt;p>為了盡量減少 Deadlock 發生，可以檢查以下方式&lt;/p>
&lt;ol>
&lt;li>盡可能減少 Update / Delete 在單一 Transaction 中的數量&lt;/li>
&lt;li>Lock 時請依照同樣的順序 (例如 select &amp;hellip; for update)&lt;/li>
&lt;li>降低 Lock 的層級，避免 lock tables 的操作&lt;/li>
&lt;li>警慎選擇 index，因為過多的 index 可能會造成 deadlock，後續會再展開描述
&lt;blockquote>
&lt;p>InnoDB uses automatic row-level locking. You can get &lt;code>deadlocks even in the case of transactions that just insert or delete a single row&lt;/code>. That is because these operations are not really “atomic”; they automatically set &lt;code>locks on the (possibly several) index records&lt;/code> of the row inserted or deleted.&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>考慮降低 isolation level，高層級的 &lt;code>isolation level 會去改變 read 的操作&lt;/code>，例如 MySQL 中 &lt;code>serializable 其實就是隱式把所有 select 都加上 lock for share&lt;/code>，引自於官方文件 &lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html" target="_blank" rel="noopener"
>15.7.2.1 Transaction Isolation Levels&lt;/a>
&lt;blockquote>
&lt;p>This level is like REPEATABLE READ, but InnoDB implicitly converts all plain SELECT statements to SELECT &amp;hellip; FOR SHARE if autocommit is disabled.&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;/ol>
&lt;p>Deadlock detection 預設是開啟，但如果在高流量下會有效能的影響，如果預期 Deadlock 狀況不多可以改透過 &lt;code>innodb_deadlock_detect&lt;/code> 選項關閉，用 &lt;code>innodb_lock_wait_timeout&lt;/code> 一直等不到 lock 發生 timeout 而觸發 rollback 取代&lt;/p>
&lt;p>MySQL 可以透過 SQL 指令 &lt;code>&amp;gt; SHOW ENGINE INNODB STATUS&lt;/code> 看最後一筆發生 Deadlock 的原因，或是開啟 &lt;code>innodb_print_all_deadlocks&lt;/code> 把每一次 Deadlock 原因都輸出到 error log 中&lt;br>
開啟設定的 SQL 為 &lt;code>&amp;gt; SET GLOBAL innodb_print_all_deadlocks=ON;&lt;/code>&lt;/p>
&lt;h2 id="具體的-deadlock-log">具體的 Deadlock log&lt;/h2>
&lt;p>當在應用程式發現 deadlock 錯誤後，回到 MySQL 使用指令查看，得到以下原始 log&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt"> 10
&lt;/span>&lt;span class="lnt"> 11
&lt;/span>&lt;span class="lnt"> 12
&lt;/span>&lt;span class="lnt"> 13
&lt;/span>&lt;span class="lnt"> 14
&lt;/span>&lt;span class="lnt"> 15
&lt;/span>&lt;span class="lnt"> 16
&lt;/span>&lt;span class="lnt"> 17
&lt;/span>&lt;span class="lnt"> 18
&lt;/span>&lt;span class="lnt"> 19
&lt;/span>&lt;span class="lnt"> 20
&lt;/span>&lt;span class="lnt"> 21
&lt;/span>&lt;span class="lnt"> 22
&lt;/span>&lt;span class="lnt"> 23
&lt;/span>&lt;span class="lnt"> 24
&lt;/span>&lt;span class="lnt"> 25
&lt;/span>&lt;span class="lnt"> 26
&lt;/span>&lt;span class="lnt"> 27
&lt;/span>&lt;span class="lnt"> 28
&lt;/span>&lt;span class="lnt"> 29
&lt;/span>&lt;span class="lnt"> 30
&lt;/span>&lt;span class="lnt"> 31
&lt;/span>&lt;span class="lnt"> 32
&lt;/span>&lt;span class="lnt"> 33
&lt;/span>&lt;span class="lnt"> 34
&lt;/span>&lt;span class="lnt"> 35
&lt;/span>&lt;span class="lnt"> 36
&lt;/span>&lt;span class="lnt"> 37
&lt;/span>&lt;span class="lnt"> 38
&lt;/span>&lt;span class="lnt"> 39
&lt;/span>&lt;span class="lnt"> 40
&lt;/span>&lt;span class="lnt"> 41
&lt;/span>&lt;span class="lnt"> 42
&lt;/span>&lt;span class="lnt"> 43
&lt;/span>&lt;span class="lnt"> 44
&lt;/span>&lt;span class="lnt"> 45
&lt;/span>&lt;span class="lnt"> 46
&lt;/span>&lt;span class="lnt"> 47
&lt;/span>&lt;span class="lnt"> 48
&lt;/span>&lt;span class="lnt"> 49
&lt;/span>&lt;span class="lnt"> 50
&lt;/span>&lt;span class="lnt"> 51
&lt;/span>&lt;span class="lnt"> 52
&lt;/span>&lt;span class="lnt"> 53
&lt;/span>&lt;span class="lnt"> 54
&lt;/span>&lt;span class="lnt"> 55
&lt;/span>&lt;span class="lnt"> 56
&lt;/span>&lt;span class="lnt"> 57
&lt;/span>&lt;span class="lnt"> 58
&lt;/span>&lt;span class="lnt"> 59
&lt;/span>&lt;span class="lnt"> 60
&lt;/span>&lt;span class="lnt"> 61
&lt;/span>&lt;span class="lnt"> 62
&lt;/span>&lt;span class="lnt"> 63
&lt;/span>&lt;span class="lnt"> 64
&lt;/span>&lt;span class="lnt"> 65
&lt;/span>&lt;span class="lnt"> 66
&lt;/span>&lt;span class="lnt"> 67
&lt;/span>&lt;span class="lnt"> 68
&lt;/span>&lt;span class="lnt"> 69
&lt;/span>&lt;span class="lnt"> 70
&lt;/span>&lt;span class="lnt"> 71
&lt;/span>&lt;span class="lnt"> 72
&lt;/span>&lt;span class="lnt"> 73
&lt;/span>&lt;span class="lnt"> 74
&lt;/span>&lt;span class="lnt"> 75
&lt;/span>&lt;span class="lnt"> 76
&lt;/span>&lt;span class="lnt"> 77
&lt;/span>&lt;span class="lnt"> 78
&lt;/span>&lt;span class="lnt"> 79
&lt;/span>&lt;span class="lnt"> 80
&lt;/span>&lt;span class="lnt"> 81
&lt;/span>&lt;span class="lnt"> 82
&lt;/span>&lt;span class="lnt"> 83
&lt;/span>&lt;span class="lnt"> 84
&lt;/span>&lt;span class="lnt"> 85
&lt;/span>&lt;span class="lnt"> 86
&lt;/span>&lt;span class="lnt"> 87
&lt;/span>&lt;span class="lnt"> 88
&lt;/span>&lt;span class="lnt"> 89
&lt;/span>&lt;span class="lnt"> 90
&lt;/span>&lt;span class="lnt"> 91
&lt;/span>&lt;span class="lnt"> 92
&lt;/span>&lt;span class="lnt"> 93
&lt;/span>&lt;span class="lnt"> 94
&lt;/span>&lt;span class="lnt"> 95
&lt;/span>&lt;span class="lnt"> 96
&lt;/span>&lt;span class="lnt"> 97
&lt;/span>&lt;span class="lnt"> 98
&lt;/span>&lt;span class="lnt"> 99
&lt;/span>&lt;span class="lnt">100
&lt;/span>&lt;span class="lnt">101
&lt;/span>&lt;span class="lnt">102
&lt;/span>&lt;span class="lnt">103
&lt;/span>&lt;span class="lnt">104
&lt;/span>&lt;span class="lnt">105
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-md" data-lang="md">&lt;span class="line">&lt;span class="cl">=====================================
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2020-12-26 00:10:16 0x7f9668490700 INNODB MONITOR OUTPUT
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">=====================================
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Per second averages calculated from the last 29 seconds
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">-----------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">BACKGROUND THREAD
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">-----------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">....
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">----------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SEMAPHORES
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">----------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">....
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">------------------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LATEST DETECTED DEADLOCK
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">------------------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2020-12-26 00:05:14 0x7f9657cf9700
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* (1) TRANSACTION:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">TRANSACTION 14048, ACTIVE 1 sec starting index read
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mysql tables in use 1, locked 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LOCK WAIT 11 lock struct(s), heap size 1136, 6 row lock(s), undo log entries 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">MySQL thread id 54, OS thread handle 140283242518272, query id 45840 172.22.0.1 api-server updating
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">update &lt;span class="sb">`products`&lt;/span> set &lt;span class="sb">`sold`&lt;/span> = 32 where &lt;span class="sb">`id`&lt;/span> = &amp;#39;919&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* (1) HOLDS THE LOCK(S):
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RECORD LOCKS space id 3 page no 8 n bits 336 index PRIMARY of table &lt;span class="sb">`online-transaction`&lt;/span>.`products` trx id 14048 lock mode S locks rec but not gap
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Record lock, heap no 259 PHYSICAL RECORD: n_fields 7; compact format; info bits 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0: len 4; hex 00000397; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 1: len 6; hex 0000000036d7; asc 6 ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2: len 7; hex 010000013f1e26; asc ? &lt;span class="ni">&amp;amp;;&lt;/span>;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 3: len 21; hex 50726163746963616c204672657368204d6f757365; asc Practical Fresh Mouse;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 4: len 4; hex 800000b1; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 5: len 4; hex 800000fe; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 6: len 4; hex 80000020; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* (1) WAITING FOR THIS LOCK TO BE GRANTED:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RECORD LOCKS space id 3 page no 8 n bits 336 index PRIMARY of table &lt;span class="sb">`online-transaction`&lt;/span>.`products` trx id 14048 lock_mode X locks rec but not gap waiting
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Record lock, heap no 259 PHYSICAL RECORD: n_fields 7; compact format; info bits 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0: len 4; hex 00000397; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 1: len 6; hex 0000000036d7; asc 6 ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2: len 7; hex 010000013f1e26; asc ? &lt;span class="ni">&amp;amp;;&lt;/span>;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 3: len 21; hex 50726163746963616c204672657368204d6f757365; asc Practical Fresh Mouse;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 4: len 4; hex 800000b1; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 5: len 4; hex 800000fe; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 6: len 4; hex 80000020; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* (2) TRANSACTION:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">TRANSACTION 14052, ACTIVE 1 sec starting index read
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mysql tables in use 1, locked 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LOCK WAIT 11 lock struct(s), heap size 1136, 6 row lock(s), undo log entries 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">MySQL thread id 57, OS thread handle 140283970258688, query id 45841 172.22.0.1 api-server updating
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">update &lt;span class="sb">`products`&lt;/span> set &lt;span class="sb">`sold`&lt;/span> = 34 where &lt;span class="sb">`id`&lt;/span> = &amp;#39;919&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* (2) HOLDS THE LOCK(S):
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RECORD LOCKS space id 3 page no 8 n bits 336 index PRIMARY of table &lt;span class="sb">`online-transaction`&lt;/span>.`products` trx id 14052 lock mode S locks rec but not gap
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Record lock, heap no 259 PHYSICAL RECORD: n_fields 7; compact format; info bits 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0: len 4; hex 00000397; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 1: len 6; hex 0000000036d7; asc 6 ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2: len 7; hex 010000013f1e26; asc ? &lt;span class="ni">&amp;amp;;&lt;/span>;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 3: len 21; hex 50726163746963616c204672657368204d6f757365; asc Practical Fresh Mouse;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 4: len 4; hex 800000b1; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 5: len 4; hex 800000fe; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 6: len 4; hex 80000020; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* (2) WAITING FOR THIS LOCK TO BE GRANTED:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RECORD LOCKS space id 3 page no 8 n bits 336 index PRIMARY of table &lt;span class="sb">`online-transaction`&lt;/span>.`products` trx id 14052 lock_mode X locks rec but not gap waiting
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Record lock, heap no 259 PHYSICAL RECORD: n_fields 7; compact format; info bits 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0: len 4; hex 00000397; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 1: len 6; hex 0000000036d7; asc 6 ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2: len 7; hex 010000013f1e26; asc ? &lt;span class="ni">&amp;amp;;&lt;/span>;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 3: len 21; hex 50726163746963616c204672657368204d6f757365; asc Practical Fresh Mouse;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 4: len 4; hex 800000b1; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 5: len 4; hex 800000fe; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 6: len 4; hex 80000020; asc ;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="ge">**&lt;/span>* WE ROLL BACK TRANSACTION (2)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">TRANSACTIONS
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.....
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">--------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FILE I/O
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">--------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.....
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">-------------------------------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">INSERT BUFFER AND ADAPTIVE HASH INDEX
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">-------------------------------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.....
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">---
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LOG
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">---
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.....
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">----------------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">BUFFER POOL AND MEMORY
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">----------------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.....
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">--------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ROW OPERATIONS
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">--------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.....
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">----------------------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">END OF INNODB MONITOR OUTPUT
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">============================
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>挑出重點來看&lt;/p>
&lt;ol>
&lt;li>&lt;code>LATEST DETECTED DEADLOCK&lt;/code> 以下顯示最後一次發生的 Deadlock，有表述互相死鎖的兩筆 Transaction &lt;code>*** (1) TRANSACTION:&lt;/code> 與 &lt;code>*** (2) TRANSACTION:&lt;/code>&lt;/li>
&lt;li>接著看到兩筆 Transaction 手上握有的 Lock，看得出來他們都有同一行 product row 的 lock mode S locks&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-md" data-lang="md">&lt;span class="line">&lt;span class="cl">RECORD LOCKS space id 3 page no 8 n bits 336 index PRIMARY of table &lt;span class="sb">`online-transaction`&lt;/span>.`products` trx id 14052 lock mode S locks rec but not gap
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="3">
&lt;li>接著他們在等待的鎖為&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-md" data-lang="md">&lt;span class="line">&lt;span class="cl">&lt;span class="sb">`online-transaction`&lt;/span>.`products` trx id 14052 lock_mode X locks rec but not gap waiting
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>答案就此揭曉，因為兩個 Transaction 手上都握有 share lock，如果要取得 exclusive lock 則對方必須先釋放 share lock，因此造成 Deadlock，最終看到 Transaction 2 被 rollback 了&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">*** WE ROLL BACK TRANSACTION &lt;span class="o">(&lt;/span>2&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Debug 資訊乍看很多，但仔細看還蠻好理解的&lt;/p>
&lt;h3 id="找出問題根源">找出問題根源&lt;/h3>
&lt;p>知道是因為 shared lock 導致後面的 exclusive lock 死鎖的原因，回頭爬指令看哪裡有問題&lt;/p>
&lt;p>首先定位到 select from，根據官方文件，除非 isolation 是 serializable，否則一般的 select from 是沒有 lock 的，出處 &lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/innodb-consistent-read.html" target="_blank" rel="noopener"
>15.7.2.3 Consistent Nonlocking Reads&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Consistent read is the default mode in which InnoDB processes SELECT statements in READ COMMITTED and REPEATABLE READ isolation levels. &lt;code>A consistent read does not set any locks&lt;/code> on the tables it accesses, and therefore other sessions are free to modify those tables at the same time a consistent read is being performed on the table.&lt;/p>
&lt;/blockquote>
&lt;p>既然不是 select 造成，嫌疑犯就變成 insert order 了，orders table 中的 product_id 是引用 product table 中的 id 當作 foreign key，果然找到相關的描述 &lt;a class="link" href="https://dev.mysql.com/doc/refman/5.7/en/innodb-locks-set.html" target="_blank" rel="noopener"
>14.7.3 Locks Set by Different SQL Statements in InnoDB&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>&lt;code>If a FOREIGN KEY constraint is defined on a table, any insert, update, or delete that requires the constraint condition to be checked sets shared record-level locks&lt;/code> on the records that it looks at to check the constraint. InnoDB also sets these locks in the case where the constraint fails.&lt;/p>
&lt;/blockquote>
&lt;p>真相大白&lt;/p>
&lt;h3 id="如何解決">如何解決&lt;/h3>
&lt;p>在 SQL 最一開始，因為篤定會改變 product 欄位，直接使用 &lt;code>select for update&lt;/code> 用 exclusive lock 鎖住，就解決問題了&lt;br>
需注意設定成 &lt;code>serializable&lt;/code> 還是有機會發生 Deadlock 喔，因為在 MySQL 中只是追加 select from 的鎖，而不是真的像 redis 一次只順序執行一道指令喔&lt;/p>
&lt;h2 id="補充資料---關於-mysql-lock">補充資料 - 關於 MySQL Lock&lt;/h2>
&lt;p>&lt;a class="link" href="https://www.aneasystone.com/archives/2018/04/solving-dead-locks-four.html" target="_blank" rel="noopener"
>解决死锁之路（终结篇） - 再见死锁&lt;/a> 強力推薦這篇文章，後來與同事在工作上排查死鎖，發現 update 單筆資料竟然也有死鎖的狀況，才知道 lock 需要鎖定對應的 Index 並且在沒有命中時會使用區間鎖 (如果 isolation level 在 Repeatable Read 以上)，還是有機會造成死鎖&lt;/p>
&lt;p>透過上述的參考資料，並重新翻閱 MySQL 文件，整理了另一篇 &lt;a class="link" href="https://yuanchieh.page/post/2022/2022-04-25-mysqllock-%E8%88%87-index-%E9%97%9C%E4%BF%82%E5%92%8C-deadlock-%E5%88%86%E6%9E%90/" target="_blank" rel="noopener"
>【MySQL】Lock 與 Index 關係和 Deadlock 分析&lt;/a>&lt;/p></description></item><item><title>Raft 演算法介紹與《In Search of an Understandable Consensus Algorithm》摘要</title><link>https://yuanchieh.page/posts/2020/2020-11-03-raft-%E6%BC%94%E7%AE%97%E6%B3%95%E4%BB%8B%E7%B4%B9%E8%88%87in-search-of-an-understandable-consensus-algorithm%E6%91%98%E8%A6%81/</link><pubDate>Tue, 03 Nov 2020 08:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2020/2020-11-03-raft-%E6%BC%94%E7%AE%97%E6%B3%95%E4%BB%8B%E7%B4%B9%E8%88%87in-search-of-an-understandable-consensus-algorithm%E6%91%98%E8%A6%81/</guid><description>&lt;p>共識演算法主要應用於分散式系統中，一個集群中有多個節點組成，讓每個節點都維護相同的狀態，例如說在多種系統中都需要集群有單一個 Leader 存在，所有節點都必須承認這一個 Leader，否則多個 Leader 可能會導致 Split brain 等資料不一致等問題；&lt;br>
但如何讓節點狀態一致是一件不簡單的事情，要考慮到節點可能失敗 / 網路封包延遲等等&lt;/p>
&lt;p>Raft 演算法是由史丹佛大學的教授所提出，他在影片中提到過往的共識演算法 Paxos 過於複雜，世界上真正了解的人沒有幾個，市面上的實作也分歧出非常多的實作版本，理論太過艱深導致實務上有很大的落差&lt;/p>
&lt;p>所以他在設計 Raft 的一個核心理念是&lt;code>好懂&lt;/code>，他在 Conference 上也僅用約 10 分鐘就大致介紹完 Raft 的原理，整份論文也才 16 頁&lt;/p>
&lt;p>以下將整理影片介紹與論文摘要，探討 Raft 如何在分散式系統中讓&lt;code>多節點在容忍錯誤下達到強一致性&lt;/code>&lt;/p>
&lt;h2 id="影片介紹">影片介紹&lt;/h2>
&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/no5Im1daS-o"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;p>先從在 Conf 上的介紹影片快速理解，Raft 由三個部分組成&lt;/p>
&lt;ol>
&lt;li>&lt;code>Leader Election&lt;/code>:&lt;br>
整個集群中票選出一位 Leader&lt;/li>
&lt;li>&lt;code>Log Replication&lt;/code>:&lt;br>
Leader 負責接收 Client 的指令，並把狀態同步到多數節點上&lt;/li>
&lt;li>&lt;code>Safety&lt;/code>:&lt;br>
當 Leader 要重新票選時，確保擁有最新資料的節點才能當上 Leader，避免確認過(commited)的資料被取消&lt;/li>
&lt;/ol>
&lt;p>以下將摘要論文 &lt;a class="link" href="https://raft.github.io/raft.pdf" target="_blank" rel="noopener"
>《In Search of an Understandable Consensus Algorithm (Extended Version)》&lt;/a>部分內容&lt;/p>
&lt;h1 id="論文摘要">論文摘要&lt;/h1>
&lt;p>Raft 是一種用於管理副本紀錄的共識演算法，效果類似於 Paxos，但結構上完全不同，這也使得 Raft 相較於 Paxos 更容易了解&lt;br>
為了增加可讀性，Raft 解構出幾個共識演算法中關鍵的元素，像是 Leader Election / Log replication / Safety，並透過減少狀態達到更強的凝聚性 (意指節點可以變化的狀態少，就更容易達到一致)&lt;/p>
&lt;h2 id="1-introduction">1. Introduction&lt;/h2>
&lt;p>共識演算法 (Consensus) 提供由機器組成的集合可以運作類似同一體並能夠容忍部分成員出錯，也這是這些特性，共識演算法在建構大型軟體系統是很關鍵的角色&lt;/p>
&lt;p>Paxos 主宰這一塊近十年，但不幸的是 Paxos 很難懂，同時在實務上需要有很負責的設計才能夠使用，所以不論是學生還是系統工程師都十分困擾&lt;/p>
&lt;p>所以作者開始想要設計一門足夠好理解、同時對於系統工程師也容易實踐的共識演算法&lt;/p>
&lt;blockquote>
&lt;p>our primary goal was &lt;code>understandability&lt;/code>: could we define a consensus algorithm for
practical systems and describe it in a way that is significantly easier to learn than Paxos&lt;/p>
&lt;/blockquote>
&lt;p>透過解構出獨件以及減少機器在不一致狀態的可能性，讓整個演算法更容易理解&lt;/p>
&lt;p>Raft 有以下幾個特點&lt;/p>
&lt;ol>
&lt;li>Strong Leader:&lt;br>
Log 的寫入必須經由 Leader 再到其他節點上，這樣可以簡化很多不必要的複雜性&lt;/li>
&lt;li>Leader Election:&lt;br>
在選舉時，Raft 利用隨機延遲(randomized timers)方式快速且有效解決可能的衝突 (避免大家在同一個時刻想要變成 Leader)&lt;/li>
&lt;li>身份改變&lt;br>
在改變節點的設定檔時，可以將前後兩種設定檔以聯集方式合併(joint consensus)，在更改設定同時還能維持服務&lt;/li>
&lt;/ol>
&lt;p>作者認為 Raft 是個優異的共識演算法，就讓我們繼續往下看&lt;/p>
&lt;h2 id="2-replicated-state-machines">2. Replicated state machines&lt;/h2>
&lt;p>Replicated state machines 是指一群機器的集合，可以運算出相同的狀態，並在少數節點失敗時還能正常運行，主要用來解決分散式系統中各種錯誤容忍性的問題，例如 GFS / HDFS / RAMCloud，在這些系統中有獨立的 Replicated state machine 掌管 Leader Election / 保存 Config，在 Leader crash 情況下還能繼續運作；
Replicated state machine 的實際案例有 Chubby / ZooKeeper&lt;/p>
&lt;p>Replicated state machine 通常是由複製 Log 所實踐，如下圖，每個 Server 都有一份 log，依照相同順序紀錄著相同的指令，運算整份 log 就能得到相同的狀態機 (state machine)&lt;br>
&lt;img src="https://yuanchieh.page/post/img/20201103/stateMachine.png"
loading="lazy"
alt="stateMachine"
>&lt;/p>
&lt;p>從 client 收到指令後，&lt;code>如何保持順序複製相同的指令到每台機器上，就是共識演算法的任務&lt;/code>，共識演算法具體提供下列保證&lt;/p>
&lt;ol>
&lt;li>Safety:&lt;br>
在非拜占庭情況下，系統即使遭遇網路延遲、網路分隔 (partition)、封包遺失、指令重複發送、發送順序改變等問題，都不影響結果&lt;/li>
&lt;li>只要多數節點存活就能夠正常運行，例如 5 個節點 3 個還活著就可以，並且失敗的節點可以在後面重新加回集群中&lt;/li>
&lt;li>不依賴時間當作判斷，在分散式系統中時間是不可信的(除非學 Google 用原子鐘自幹出 &lt;a class="link" href="https://cloud.google.com/spanner/docs/true-time-external-consistency" target="_blank" rel="noopener"
>TrueTime&lt;/a> )，每個系統都存在著時鐘沒對齊的可能&lt;/li>
&lt;li>多數節點有回應收到副本就算成功，少數節點晚回覆不會造成性能影響&lt;/li>
&lt;/ol>
&lt;h2 id="3-whats-wrong-with-paxos">3. What’s wrong with Paxos?&lt;/h2>
&lt;p>這一章節主要在描繪 Paxos 的背景與有多難理解的原因，但因為之前沒有學過 Paxos，就先略過這章&lt;/p>
&lt;h2 id="4-designing-for-understandability">4. Designing for understandability&lt;/h2>
&lt;p>這一章節主要是作者不斷強調 &lt;code>understandability&lt;/code> 是他們的核心理念，當遇到設計有多種方案選擇時，他們會選擇最好解釋給別人聽的那一個，對於他們來說可讀性是核心理念&lt;/p>
&lt;p>具體上，透過 &lt;code>decomposition 拆分獨立模組&lt;/code>以及&lt;code>減少不確定性與狀態可能性&lt;/code> 達成目的，但在某一些部分還是有用上隨機性，因為這讓演算法更好理解&lt;/p>
&lt;h2 id="5-the-raft-consensus-algorithm">5. The Raft consensus algorithm&lt;/h2>
&lt;p>Raft 在實作上會先選出一名 Leader ，由 Leader 管理 log 的複製到其他節點的狀態機上，透過 Leader 的好處是不需要其他節點同意 Leader 能獨自決定新的 log 要儲放的位置；&lt;br>
如果 Leader 失敗了可以再選新的 Leader 出來&lt;/p>
&lt;h3 id="51-raft-basics">5.1 Raft basics&lt;/h3>
&lt;p>通常 Raft 集群會由五個節點組成，可以容忍兩個節點失敗，而每個節點有三種狀態 &lt;code>leader / follower / candidate&lt;/code>，通常情況下是一個 leader 其他人都是 follower&lt;/p>
&lt;ol>
&lt;li>follower: 被動的處理來自 leader 或 candidate 的請求&lt;/li>
&lt;li>leader: 負責所有 client 的 request，並複製指令到 follower 中&lt;/li>
&lt;li>candidate: follower 發現沒有 leader，設一個隨機 timeout 切換成 candidate 模式，準備要選新 leader&lt;/li>
&lt;/ol>
&lt;p>下圖為狀態機示意圖
&lt;img src="https://yuanchieh.page/post/img/20201103/state.png"
loading="lazy"
alt="state-machine"
>&lt;/p>
&lt;p>Raft 將時間切割成 &lt;code>回合 (term)&lt;/code>，每一個回合代表著一次的選舉，也就是 candidate 去競選 leader 的過程，如果成功推選出 leader 後，則每個節點紀錄這一個回合數；如果選舉失敗，則開啟新的回合直到有人成為 leader&lt;/p>
&lt;p>以下為概念圖
&lt;img src="https://yuanchieh.page/post/img/20201103/term.png"
loading="lazy"
alt="term"
>&lt;/p>
&lt;p>回合本身是一個遞增數值，用來表示邏輯上的時間概念，有可能節點觀察到的回合跟其他節點不同，如果回合數小則代表自身的資料過時，他必須更新自己的回合數；&lt;br>
例如說原本的 leader 可能斷線，其他節點推選出新的 leader 則會進到下一個回合數，&lt;code>原本的 leader 回歸後發現自己的回合數比較小，則會主動變成 follower&lt;/code>；&lt;br>
如果節點收到請求時，發現回合數比自己小，則代表請求過期，直接拋棄該請求&lt;/p>
&lt;h3 id="52-leader-election">5.2 Leader election&lt;/h3>
&lt;p>Raft 透過 &lt;code>heartbeat&lt;/code> 觸發 leader 選舉，當 leader 選上時，會在固定時間內發&lt;code>內容為空的 AppendEntries RPC 當作心跳包&lt;/code>，如果 follower 超過 election timeout 沒有收到心跳包，則進入選舉階段&lt;/p>
&lt;p>folower 會將現今的回合數加一便轉為 candidate，並請求其他 follower 投票給他 &lt;code>RequestVote RPC&lt;/code>，遇到以下情況 candidate 才會改變狀態&lt;/p>
&lt;ol>
&lt;li>贏得選舉&lt;/li>
&lt;li>其他節點成為 leader&lt;/li>
&lt;li>超過一定時間都沒選出 leader&lt;/li>
&lt;/ol>
&lt;h4 id="贏得選舉">贏得選舉&lt;/h4>
&lt;p>如果 candidate 拿下過半的票數，則成為新的 leader，每一個 follower &lt;code>在同一個回合數下只會投票給請求先到的 candidate&lt;/code>，這避免無效選舉的發生&lt;br>
如果 candidate 成為 leader，則開始發送心跳包&lt;/p>
&lt;h4 id="發現有其他-leader">發現有其他 leader&lt;/h4>
&lt;p>如果在 candidate 階段收到心跳包(AppendEntries)，則代表有其他 leader 產生，candidate 會去比對回合數至少要大於等於他自身的回合數，如果是則轉成 follower；&lt;br>
反之則繼續維持 candidate&lt;/p>
&lt;h4 id="超過一定時間都沒選出-leader">超過一定時間都沒選出 leader&lt;/h4>
&lt;p>超過一定時間還是沒有選出來的話，timeout 後開始下一輪新的選舉&lt;/p>
&lt;p>Raft 透過在一定時間內隨機 timeout (150-300ms)，避免所有的 follower 同時進入選舉階段，這樣能加速 leader 的推選，後續會有更近一步的說明&lt;/p>
&lt;p>在設計過程，作者曾考慮加入 rank ，rank 較高者更有機會成為 leader，但發現這會導致演算法設計更加複雜，且有可用性的問題，例如高順位 candidate 發生狀況，則低順位 candidate 要多一次 timeout 才能當上 leader 等問題&lt;/p>
&lt;h3 id="53-log-replication">5.3 Log replication&lt;/h3>
&lt;p>Leader 會透過 AppendEntries RPC 將指令同步到 follower 並回傳執行結果給 client，如果 follower 此時 crash 等，leader 會持續送直到 follower 狀態同步&lt;/p>
&lt;p>Log 是以 &lt;code>回合數 + 指令&lt;/code> 的方式依序儲存，主要是檢視是否有不一致的狀況產生&lt;/p>
&lt;p>每個節點都會保存現今最後一個 commited log 的索引 (&lt;code>commitIndex&lt;/code>)，Leader 在同步 log 時，會紀錄 log 要寫入的位置 (commitIndex + 1)，並同時發送給 follower (leaderCommit)，等到多數的 follower 都寫入 log 後才標記成 &lt;code>commited&lt;/code>，Raft 保證 commited log 是已經持久化且最終每個 follower 都會達到一致性&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/20201103/log.png"
loading="lazy"
alt="log"
>&lt;/p>
&lt;p>因此 Raft 保證 Logs 有以下特性&lt;/p>
&lt;ol>
&lt;li>如果任意兩個節點的 log 有著相同的 index 與回合數，則他們必定儲存相同的指令&lt;/li>
&lt;li>如果任意兩個節點的 log 有著相同的 index 與回合數，則該指令先前的 log 紀錄都必定相同&lt;/li>
&lt;/ol>
&lt;p>第一點保證節點儲存 log 後就不會再被改變，第二點則確保當 follower 發現自己的 log 跟 leader 不同時，可以依此重新跟 leader 同步紀錄&lt;/p>
&lt;p>Leader 會針對每一個 follower 維護指針 &lt;code>nextIndex&lt;/code>，用來記錄 follower 目前需要同步的 log 索引，leader 在發送 AppendEntries 指令時，會夾帶最新 committed log 的回合數與 index，讓 follower 可以比對 log 是否同步，如果 follower 在自己的 logs 中沒有找到對應的紀錄，則代表兩者非同步，回傳失敗，接著 &lt;code>Leader 不斷遞減 nextIndex 直到 follower 找到兩者最近一次同步的紀錄&lt;/code>，接著開始一步步同步紀錄&lt;/p>
&lt;blockquote>
&lt;p>leader 與 follower 找到最近一次同步紀錄的方式，可以優化成 follower 回傳這一個回合數下他所以紀錄的索引，leader 直接倒回這個回合開始同步；&lt;br>
但作者認為不一致狀態應該很少發生，優化的效益不大&lt;/p>
&lt;/blockquote>
&lt;p>透過這樣的 log 同步設計，Leader 在剛啟動時不用擔心太多同步的問題，利用 AppendEntries 的成功與失敗去調配 follower 儲存的紀錄，leader 也不用去刪除或更新自身的 log，讓整個同步的過程更加的簡單&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/20201103/AppendEntries.png"
loading="lazy"
alt="AppendEntries"
>&lt;/p>
&lt;h3 id="54-safety">5.4 Safety&lt;/h3>
&lt;p>先前介紹了 leader election 和 relicate log，但僅有這樣的機制是不夠的，試想如果 leader 發生錯誤，今天有一個 follower 僅包含部分的 commited log，選上 leader 後便會複寫原本其他已經 commited 的 log，這樣就不能保證一致性與持久化&lt;/p>
&lt;p>這一章介紹 Raft 在 leader election 加上限制後，如何達到&lt;code>確保每一台狀態機都以相同順序保存相同的指令&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/20201103/safety.png"
loading="lazy"
alt="safety"
>&lt;/p>
&lt;p>Raft 會確保任何時候集群都符合上述條件&lt;/p>
&lt;ol>
&lt;li>Election Safety: 每一輪選舉至多只選出一位 leader&lt;/li>
&lt;li>Leader Append-Only: leader 從不刪除或改寫自己的 log，只會一直增加&lt;/li>
&lt;li>Log Matching: 任兩份 logs 在同一個 term 同一個 index 上，則 log 內容必定相同，且先前的 log 也都相同&lt;/li>
&lt;li>Leader Completeness: 某個 log 在任一一個 term 中認定 commited，則後續 term 中的 leader 都必須有該份 log&lt;/li>
&lt;li>State Machine Safety: 如果某個 server 在某 index 上的 log 套用至狀態機，則不會有其他的 server 在同一個 index 上套用不同的 log&lt;/li>
&lt;/ol>
&lt;h4 id="541-election-restriction">5.4.1 Election restriction&lt;/h4>
&lt;p>在 leader-based 的共識演算法中，leader 最終會儲存所有的 commited log，在某些演算法中，leader 在沒有保存所有 commited log 情況下也能夠檔選，並透過額外的機制去回補這些未同步的 log，這增加了蠻多的複雜性&lt;/p>
&lt;p>Raft 確保 leader 必須是由 &lt;code>擁有大多數節點同意的最新 committed log 的 candidate&lt;/code> 才能當選，確保 leader 一定是擁有最新 log 的節點，只負責增加新的 log，讓資料流只有一個方向，省去其他的麻煩&lt;/p>
&lt;p>在 RequestVote RPC 中增加了限制，RPC 中夾帶 candidate 最後一個 log 中的回合數與索引數，如果 follower 發現 candidate 的紀錄比自己舊，則回傳失敗&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/20201103/RequestVote.png"
loading="lazy"
alt="RequestVote"
>&lt;/p>
&lt;h4 id="542-committing-entries-from-previous-terms">5.4.2 Committing entries from previous terms&lt;/h4>
&lt;p>先前提到，Leader 會等多數的節點儲存 log 才標記成 commited， 但如果 leader 將 log 寫到多個 follower 後，還來不及收到 commited 就 crash 了&lt;br>
此時&lt;code>新的 leader 會持續同步 log，但無法確認先前的 log 是不是被 commit&lt;/code> 了，因為只有先前的 leader 才能確認 log 已經被多數的節點所保存&lt;/p>
&lt;p>如以下圖示
&lt;img src="https://yuanchieh.page/post/img/20201103/commit.png"
loading="lazy"
alt="commit"
>&lt;/p>
&lt;ol>
&lt;li>S1 一開始是 leader，同步 term2 到 S2 就 crash&lt;/li>
&lt;li>S5 接著當 leader (S3,S4 可以投給他) 開始了 term 3，此時發生 crash&lt;/li>
&lt;li>S1 又回來當 leader，將 term2 的 log 同步到 S3 後，此時又 crash&lt;/li>
&lt;/ol>
&lt;p>接著拆兩種情況&lt;br>
d. S1 來不及同步 term4 資料，則 S5 有機會當入 leader，並用 term3 複寫掉其他資料&lt;br>
e. S1 同步 term4 資料到大多數節點上，則 S5 無法當上 leader&lt;/p>
&lt;p>&lt;code>在 leader 還沒收到 commited 情況下，即使多數的節點已經同步 log，但新的 leader 有機會複寫&lt;/code>&lt;/p>
&lt;p>為了減少這樣的情況，Raft 不去計算先前 log 所同步的副本數去判定是否 commited，&lt;code>只有 leader 當下的回合數是透過副本的計算來決定 log 是否被 commited，如果 commit 後，則先前的所有 log 都被視為 commited&lt;/code>，降低計算上的複雜性，並因為之前的 log 特性保證，先前的 log 一定也都被複製到其他副本上&lt;/p>
&lt;h4 id="543-safety-argument">5.4.3 Safety argument&lt;/h4>
&lt;p>更進一步解釋 &lt;code>Leader Completeness&lt;/code>，透過反證法，找出集群無法不遵守 Leader Completeness&lt;/p>
&lt;p>假設 leaderT 代表在 term T 的 leader，leader U 則是 term U，且 U 代表是 T 的下一位，且 leaderT 所認定的 commited log (logT) 在 leader U 不存在 (違反 Leader Completeness)&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/20201103/leader-completeness.png"
loading="lazy"
alt="leader-completeness"
>&lt;/p>
&lt;ol>
&lt;li>leaderU 在當 follower 時並保存沒有 logT&lt;/li>
&lt;li>leaderT 將 logT 同步到多數節點上，而 leaderU 在選舉時獲得多數同意，也就是至少有一位投票節點 (voter) 收到 logT 同時又投票給 leaderU&lt;/li>
&lt;li>voter 必須先保存 logT，才又投票給 leaderU，反過來就不會有衝突 (term U &amp;gt; term T 所以 logT 後到會被丟棄)&lt;/li>
&lt;li>voter 依然保存 logT，因為 leader 從不改變既定 log，而 follower 也只有與 leader 衝突時才會複寫&lt;/li>
&lt;/ol>
&lt;p>製造出場景後，讓我們來看為什麼 Raft 不可能達到這樣的狀況&lt;br>
5. 依據先前規定， follower 只會投給 log 保留比自己更多的 candidate&lt;br>
6. 如果 voter 與 leaderU 最新一個 term 都是 T 的話，則 leaderU 的 log 數應該與 voter 相同，也就是 leaderU 至少擁有 voter 所擁有的 log&lt;br>
7. 反之，如果 leaderU 的最新 log term 大於 voter 的話，為了要符合早於 leaderU 的 leader 所有 commited log 都應該被保留到 leaderU 中，因此根據 &lt;code>Log Matching&lt;/code> 則 leaderU 應該要儲存這些 log&lt;/p>
&lt;p>在無法達成的情況，證明了 Raft 滿足 Leader Completeness 條件，確保 leader 如果最新的 log term &amp;gt; T，則 leader 必定擁有 term T 所 commited 的一切 log&lt;/p>
&lt;blockquote>
&lt;p>Thus, the leaders of all terms greater than T must contain all entries from term T that are committed in term T&lt;/p>
&lt;/blockquote>
&lt;p>有了 Leader Completeness 屬性，就能進一步證明 &lt;code>State Machine Safety&lt;/code>，如果某一機器在某一 index 套用指令到狀態機中，則其他機器在相同 index 下並然套用相同的指令，因為能夠被套用的 log 一定是 leader commited 後的 log，且因為 Log
Completeness，所有更新的 leader 也都保留被 commited 後的 log，因此能&lt;code>確保所有的節點終將以相同的順序套用相同的指令到狀態機上&lt;/code>&lt;/p>
&lt;h3 id="55-follower-and-candidate-crashes">5.5 Follower and candidate crashes&lt;/h3>
&lt;p>先前都是討論 leader crashed 後的處置，至於 follower 與 candidate 則單純很多，因為 Raft 的 RPC 指令都是 &lt;code>idempotent&lt;/code>，leader 可以持續的送指令直到成功，follower 跟 candidate 失敗後重啟就重新接收指令就好&lt;/p>
&lt;h3 id="56-timing-and-availability">5.6 Timing and availability&lt;/h3>
&lt;p>Raft Safety 建立在不依賴 timing，系統不會因為訊息發送的快慢而得到不預期的結果；&lt;br>
但整體系統的可用性卻還是跟時間有一些關聯，例如說 server 不能再 election timeout 期間內票選出 leader，而 Raft 在沒有 leader 的情況下就不可用&lt;/p>
&lt;p>所以整體上要符合以下不等式 Raft 才能運作正常&lt;/p>
&lt;blockquote>
&lt;p>broadcastTime ≪ electionTimeout ≪ MTBF&lt;/p>
&lt;/blockquote>
&lt;ol>
&lt;li>&lt;code>broadcastTime&lt;/code> 代表 RPC 完整 request / response 所耗費的時間，須小於 electionTimeout 一個量級，通常在 0.5ms ~ 20ms；&lt;/li>
&lt;li>&lt;code>electionTimeout&lt;/code> 則是 follower 等待多久後會觸發選舉，這是可以主動去設定的，通常在 100ms ~ 500ms；&lt;/li>
&lt;li>&lt;code>MTBF&lt;/code> 則代表 server 進入錯誤狀態的區間，通常是數天至數個月&lt;/li>
&lt;/ol>
&lt;p>試想如果 broadcastTime &amp;gt; electionTimeout，則每一次選舉在還沒收到投票結果又開始下一輪選舉，則永遠選不完；&lt;br>
如果 electionTimeout &amp;gt; MTBF，則選舉還沒結束 server 又 crash，那也一樣會有 leader 無法產生的問題&lt;/p>
&lt;h2 id="總結">總結&lt;/h2>
&lt;p>後續還有 Cluster membership changes / Log compaction / Client interaction 進階探討，就先暫時略過，僅理解前半部演算法的核心設計&lt;/p>
&lt;p>分散式系統的迷人之處在於&lt;code>複雜&lt;/code>，需要面對網路延遲 / 時間不一致(time skewed) / 機器失敗等不穩定的因子，「再不穩定的條件下架構出可容錯/高可用/一致性的穩定系統」，看似荒謬卻可以透過演算法的設計達成目的(或是說更貼近)，實在令人讚嘆這些設計演算法的專家們&lt;/p>
&lt;p>Raft 透過由 Leader 主導 Log 的同步，並加入選舉時的條件限制，確保 commited log 不會被改寫達到 &lt;code>強一致性&lt;/code>；如果 Leade 失敗，也不用擔心 log 發生問題，等下一位 Leader 被推選出來又能夠繼續維持系統運作&lt;/p>
&lt;p>整份論文讀起來還算蠻好理解的，確實符合作者不斷強調可讀性的重要&lt;/p></description></item><item><title>Gossip Protocol 介紹 (下) - 《Efficient Reconciliation and Flow Control for Anti-Entropy Protocols》論文摘要</title><link>https://yuanchieh.page/posts/2020/2020-10-28-gossip-protocol-%E4%BB%8B%E7%B4%B9-%E4%B8%8B-efficient-reconciliation-and-flow-control-for-anti-entropy-protocols%E8%AB%96%E6%96%87%E6%91%98%E8%A6%81/</link><pubDate>Wed, 28 Oct 2020 08:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2020/2020-10-28-gossip-protocol-%E4%BB%8B%E7%B4%B9-%E4%B8%8B-efficient-reconciliation-and-flow-control-for-anti-entropy-protocols%E8%AB%96%E6%96%87%E6%91%98%E8%A6%81/</guid><description>&lt;h1 id="gossip-protocol">Gossip Protocol&lt;/h1>
&lt;p>Gossip Protocol 是一種通訊機制，應用於同一網路內機器與機器間交換訊息使用，原理類似於辦公室傳謠言一樣，一個傳一個，最終每一個機器都擁有相同的資訊，又稱 Epidemic Protocol&lt;/p>
&lt;p>上一篇分享到 &lt;a class="link" href="https://yuanchieh.page/post/2020-10-26-gossip-protocol-%E4%BB%8B%E7%B4%B9%E4%B8%8A/" target="_blank" rel="noopener"
>Cassandra 內部如何使用 Gossip Protocol&lt;/a>，影片中有推薦 &lt;a class="link" href="https://www.cs.cornell.edu/home/rvr/papers/flowgossip.pdf" target="_blank" rel="noopener"
>Efficient Reconciliation and Flow Control for Anti-Entropy Protocols&lt;/a>，以下摘要此篇論文所探討的內容&lt;/p>
&lt;p>建議可以先讀上篇，有個概略認識後在看理論會比較好懂些&lt;/p>
&lt;h2 id="efficient-reconciliation-and-flow-control-for-anti-entropy-protocols-摘要">《Efficient Reconciliation and Flow Control for Anti-Entropy Protocols》 摘要&lt;/h2>
&lt;p>anti-entropy，又或稱作 gossip，用於不需要強一致性的狀態同步，在一些限制下，時間複雜度是 log(N) (N 為群體數量) 且在 host 遭遇錯誤或是訊息丟失都不影響&lt;/p>
&lt;p>gossip 希望盡量在可控制的回合內完成同步，但如同其他同步操作，這會仰賴 CPU 資源與 Network 流量，在高負載下 CPU 可能來不及運算要更新的狀態或是網路流量不夠快導致延遲封包&lt;/p>
&lt;p>這份論文主要提供兩個價值，&lt;/p>
&lt;ol>
&lt;li>在限定 CPU / Network 下優化 gossip protocol 傳輸效率&lt;/li>
&lt;li>分析 gossip protocol 的流量管制&lt;/li>
&lt;/ol>
&lt;p>gossip protocol 主要有兩種類型&lt;/p>
&lt;ol>
&lt;li>anti-entropy: 持續傳送 gossip information 直到全部資料都更新完成&lt;/li>
&lt;li>rumormongering: 選定一個足夠有效的時間持續送 gossip information，大概率節點都會拿到最新資訊&lt;/li>
&lt;/ol>
&lt;p>假設目前的集群 {p,q &amp;hellip;}，每個參與者都需要維護一份列表，這個列表是由 key -&amp;gt; (value + version) 組成，也就是 Cassandra 內的 ApplicationState&lt;/p>
&lt;blockquote>
&lt;p>σ ∈ S = K → (V × N ) // σ 代表取狀態
σ(k) = (v, n) ，表示 key 此時對應的 value v 跟 version n&lt;/p>
&lt;/blockquote>
&lt;p>列表包含 key -&amp;gt; value -&amp;gt; version，如果是這個 key 的最新資料，則他的 version 會大於舊的 version&lt;/p>
&lt;blockquote>
&lt;p>σ1(k) = (v1, n1), σ2(k) = (v2, n2) // σ1(k) 代表這一個節點取他的 key，返回 (v1, n1) 代表 value 為 v1 且 version n1；
σ(k) 表示取 σ1 與 σ2 取 XOR，並遇到相同 key 時取 verson 較大者，也就是如果 n1 &amp;gt; n2 則 σ(k) = (v1, n1)&lt;/p>
&lt;/blockquote>
&lt;p>操作流程大致是&lt;/p>
&lt;ol>
&lt;li>從集群中隨機挑一個 host 傳送訊息，訊息內容是自己所維護的列表&lt;/li>
&lt;li>收到訊息後運算，此動作稱為 merge 或稱為 reconciliation ，也就是收到訊息時會去運算列表的差異，並保留差異中 version 較高的 key -&amp;gt; value&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>∀r : µq (r) = µq (r) ⊕ µp(r) // q 真正要更新的是 p 傳來的訊息與 q 自身現在的訊息取 XOR 找出差異處&lt;/p>
&lt;/blockquote>
&lt;p>傳送訊息有三種格式&lt;/p>
&lt;ol>
&lt;li>push: 節點 p 傳送整份列表，節點 q 收到則計算 merge 後合併入自己的列表&lt;/li>
&lt;li>pull: 節點 p 傳送 key -&amp;gt; version 而沒有 value，節點 q 回傳節點 p 須要更新的鍵值，變免多餘的值傳送&lt;/li>
&lt;li>push-pull: 就像 push，節點 p 傳送完整列表，節點 q 會回傳 p 過期須要更新的鍵值 ( pull 後半段，&lt;code>push-pull 是最有效率的做法&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>如果某個 key 不再更新，那在一定的時間內很高的機率大家都會同步相同的 value，如果集群隨機挑選節點的演算法 &lt;code>(Fp ⊆ P − {p})&lt;/code> 夠隨機的話，即使遇到 message loss 或是 host 短暫 failed，也僅僅是稍微延遲同步的時間&lt;/p>
&lt;p>假設 update key 的時間是固定的，那隨著集群數量線性增長 N，則達成同步所需要的時間會成 log(N) 增長。&lt;/p>
&lt;p>但實務上必須考量到 CPU / Network 以及更新的頻率，如果更新的頻率太高，因為資源受限則同步的延遲可能會無限的增長，實際上應用程式在意的不是多常更新，而是資料是不是抵達同步&lt;/p>
&lt;p>接著要探討如果我們限定 gossip message 不能超過 MTU(Maximum Transmission Unit)，那我們該怎麼決定要更新哪些 key 才能最有效讓所有節點狀態一致&lt;/p>
&lt;h2 id="reconciliation">RECONCILIATION&lt;/h2>
&lt;p>先前提到 p 跟 q 來回通信都只送兩者狀態的 delta，如果超過 MTU 則必須有一個優先序決定哪些鍵值要先更新( &lt;code>&amp;lt;π&lt;/code> 代表此排序演算法)，作者介紹了兩種，一種是 &lt;code>precise reconciliation&lt;/code> 最為基準線，對比另一個作者提出的 &lt;code>Scuttlebutt&lt;/code> 更新機制&lt;/p>
&lt;h3 id="precise-reconciliation">precise reconciliation&lt;/h3>
&lt;p>根據更新時間序決定哪些 key 要先送出去，在實務上 precise reconciliation 比較麻煩些，如先前說必須要先送 state 給對方做比較才能算出 delta，這會消耗頻寬以及 CPU cycle&lt;/p>
&lt;p>依據時間序又可以細分成 &lt;code>precise-oldest&lt;/code>: 在 MTU 限制下先送那些很久沒有更新的 key / &lt;code>precise-newest&lt;/code>: 先送最近才被更新的 key，後者要留意會有 starvation 問題，在實作上節點必須同步時間，才能作為判斷的依據&lt;/p>
&lt;blockquote>
&lt;p>Note that, if implemented, both these orderings would require a synchronized clock among the members and that all
updates be timestamped with this clock.&lt;/p>
&lt;/blockquote>
&lt;h3 id="scuttlebutt-reconciliation">Scuttlebutt Reconciliation&lt;/h3>
&lt;p>作者提及另一種解法，也是 Cassandra 採納的做法，初始化時 version 固定是最小的數字，每次更新鍵值時，要把 version 設定大於成目前任意鍵值對應的最高版號&lt;/p>
&lt;blockquote>
&lt;p>&lt;code>{(r, max(µp(r))) | r ∈ P}&lt;/code> // 此公式表示 r 是屬於節點 P 的屬性，找出 r 以及當下 P 中 r 最大的版號；&lt;/p>
&lt;/blockquote>
&lt;p>例如說目前 Participant p 的列表是&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">key &lt;span class="p">|&lt;/span> value &lt;span class="p">|&lt;/span> version
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">a &lt;span class="p">|&lt;/span> a1 &lt;span class="p">|&lt;/span> &lt;span class="m">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">b &lt;span class="p">|&lt;/span> b1 &lt;span class="p">|&lt;/span> &lt;span class="m">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">c &lt;span class="p">|&lt;/span> c1 &lt;span class="p">|&lt;/span> &lt;span class="m">3&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>如果此時 a 要更新，則版號至少要拉到 4，而且不像 precise-conciliation 會一次送多組間值更新，Scuttlebutt 允許一次可以送一個鍵值，但必須按照 version 大小逐一送
整個架構必須符合以下狀態
&lt;img src="https://yuanchieh.page/post/img/20201028/gossip_equation.png"
loading="lazy"
>&lt;/p>
&lt;p>也就是說在整個集群下，任一鍵值 k 在節點 p / 節點 q 必須滿足以下任一條件&lt;/p>
&lt;ol>
&lt;li>在節點 p 跟節點 q 中同一個 key version 是一樣，代表&lt;code>資料已經同步&lt;/code>&lt;/li>
&lt;li>如果節點 p 的 key version 跟節點 q 不同，則此 version 必須比是節點q 中任意最大的版號還要大&lt;/li>
&lt;/ol>
&lt;p>第二點非常重要，這是保持每次更新不需要整包送，先從版本判斷就能判斷哪些欄位真的需要更新的依據&lt;/p>
&lt;p>來看一個實際案例，目前有三個節點 r,p,q，共有 3 個 key a,b,c，可以看到 t1 時 r 的三個 key 都被更新過，版號分別是 21/22/23；&lt;br>
此時 r 要向 p,q 發送 gossip message，他必須先從 a 開始，因為這是 a,b,c 三者中版號最小，且大於&lt;code> µq(p) / µp(p)&lt;/code> ，這意味著節點 p 和 節點q 都要更新，所以 r 會同時送訊息給 p , q，在 t2 時只有 key a 先被更新&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/20201028/example.png"
loading="lazy"
>&lt;/p>
&lt;blockquote>
&lt;p>可以回去看 Gossip 介紹(上)的 GossipDigestSynMessage 部分&lt;/p>
&lt;/blockquote>
&lt;p>雖然說一次只更新一個鍵值效率好像很低，但優點是 r 不需要送已經更新過的值，減少重複，在頻寬有限情況下，Scuttlebutt 也必須決定 gossip message 傳送的優先序，這裡有兩種做法&lt;/p>
&lt;ol>
&lt;li>&lt;code>scuttle-breadth&lt;/code>: 在同一個 participant 中，將 delta 用 version 從小到大排序，如果兩個不同 delta 的 version 相同，則隨機抽 participant 發送&lt;/li>
&lt;li>&lt;code>scuttle-depth&lt;/code>: 在 participant 中，只有鍵值有落差就算一個 delta，從 delta 最多的 participant 開始送，所以有可能都送給同一個 participant&lt;/li>
&lt;/ol>
&lt;h4 id="實驗結果">實驗結果&lt;/h4>
&lt;p>總共 128 participants 與 64 組 key/ value，每秒每個 participant gossip 一次；
前 15 sec 暖機，並開始限縮頻寬 / 25 秒開始加倍更新頻率 / 75 秒更新頻率回歸正常 / 120 sec 停止更新，中間 25~75 加大流量主要是想要看演算法在高負載下的表現，以及高峰過去後的恢復速度&lt;br>
&lt;img src="https://yuanchieh.page/post/img/20201028/gossip.png"
loading="lazy"
>&lt;/p>
&lt;ol>
&lt;li>第一張圖表代表這一個時間上，該鍵值自從上次被更新後隔了多久才收到最新資訊，越低者越好&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>staleness of such a mapping µq (p)(k) is the amount of time that has lapsed since µq(p)(k) was last updated&lt;/p>
&lt;/blockquote>
&lt;ol start="2">
&lt;li>第二張圖表代表這一個時間有多少個鍵值是過期的 ，越低者越好&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>reports the number of stale mappings as a function of time&lt;/p>
&lt;/blockquote>
&lt;p>交叉比對有以下結論&lt;/p>
&lt;ol>
&lt;li>&lt;code>Scuttle-depth 表現優異&lt;/code>&lt;/li>
&lt;li>Precise-newest 可以看出有 starvation 狀況，也就是有鍵值很久沒有被更新 (圖一他最高)，但是真正影響到的鍵值其實是少數 (同一時間點其實過期的鍵值數不多)，但是高峰過去收斂很快&lt;/li>
&lt;li>其餘兩者表現普普&lt;/li>
&lt;/ol>
&lt;h2 id="flow-control">Flow Control&lt;/h2>
&lt;p>在一些情況下，participant 交換訊息時更新頻率可能不同，所以會需要一個流量控制的演算法，去平衡一個 participant 想要增加更新頻率而另一個想要降低頻率的可能，要製造出這樣的不同更新頻率，但同時系統必須維持相同的最大交換頻率上限&lt;br>
在 participant 交換 gossip 時，會連帶交換彼此預設更新的頻率 (ρp , ρq)以及最大值 (τp,τq )，當兩個 participant 在交換時會順便交換&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/20201028/flow1.png"
loading="lazy"
>&lt;/p>
&lt;p>機制有點類似於 TCP 的 Additive Increase Multiplicative Decrease (AIMD)，逐漸增加發送的頻率但遇到錯誤時快速減少；&lt;br>
如果要發送的 delta 數量高於 MTU，則線性增加，反之，則倍數減少&lt;/p>
&lt;p>實驗過程是在 t = 90 時限縮 mtu 從 100 降到 50，可以看到 90 之後 max out of date 大幅增加，之後才慢慢收斂，其中 scuttle-depth 在表現上比較穩定 &lt;br>
&lt;img src="https://yuanchieh.page/post/img/20201028/exp2.png"
loading="lazy"
>&lt;/p>
&lt;p>這一章節比較不確定，如果有什麼錯誤麻煩指教 🙏&lt;/p>
&lt;h2 id="總結">總結&lt;/h2>
&lt;p>本篇提出兩個重點&lt;/p>
&lt;ol>
&lt;li>新的 reconciliation 機制，加速同步的效率，同時避免 starvation&lt;/li>
&lt;li>引入 flow control 機制，讓 participant 可以用合理的速度更新&lt;/li>
&lt;/ol>
&lt;h2 id="實作面">實作面&lt;/h2>
&lt;p>網路上找了一個 nodejs 版本的 gossip protocol 實作 &lt;a class="link" href="https://github.com/bpot/node-gossip" target="_blank" rel="noopener"
>node-gossip&lt;/a>，看起來是使用 scuttle-depth 協議機制
計算與 peer 中的 delta 最多的，接著先按照 peer 中最舊的 version 開始排序&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// Sort by peers with most deltas
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="nx">deltas_with_peer&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">sort&lt;/span>&lt;span class="p">(&lt;/span> &lt;span class="kd">function&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">a&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="nx">b&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="nx">b&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">deltas&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">length&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="nx">a&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">deltas&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">length&lt;/span> &lt;span class="p">}&lt;/span> &lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">var&lt;/span> &lt;span class="nx">deltas&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[];&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">i&lt;/span> &lt;span class="k">in&lt;/span> &lt;span class="nx">deltas_with_peer&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">var&lt;/span> &lt;span class="nx">peer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">deltas_with_peer&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nx">i&lt;/span>&lt;span class="p">];&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">var&lt;/span> &lt;span class="nx">peer_deltas&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">peer&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">deltas&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// Sort deltas by version number
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="nx">peer_deltas&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">sort&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kd">function&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">a&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="nx">b&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="nx">a&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="nx">b&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">];&lt;/span> &lt;span class="p">})&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">peer_deltas&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">length&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// console.log(peer_deltas);
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">j&lt;/span> &lt;span class="k">in&lt;/span> &lt;span class="nx">peer_deltas&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">var&lt;/span> &lt;span class="nx">delta&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">peer_deltas&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nx">j&lt;/span>&lt;span class="p">];&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">delta&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">unshift&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">peer&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">peer&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">deltas&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">push&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">delta&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Gossip Protocol 介紹 (上) - 從 Cassandra 內部實作認識 Gossip Protocol 的使用</title><link>https://yuanchieh.page/posts/2020/2020-10-26-gossip-protocol-%E4%BB%8B%E7%B4%B9-%E4%B8%8A-%E5%BE%9E-cassandra-%E5%85%A7%E9%83%A8%E5%AF%A6%E4%BD%9C%E8%AA%8D%E8%AD%98-gossip-protocol-%E7%9A%84%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 26 Oct 2020 08:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2020/2020-10-26-gossip-protocol-%E4%BB%8B%E7%B4%B9-%E4%B8%8A-%E5%BE%9E-cassandra-%E5%85%A7%E9%83%A8%E5%AF%A6%E4%BD%9C%E8%AA%8D%E8%AD%98-gossip-protocol-%E7%9A%84%E4%BD%BF%E7%94%A8/</guid><description>&lt;p>Gossip Protocol 是一種通訊機制，應用於同一網路內機器與機器間交換訊息，原理類似於辦公室傳謠言一樣，一個傳一個，最終每一個機器都擁有相同的資訊，又稱 &lt;code>Epidemic Protocol&lt;/code>&lt;/p>
&lt;p>實務上有幾個好處&lt;/p>
&lt;ol>
&lt;li>去中心化:&lt;br>
機器與機器間直接溝通 (peer to peer)&lt;/li>
&lt;li>容錯率高:&lt;br>
即便節點與節點之間無法直接相連，只有有其他 節點 可以傳遞狀態，也可以維持一致的狀態&lt;/li>
&lt;li>效率高且可靠&lt;/li>
&lt;/ol>
&lt;p>Gossip Protocol 被廣泛採納，如Cassandra / Redis Cluster / Consul 等集群架構，以下將從 Cassandra 的實作來理解 Gossip Protocol&lt;/p>
&lt;h2 id="apple-inc-cassandra-internals--understanding-gossip">Apple Inc.: Cassandra Internals — Understanding Gossip&lt;/h2>
&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/FuP1Fvrv6ZQ"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;p>先從實務面來看，Gossip Protocol 在 Cassandra 中主要用於同步 節點 的 Metadata，包含&lt;/p>
&lt;ol>
&lt;li>cluster membership&lt;/li>
&lt;li>heartbeat&lt;/li>
&lt;li>node status&lt;br>
同時每個節點都會保存一份其他節點狀態的 Mapping Table&lt;/li>
&lt;/ol>
&lt;p>更具體來看節點狀態所保存的資料格式&lt;/p>
&lt;ol>
&lt;li>HeartbeatState:&lt;br>
每一個節點會有一個 HeartbeatState，紀錄 generation / version，&lt;code>generation&lt;/code> 是節點啟動時的 timestamp，用來區分機器是否重新啟動過；&lt;code>version&lt;/code> 則是遞增數值，每次 ApplicationState 有值更新時就會遞增&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>所以同一個節點內的 ApplicationState version 不會重複，且 version 比較大一定代表這個鍵值比較新&lt;/p>
&lt;/blockquote>
&lt;ol start="2">
&lt;li>ApplicationState: 一個由&lt;code>{enum_name, value, version}&lt;/code>建立的 tuple，enum_name 代表固定的 key 名稱，version 則表示 value 的版本號碼，號碼大者則代表資料較新&lt;/li>
&lt;li>EndpointState: 紀錄某一個節點下所有的 ApplicationState&lt;/li>
&lt;li>EndpointStateMapping: 一個節點會有一張針對已知的節點所紀錄的 EndpointState，同時會包含自己的狀態&lt;/li>
&lt;/ol>
&lt;p>如下圖&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">EndPointState 10.0.0.1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> HeartBeatState: generation 1259909635, version &lt;span class="m">325&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;load-information&amp;#34;&lt;/span>: 5.2, generation 1259909635, version &lt;span class="m">45&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;bootstrapping&amp;#34;&lt;/span>: bxLpassF3XD8Kyks, generation 1259909635, version &lt;span class="m">56&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;normal&amp;#34;&lt;/span>: bxLpassF3XD8Kyks, generation 1259909635, version &lt;span class="m">87&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">EndPointState 10.0.0.2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> HeartBeatState: generation 1259911052, version &lt;span class="m">61&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;load-information&amp;#34;&lt;/span>: 2.7, generation 1259911052, version &lt;span class="m">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;bootstrapping&amp;#34;&lt;/span>: AujDMftpyUvebtnn, generation 1259911052, version &lt;span class="m">31&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.....
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>這邊可以看到節點 10.0.0.1 所保存的 &lt;code>EndPointStateMap&lt;/code> 有兩筆 EndPointState，其中 10.0.0.1 的 HeartBeatState 是 &lt;code>generation 1259909635, version 325&lt;/code>，這代表 10.0.0.1 是在 1259909635 時啟動的，並且他目前保存欄位中最新的版本是 325；&lt;br>
接著看 &lt;code>ApplicationState &amp;quot;load-information&amp;quot;: 5.2, generation 1259909635, version 45&lt;/code>，這代表節點內 &amp;ldquo;load-information&amp;rdquo; 這個 Key 對應的值是 5.2 以及當時收到的 generation 與 version，後兩者用來決定 &lt;code>這個 key 收到訊息後要不要更新的依據&lt;/code>&lt;/p>
&lt;h3 id="gossip-messaging">Gossip Messaging&lt;/h3>
&lt;p>接著來看每次 Gossip 的實作流程，每個節點會在每一秒啟動一個新的 gossip 回合&lt;/p>
&lt;ol>
&lt;li>挑出 &lt;code>1~3&lt;/code> 的節點，優先選擇 live 狀態的節點，接著會機率性選擇 Seed 節點 / 先前判定已經離綫的節點&lt;/li>
&lt;li>傳遞訊息的流程是 SYN / ACK / ACK2 (類似於 TCP 的3次交握)&lt;/li>
&lt;/ol>
&lt;p>假設現在是節點 A 要傳訊息給 節點 B 關於節點 C 的 Gossip&lt;/p>
&lt;ol>
&lt;li>&lt;strong>GossipDigestSynMessage&lt;/strong> :&lt;br>
節點 A 要發送的 SYN 訊息包含 &lt;code>{ipAddr, generation, heartbeat}&lt;/code>，需注意此時只要送 HeartbeatState，而沒有送詳細的 ApplicationState，避免多餘的資料傳輸&lt;/li>
&lt;li>&lt;strong>GossipDigestAckMessage&lt;/strong> :&lt;br>
節點 B 收到後，會去比對他自己暫存節點 C 的狀態，運算兩者差異 &lt;br>
a. 節點 A 的資料比較新，則節點 B 會準備跟節點 A 要新的資料&lt;br>
b. 節點 B 的資料比較新，打包要更新的 ApplicationState 回傳 &lt;code>ACK&lt;/code> 通知節點 A&lt;/li>
&lt;li>&lt;strong>GossipDigestAck2Message&lt;/strong> :&lt;br>
節點 A 收到 ACK 後，更新自己暫存的資料，並且根據 (2.a) 中節點 B 所需要的 ApplicationState，回傳 &lt;code>ACK2&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>會多一個 &lt;code>ACK2&lt;/code> 是為了讓通訊更穩定，達到更快收斂的作用，但這邊如果 節點 B 沒收到 ACK2 是否會重試等如同 TCP 作法就沒有提及&lt;/p>
&lt;blockquote>
&lt;p>總結來看傳送訊息的過程，在 Cluster 沒有節點狀態異動下，傳送的訊息量是固定的，不會有 &lt;code>Gossip Storm&lt;/code> 網路封包突然爆量的情況； &lt;br>
除非是有節點 新加入，多個節點 希望同步資訊才有可能&lt;/p>
&lt;/blockquote>
&lt;p>來看實際案例，假設
目前有節點A (10.0.0.1)&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">EndPointState 10.0.0.1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> HeartBeatState: generation 1259909635, version &lt;span class="m">325&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;load-information&amp;#34;&lt;/span>: 5.2, generation 1259909635, version &lt;span class="m">45&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;bootstrapping&amp;#34;&lt;/span>: bxLpassF3XD8Kyks, generation 1259909635, version &lt;span class="m">56&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;normal&amp;#34;&lt;/span>: bxLpassF3XD8Kyks, generation 1259909635, version &lt;span class="m">87&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">EndPointState 10.0.0.2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> HeartBeatState: generation 1259911052, version &lt;span class="m">61&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;load-information&amp;#34;&lt;/span>: 2.7, generation 1259911052, version &lt;span class="m">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;bootstrapping&amp;#34;&lt;/span>: AujDMftpyUvebtnn, generation 1259911052, version &lt;span class="m">31&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">EndPointState 10.0.0.3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> HeartBeatState: generation 1259912238, version &lt;span class="m">5&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;load-information&amp;#34;&lt;/span>: 12.0, generation 1259912238, version &lt;span class="m">3&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">EndPointState 10.0.0.4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> HeartBeatState: generation 1259912942, version &lt;span class="m">18&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;load-information&amp;#34;&lt;/span>: 6.7, generation 1259912942, version &lt;span class="m">3&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;normal&amp;#34;&lt;/span>: bj05IVc0lvRXw2xH, generation 1259912942, version &lt;span class="m">7&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>以及節點B (10.0.0.2)&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">EndPointState 10.0.0.1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> HeartBeatState: generation 1259909635, version &lt;span class="m">324&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;load-information&amp;#34;&lt;/span>: 5.2, generation 1259909635, version &lt;span class="m">45&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;bootstrapping&amp;#34;&lt;/span>: bxLpassF3XD8Kyks, generation 1259909635, version &lt;span class="m">56&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;normal&amp;#34;&lt;/span>: bxLpassF3XD8Kyks, generation 1259909635, version &lt;span class="m">87&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">EndPointState 10.0.0.2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> HeartBeatState: generation 1259911052, version &lt;span class="m">63&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;load-information&amp;#34;&lt;/span>: 2.7, generation 1259911052, version &lt;span class="m">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;bootstrapping&amp;#34;&lt;/span>: AujDMftpyUvebtnn, generation 1259911052, version &lt;span class="m">31&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;normal&amp;#34;&lt;/span>: AujDMftpyUvebtnn, generation 1259911052, version &lt;span class="m">62&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">EndPointState 10.0.0.3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> HeartBeatState: generation 1259812143, version &lt;span class="m">2142&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;load-information&amp;#34;&lt;/span>: 16.0, generation 1259812143, version &lt;span class="m">1803&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ApplicationState &lt;span class="s2">&amp;#34;normal&amp;#34;&lt;/span>: W2U1XYUC3wMppcY7, generation 1259812143, version &lt;span class="m">6&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h4 id="節點a-決定向節點b-發起-gossip">節點A 決定向節點B 發起 Gossip&lt;/h4>
&lt;p>產生的 GossipDigestSynMessage 會是類似於 &lt;code>10.0.0.1:1259909635:325 10.0.0.2:1259911052:61 10.0.0.3:1259912238:5 10.0.0.4:1259912942:18&lt;/code>，主要是傳送 &lt;code>Node IP:generation:version&lt;/code>&lt;/p>
&lt;h4 id="節點b-收到-gossipdigestsynmessage">節點B 收到 GossipDigestSynMessage&lt;/h4>
&lt;p>會有以下流程&lt;/p>
&lt;ol>
&lt;li>跟自己的狀態比較，從差異最多的遞減排序，這意味著優先處理差異最多的節點資訊&lt;/li>
&lt;li>接著檢驗每一個節點的資料
-節點A 所保存的 &lt;code>10.0.0.1:1259909635:325&lt;/code> 會大於節點B 所保存的&lt;code>10.0.0.1:1259909635:324&lt;/code>，generation 一樣所以略過，但是 version 325 &amp;gt; 324，則代表節點B 需要向節點 A 索取 10.0.0.1 在 ApplicationState 在版本 324 之後的資料
&lt;ul>
&lt;li>&lt;code>10.0.0.2:1259911052:61&lt;/code> 比節點B 保存的版本還要小，所以到時候會打包資料給節點A&lt;/li>
&lt;li>&lt;code>10.0.0.3:1259912238:5&lt;/code> 部分節點B generation 比較小，這意味著 10.0.0.3 有 reboot 過，所以節點B 需要更新全部的資料&lt;/li>
&lt;li>&lt;code>10.0.0.4:1259912942:18&lt;/code>節點B 根本沒有 10.0.0.4 的資料，所以需要全部的資料&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>組合以上結果 GossipDigestAckMessage的內容會是&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">10.0.0.1:1259909635:324
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">10.0.0.3:1259912238:0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">10.0.0.4:1259912942:0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">10.0.0.2:&lt;span class="o">[&lt;/span>ApplicationState &lt;span class="s2">&amp;#34;normal&amp;#34;&lt;/span>: AujDMftpyUvebtnn, generation 1259911052, version 62&lt;span class="o">]&lt;/span>, &lt;span class="o">[&lt;/span>HeartBeatState, generation 1259911052, version 63&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>這代表著&lt;/p>
&lt;ul>
&lt;li>請給我 10.0.0.1 在 generation 1259909635 中 version 324 以後的更新資料&lt;/li>
&lt;li>請給我 10.0.0.3 在 generation 1259912238 全部資料 (version:0)&lt;/li>
&lt;li>10.0.0.4 同上&lt;/li>
&lt;li>這是你需要更新關於 10.0.0.2 的 ApplicationState 資料&lt;/li>
&lt;/ul>
&lt;h4 id="節點a-回覆-gossipdigestack2message">節點A 回覆 GossipDigestAck2Message&lt;/h4>
&lt;p>節點A 收到後，更新完 10.0.0.2 的資訊後，接著回覆節點B 所要的資料&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">10.0.0.1:&lt;span class="o">[&lt;/span>ApplicationState &lt;span class="s2">&amp;#34;load-information&amp;#34;&lt;/span>: 5.2, generation 1259909635, version 45&lt;span class="o">]&lt;/span>, &lt;span class="o">[&lt;/span>ApplicationState &lt;span class="s2">&amp;#34;bootstrapping&amp;#34;&lt;/span>: bxLpassF3XD8Kyks, generation 1259909635, version 56&lt;span class="o">]&lt;/span>, &lt;span class="o">[&lt;/span>ApplicationState &lt;span class="s2">&amp;#34;normal&amp;#34;&lt;/span>: bxLpassF3XD8Kyks, generation 1259909635, version 87&lt;span class="o">]&lt;/span>, &lt;span class="o">[&lt;/span>HeartBeatState, generation 1259909635, version 325&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">10.0.0.3:&lt;span class="o">[&lt;/span>ApplicationState &lt;span class="s2">&amp;#34;load-information&amp;#34;&lt;/span>: 12.0, generation 1259912238, version 3&lt;span class="o">]&lt;/span>, &lt;span class="o">[&lt;/span>HeartBeatState, generation 1259912238, version 3&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">10.0.0.4:&lt;span class="o">[&lt;/span>ApplicationState &lt;span class="s2">&amp;#34;load-information&amp;#34;&lt;/span>: 6.7, generation 1259912942, version 3&lt;span class="o">]&lt;/span>, &lt;span class="o">[&lt;/span>ApplicationState &lt;span class="s2">&amp;#34;normal&amp;#34;&lt;/span>: bj05IVc0lvRXw2xH, generation 1259912942, version 7&lt;span class="o">]&lt;/span>, &lt;span class="o">[&lt;/span>HeartBeatState: generation 1259912942, version 18&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>這樣就完成一輪的 Gossip 了&lt;/p>
&lt;blockquote>
&lt;p>可以看出為什麼 HeartbeatState 的 version 會與 ApplicationState 共享，這邊的共享指的是在&lt;code>同一個節點下 ApplicationState 的 version 必須是獨一無二且遞增&lt;/code>，這樣才能在 SYN 時只傳送 HeartbeatState 直接判斷有哪些欄位需要更新&lt;/p>
&lt;/blockquote>
&lt;p>以上範例整理自 &lt;a class="link" href="https://cwiki.apache.org/confluence/display/CASSANDRA2/ArchitectureGossip" target="_blank" rel="noopener"
>ArchitectureGossip&lt;/a>&lt;/p>
&lt;h2 id="其他集群上的管理">其他集群上的管理&lt;/h2>
&lt;p>集群管理上，除了透過 Gossip Protocol 同步資訊外，還有幾個問題要解決&lt;/p>
&lt;ol>
&lt;li>誰在 Cluster 當中&lt;/li>
&lt;li>如何決定節點的狀態是 Up / Down，這又會帶來什麼影響&lt;/li>
&lt;li>何時要終止跟某節點的通訊&lt;/li>
&lt;li>應該要偏好與哪個節點通訓&lt;/li>
&lt;li>增加/移除/刪除/取代節點時如何實作&lt;/li>
&lt;/ol>
&lt;h3 id="誰在-cluster-當中">誰在 Cluster 當中&lt;/h3>
&lt;p>當一個新的節點要啟動時，他必須要知道集群中有哪些節點去 Gossip，在 Cassandra 的設定檔中可以指定 &lt;code>Seed&lt;/code>，有不同的作法可以指定，常見是寫死某一些節點的 ip addr，節點啟動後就跟 Seed 節點溝通，後續就透過 Gossip Protocol 取得所有節點的狀態與 IP&lt;/p>
&lt;blockquote>
&lt;p>在 Consul 中，會自己透過廣播在 LAN 裡面自動發現有沒有其他節點，在 EC2 上還可以指定 EC2 Tag 去找出其他節點&lt;/p>
&lt;/blockquote>
&lt;h3 id="failure-detection-決定節點是-up-或-down">Failure Detection: 決定節點是 Up 或 Down&lt;/h3>
&lt;p>在 Cassandra 中，錯誤偵測是該節點在本地端決定某節點的狀態，而這個狀態不會隨著 Gossip 所傳送&lt;/p>
&lt;blockquote>
&lt;p>ex.節點A 覺得節點B 是 Down，當節點A 跟節點C Gossip 時，節點C 不會因為節點A 而把節點B 判斷成 Down，節點 C 會自行判斷&lt;/p>
&lt;/blockquote>
&lt;p>偵測的方式透過 Heartbeat，Heartbeat 可以是節點跟節點直接用 Gossip 通訊，也可以是從其他節點間接取得 Gossip；&lt;br>
節點會計算每次 Heartbeat 的間隔，當超過 &lt;code>phi_convict_threshold&lt;/code> 則判定為 Down，系統需要因應硬體狀態/網路環境去調整閥值，避免太敏感誤判或是太遲鈍而反應不及等狀況&lt;/p>
&lt;p>在節點斷線的時候，其他節點部分的寫入可能因此沒有收到 ACK 回覆，此時會暫存在本地當作 Hint，如果節點在一定時間內恢復，則會透過 Hint 重新傳送寫入，修復掉資料的可能&lt;/p>
&lt;p>如果節點重新恢復時，其他節點會定期重送 Gossip 給 Offline 節點，屆時就能把 Down 調整回 Up&lt;/p>
&lt;h3 id="節點偏好">節點偏好&lt;/h3>
&lt;p>除了錯誤偵測外，Cassandra 內部有模組 Dynamic Snitch 專門做節點間的通訊品質偵測，每 100 ms計算與其他節點的延遲，藉此找出表現較好的節點；&lt;br>
為了避免一時網路波動，每 10 分鐘就會重新計算&lt;/p>
&lt;p>其餘的節點管理就暫時略過，對於理解 Gossip Protocol 不大&lt;/p>
&lt;h2 id="結語">結語&lt;/h2>
&lt;p>在分散式系統中，節點的狀態同步十分基礎且重要，而 Gossip Protocol 目前是被廣泛應用的解法，模擬人類傳送八卦的方式，想不到在機器也一樣適用&lt;br>
整體最有趣的設計應該在於 &lt;code>generation / version&lt;/code> 的實作，透過 generation 可以知道機器重啟過後要不要重新要資料；透過 version 可以快速 diff 僅有哪些資料要更新，避免額外的傳輸浪費，下一篇將從理論上去分析 Gossip Protocol&lt;/p></description></item><item><title>Redis Cluster 介紹</title><link>https://yuanchieh.page/posts/2020/2020-10-19-redis-cluster-%E4%BB%8B%E7%B4%B9/</link><pubDate>Mon, 19 Oct 2020 08:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2020/2020-10-19-redis-cluster-%E4%BB%8B%E7%B4%B9/</guid><description>&lt;p>雖然 Redis Cluster 推出已久，但公司最近才準備從 Sentinel 轉成 Cluster，架構上有不少的調整，以下閱讀文件 &lt;a class="link" href="https://redis.io/topics/cluster-spec" target="_blank" rel="noopener"
>Redis Cluster Specification&lt;/a>並摘要&lt;/p>
&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>可以由一至多個 replica 組成，每一個 replica 分配固定的 slot，透過 CRC 將 key 做 hash 後分配至固定的 replica，slot 總數固定在 &lt;code>16358&lt;/code> 個&lt;/p>
&lt;ol>
&lt;li>動態增加、刪除 replica，可以透過 Migrate 指令重新分配 slot&lt;/li>
&lt;li>任何一個 Node 都能夠接收 request，但沒有 proxy 功能，會透過 MOVED 回傳 client 正確的 Node&lt;/li>
&lt;li>&lt;code>可用性&lt;/code>，遭遇網路分割時多數群體可以活下來，條件是 replica 至少有任一 Master 存在 (從 Slave Promote 成 Master 也可以)&lt;/li>
&lt;/ol>
&lt;p>所有的單一key 指令支援 Cluster，如果是 multi-key 指令例如 set union 等，Redis 會產生 hash tag 強迫所有的 multi-key 分配到同一個 Node 上&lt;/p>
&lt;h3 id="node">Node&lt;/h3>
&lt;p>每個 Node 彼此互相透過 tcp 連接，稱為 Redis Cluster Bus，透過 gossip protocol 發現新的 node /ping 彼此 / 發送 cluster message 等&lt;/p>
&lt;p>每個 Node 都會有 &lt;code>160 bit亂數 ID&lt;/code>，即使 Cluster ip 位置改變，ID 也不會改變，除非是 config 檔被刪除或是 admin 強制替換
Node 之間是走 TCP 並透過 16739 port，Node 會與其他 Cluster 內的所有 Node 相連行程 &lt;code>full mesh (N-1 connection)&lt;/code>&lt;/p>
&lt;p>Clusert Node 會接受任意的連線，並回應任意的ping，但其他訊息只有&lt;code>被視為 cluster 一部分的 Node&lt;/code> 才會處理，否則直接丟棄
要加入 cluster 的驗證有兩種方式&lt;/p>
&lt;ol>
&lt;li>admin 使用 &lt;code>CLUSTER MEET ip port&lt;/code> 加入&lt;/li>
&lt;li>已經互相驗證過的 Node 口耳相傳，例如 A -&amp;gt; B 驗證過，B&amp;lt;-&amp;gt;C驗證過，則 B 會推薦 C 給 A，則 A&amp;lt;-&amp;gt;C 也能成功建立連線；
所以 Node 與任一被驗證的 Node 許可後，後續其他 Node 就能自動發現&lt;/li>
&lt;/ol>
&lt;p>整體的 Cluster Node 數量上限建議在 &lt;code>1000&lt;/code> 以內&lt;/p>
&lt;h3 id="寫入遺失">寫入遺失&lt;/h3>
&lt;p>因為是非同步副本，所以有小概率已經回傳成功給 client 的 write 會被覆蓋，Redis 採取 last failover wins，也就是最新的一個 Master 會覆寫其他副本的結果，所以會有一段空窗期遺失資料，空窗期長短要看發生網路分隔時 client 是連到多數還是少數群&lt;/p>
&lt;p>Master 寫入後，還來不及複製到 Slave 就死掉了，如果沒有在一定時間 ( NODE_TIMEOUT )內恢復，Slave 被 promote 成 Master 那寫入的結果就掉了；
而 Master 被 partition 隔開，在一段時間後 Master 發現自己連不到多數Master 就會停止接受寫入請求&lt;/p>
&lt;h3 id="可用性">可用性&lt;/h3>
&lt;p>例如說目前有 N 個 Master ，且對應搭配 N 個 Slave (1對1)，假設有任一個 Node 掛掉，目前為 &lt;code>2N - 1&lt;/code>&lt;/p>
&lt;p>此時如果剛好殘存的 replica 那一個 Node 死去，整個 Cluster 才算掛掉，反之就能繼續運作，因為會有一部分的 slot 沒有 Node 負責&lt;br>
所以 &lt;code>avalaibility 是 1 / (2N-1)&lt;/code>&lt;/p>
&lt;h3 id="效能">效能&lt;/h3>
&lt;p>因為 Node 沒有 Proxy 功能，所以只會跟 client 說正確的 Node 在哪，接著 client 要再發起一次 request 才能完成操作，最終 client 會知道所有的操作該去哪個 Node；&lt;br>
基本上不太需要擔心效能問題，假設 Cluster 有 N 個 Master，負載能力基本上可以視為單機 * N，雖然有上述在第一次要多查一次的問題，但因為 Client 對於每個 Cluster Master 都保持 TCP 長連結，所以不至於太擔心&lt;/p>
&lt;h3 id="分散式模型">分散式模型&lt;/h3>
&lt;p>redis 將 key space 切割成 16384 等分 &lt;code>HASH_SLOT = CRC16(key) mod 16384&lt;/code>，分配後會固定，該 slot 就會由同一個 Node 負責，直到有 reconfig 的指令；&lt;/p>
&lt;p>hash tag 是一個分散的例外，主要是為了支援 &lt;code>multi-key&lt;/code> 可以分配到同一個 hash slot 上，如果 key 包含 {} ，則 hash key 產生是key 裡面第一組 {…} 中間的值 (沒有包含 {})&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c++" data-lang="c++">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">unsigned&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="nf">HASH_SLOT&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">char&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">key&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">keylen&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">int&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">s&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">s&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">keylen&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="o">++&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">key&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="sc">&amp;#39;{&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">break&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="cm">/* 沒有找到 {，則 hash 整個字串 */&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">s&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">keylen&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="n">crc16&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">key&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">keylen&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;amp;&lt;/span> &lt;span class="mi">16383&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="cm">/* 找到 { */&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">e&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">e&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">keylen&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="o">++&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">key&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">e&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="sc">&amp;#39;}&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">break&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="cm">/* 沒有找到 }，hash 整個字串 */&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">e&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">keylen&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="n">e&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">s&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="n">crc16&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">key&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">keylen&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;amp;&lt;/span> &lt;span class="mi">16383&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="cm">/* 如果有 {} 配對，則 key 取 {...} 之間的字串 */&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">crc16&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">key&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">e&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;amp;&lt;/span> &lt;span class="mi">16383&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="resharding">Resharding&lt;/h2>
&lt;p>Redis Cluster 在管理上以及使用上都有相當大的彈性，Cluster 可以任意增減 Node 數量以及調整 Slot 對應的 Node；而 Redis Client 可以與任意的 Node 連線&lt;/p>
&lt;p>如果 Node 收到 Client request 後&lt;/p>
&lt;ol>
&lt;li>如果該資料屬於他的 slot，則直接處理&lt;/li>
&lt;li>反之則找出哪個 Node 應該負責，回傳 Moved 錯誤給 Client &lt;code>-MOVED 3999 127.0.0.1:6381&lt;/code>，這代表 key 在 slot 3999，正確的 Node 是 127.0.0.1:6381&lt;/li>
&lt;/ol>
&lt;p>Client 在每次收到 MOVED 後都應該去記住哪一個 slot 對應哪一個 Node，這樣可以增加效率；&lt;br>
又直接拉下整張 mapping，用 &lt;code>$cluster nodes&lt;/code> 找出所以的 node，並結合 &lt;code>$cluster slots&lt;/code> 直接查看 cluster 完整對照表，就可以完整知道 node 對應的 slot 以及 node ip 位置與 id&lt;/p>
&lt;h3 id="rebalance">Rebalance&lt;/h3>
&lt;p>Cluster 可以在運行中增減 Node，並且會自動搬移資料並更新 slot mapping，有幾個 command 可以動態影響 Node 與 Slot&lt;/p>
&lt;ol>
&lt;li>&lt;code>addslot&lt;/code> : 指定 Node 增加 slot&lt;/li>
&lt;li>&lt;code>delslot&lt;/code> : 移除 slot，原本負責的 Node 會遺忘這個 slot&lt;/li>
&lt;li>&lt;code>setslot&lt;/code> : 轉移 slot&lt;/li>
&lt;/ol>
&lt;p>轉移的部分比較複雜，會需要先去調整 Node 狀態，例如說希望將 slot 8從 Node A 轉到 Node B&lt;/p>
&lt;ol>
&lt;li>在 Node B 上指定資料會從 Node A 過來: &lt;code>$CLUSTER SETSLOT 8 IMPORTING A&lt;/code>&lt;/li>
&lt;li>在 Node A 上指定要把 slot 8 轉移到 Node B 上: &lt;code>$CLUSTER SETSLOT 8 MIGRATING B&lt;/code>&lt;/li>
&lt;li>之後有一個背景程式 &lt;code>redis-trib&lt;/code> 會主動將 slot 逐步搬移&lt;/li>
&lt;/ol>
&lt;p>也可以手動轉移&lt;/p>
&lt;ol>
&lt;li>列出該 slot 一定數量的 hash key: &lt;code>$CLUSTER GETKEYSINSLOT slot count&lt;/code>&lt;/li>
&lt;li>將這些 key 轉移: &lt;code>$MIGRATE target_host target_port key target_database id timeout&lt;/code>，Migrate 會在轉移成功後才移除 Node B 的紀錄&lt;/li>
&lt;/ol>
&lt;p>過程可參考此問答 &lt;a class="link" href="https://stackoverflow.com/questions/53080371/redis-cluster-live-reshard-failure" target="_blank" rel="noopener"
>Redis cluster live reshard failure&lt;/a>&lt;/p>
&lt;h3 id="轉移過程">轉移過程&lt;/h3>
&lt;p>在轉移過程中，client 針對搬移中與搬入中的 Node 發出 Request 反應會有所不同&lt;/p>
&lt;ol>
&lt;li>搬出中的 Node : &lt;br>
a. 如果 key 還在 Node中 則直接處理 &lt;br>
b. 不再則回傳 &lt;code>ASK&lt;/code> 錯誤，Client 接著必先向新的 Node 發出 &lt;code>ASKING&lt;/code>，接著才傳送 Request&lt;/li>
&lt;li>搬入中的 Node : 只處理有先傳送 ASKING 的請求，其餘回傳 MOVED 錯誤&lt;/li>
&lt;/ol>
&lt;p>這樣的目的是為了方便轉移過程，&lt;code>New Key 一定是在搬入中 Node產生&lt;/code>，Migrate 則只需要處理 Old Key&lt;/p>
&lt;blockquote>
&lt;p>已經有 MOVED 錯誤碼仍然需要 ASK 的原因是 ASK 是一次性請求，我們會希望在搬移過程，假設 Client 如果有 slot 8 的請求，應該先去問 A 再去問 B，如果 A 沒有會用 ASK 轉去 B；&lt;br>
MOVED 代表的是往後的永久性所有針對 slot 8 的請求都去 Node B，但顯然還在 migrate 的話會有大量的 key 還沒搬移，所以用 ASK 一次性的查詢當作過度&lt;/p>
&lt;/blockquote>
&lt;p>如果是 multi-key 操作，假設 key 分散在兩個 node 之間，則會收到 &lt;code>TRYAGAIN&lt;/code> 錯誤&lt;/p>
&lt;h2 id="fault-tolerance">Fault Tolerance&lt;/h2>
&lt;p>Node 會發送 &lt;code>ping / pong&lt;/code> 去確認其他 Node 是否還存活，兩者合併又稱 &lt;code>heartbeat&lt;/code>，除了 ping 會觸發 pong 回復外，如果 Node 有 config 檔更新，也會主動發送 pong 給其他 Node&lt;/p>
&lt;p>在半個 &lt;code>NODE_TIMEOUT&lt;/code> 時間內，Node 會送 ping 給其他所有的 Node 確保存活，在 NODE_TIMEOUT 時間點到前，Node 還會重新與其他 Node 建立 TCP 連線，確保ping 沒收到不是剛好這一次的 TCP 連線有問題&lt;/p>
&lt;blockquote>
&lt;p>所以 packet 交換數量與 Node 數量和 NODE_TIMEOUT 時間有關，例如 100 Node + 60 sec 的 timeout，則每一個 Node 30 sec 內會送 99 個ping 給其他 Node，換算後整個 cluster 是每秒 330ping&lt;/p>
&lt;/blockquote>
&lt;p>heartbeat 封包共用 Header 大致如下&lt;/p>
&lt;ol>
&lt;li>NodeID: 160 bit 識別碼&lt;/li>
&lt;li>currentEpoch: 遞增數字，用來表示訊息的先後順序&lt;/li>
&lt;li>flag: 是 Master 還是 Slave&lt;/li>
&lt;li>bitmap: 用來表示負責的 slot&lt;/li>
&lt;li>sender 的 tcp port&lt;/li>
&lt;li>sender 認為 Cluter 是否還在運行&lt;/li>
&lt;li>如果是 Slave 則需要包含 Master NodeID&lt;/li>
&lt;/ol>
&lt;h3 id="fault-detection">Fault Detection&lt;/h3>
&lt;p>在 Cluster 中，一個 Node 被判定錯誤是經由多數的 Node 所決定；&lt;br>
而如果發生錯誤的是 Master，且沒有 Slave 被成功升級成 Master，則此時 Cluster 進入錯誤狀態，停止 Client 的請求&lt;/p>
&lt;p>Node 在時間內會隨機對數個 Node 發送ping 請求，此時如果超過 &lt;code>NODE_TIMEOUT&lt;/code> 都沒收到 pong，則會標記該 Node 為 &lt;code>PFAIL&lt;/code>，此時的 PFAIL 並不會觸發任何機制；&lt;br>
當 Node 在回覆 pong 時，會把自己所維護的&lt;code>hash slot map&lt;/code>也一並發送，所以每個 Node 在一定的時間內都會知道其他 Node 所維護的標記狀態清單&lt;/p>
&lt;p>假設 Node A 標記 Node B 為 PFAIL，接著 Node A 收到來自其他 Master Node 對於 Node B 的標記，如果在 &lt;code> NODE_TIMEOUT * FAIL_REPORT_VALIDITY_MULT&lt;/code> 等待時間內，大多數的 Master 也都標記 Node B 為 PFAIL 或是 FAIL，則 Node A 轉標記 Node B 為 &lt;code>FAIL&lt;/code>&lt;/p>
&lt;p>被標記成 FAIL 幾乎是不可逆，除了下述情況&lt;/p>
&lt;ol>
&lt;li>Node 是 Slave 且可以被連上&lt;/li>
&lt;li>Node 是 Master 且可以被連上，同時沒有分配到任何 slot，此時會等待被加入 Cluster&lt;/li>
&lt;li>Node 是 Master 且可以被連上，同時 Cluster 過很長一段時間都沒有 Slave 被 Promote 成功，則可以考慮重新加入 Cluster&lt;/li>
&lt;/ol>
&lt;p>透過這樣的設計，最終 Cluster 中每一個節點的狀態都會是被同步的&lt;/p>
&lt;h2 id="configuration-handling-propagation-and-failovers">Configuration handling, propagation, and failovers&lt;/h2>
&lt;p>這一章節主要談 Slave promotion 的過程&lt;/p>
&lt;h3 id="cluster-current-epoch">Cluster current epoch&lt;/h3>
&lt;p>在分散式系統中，必須有個方式決定重複或是衝突的事件該選擇哪一個，Redis Cluster 中採用 &lt;code>epoch&lt;/code> (對比 Raft 中的 term) 是一個 64 bit unsigned int，初始化 Master / Slave 都是 0，在發送訊息時加 1，在收到訊息時如果對方的 epoch 高於自己，則更新 epoch 並加 1；&lt;br>
遇到有衝突，則選擇 epoch 較高的那一則訊息&lt;/p>
&lt;p>Master 在發送 ping 時會夾帶 configEpoch 且在回 pong 時會夾帶所屬的 slot mapping&lt;/p>
&lt;h3 id="promotion-過程">Promotion 過程&lt;/h3>
&lt;p>如果符合以下條件&lt;/p>
&lt;ol>
&lt;li>Master Node 失敗&lt;/li>
&lt;li>Master 有負責 slot&lt;/li>
&lt;li>Slave 並沒有與 Master 失聯超過一定時間，這個判定是為了避免 Slave 的資料太舊&lt;/li>
&lt;/ol>
&lt;p>則 Slave 會準備提起 Promotion，此時會增加 configEpoch 值，並希望取得多數 Master 的同意，發送 &lt;code>FAILOVER_AUTH_REQUEST&lt;/code> 給 Master Nodes，接著 Slave 會等待 2 * NODE_TIMEOUT&lt;/p>
&lt;p>此時 Master 如果同意，則回覆 &lt;code>FAILOVER_AUTH_ACK&lt;/code>，此時 Master 在接下來的 2 * NODE_TIMEOUT 不可以回覆其他 Slave Node FAILOVER_AUTH_ACK 訊息，避免多個 Slave 同時投票&lt;/p>
&lt;p>如果 Slave 在 2 * NODE_TIMEOUT 內收到多數 Master 同意，則選舉通過；&lt;br>
反之如果失敗，則 4 * NODE_TIMEOUT 後開始下一次選舉&lt;/p>
&lt;h3 id="hash-slot-維護">Hash Slot 維護&lt;/h3>
&lt;p>先前提到 Master 在送 pong 時會把自己管理的 slot 也一併更新，此時的 slot 會夾帶目前 Master 的 epoch 資訊，例如以下&lt;/p>
&lt;ol>
&lt;li>Cluster 初始化，此時 Slot 都沒有對應的 Master，需要 &lt;code>CLUSTER ADDSLOTS&lt;/code> 分配&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="m">0&lt;/span> -&amp;gt; NULL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="m">1&lt;/span> -&amp;gt; NULL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="m">2&lt;/span> -&amp;gt; NULL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="m">16383&lt;/span> -&amp;gt; NULL
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="2">
&lt;li>假設分配部分給 A，A 會順便標記 epoch，假設此時值為 3&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="m">0&lt;/span> -&amp;gt; NULL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="m">1&lt;/span> -&amp;gt; A &lt;span class="o">[&lt;/span>3&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="m">2&lt;/span> -&amp;gt; A &lt;span class="o">[&lt;/span>3&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="m">16383&lt;/span> -&amp;gt; NULL
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="3">
&lt;li>產生 Failover，B 上來頂替 A，此時會把 &lt;code>epoch + 1&lt;/code>&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="m">0&lt;/span> -&amp;gt; NULL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="m">1&lt;/span> -&amp;gt; B &lt;span class="o">[&lt;/span>4&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="m">2&lt;/span> -&amp;gt; B &lt;span class="o">[&lt;/span>4&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="m">16383&lt;/span> -&amp;gt; NULL
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>這也就是 &lt;code>last failover wins&lt;/code> 策略，假使 A 此時網路連線回來要宣稱自己是 Master 也會被擋下來，因為 A 的 epoch 比較小&lt;/p>
&lt;h4 id="實際案例">實際案例&lt;/h4>
&lt;p>假設 Master 已經掛了，此時有 A,B,C 三個 Slave&lt;/p>
&lt;ol>
&lt;li>A 競選成功變成了 Master&lt;/li>
&lt;li>網路區隔關係，A 被視為錯誤&lt;/li>
&lt;li>B 因此競選而成 Master&lt;/li>
&lt;li>接著換 B 被網路區隔&lt;/li>
&lt;li>此時 A 成功連線回來&lt;/li>
&lt;/ol>
&lt;p>此時 B 失聯，A 以為自己還是 Master，此時 C 因為 B 失聯會想要去競選 Master&lt;/p>
&lt;ol>
&lt;li>此時 C 會成功，因為其他的 Master 知道 C 的 Master(B) 已經失敗&lt;/li>
&lt;li>A 無法宣稱自己是 Master ，因為 hash slot 已經被更新成 B 的 epoch （第三步)，且 B 的 epoch 高於 A 的 epoch&lt;/li>
&lt;li>接著 C 會更新 hash slot 的 epoch，Cluster 持續運作&lt;/li>
&lt;/ol>
&lt;h2 id="結論">結論&lt;/h2>
&lt;p>整個看過 Redis Cluster Spec 會對於實際操作比較有信心，下一篇來自己實際架設看看&lt;/p>
&lt;p>有一些細節比較瑣碎就跳過，有些章節讀起來比較不通順，自己重新理解後編排一下 (OS. 可能會變得更難理解 ?!&lt;/p></description></item><item><title>使用 Redis 當作 API Rate limit 的三種方法</title><link>https://yuanchieh.page/posts/2020/2020-10-18-%E4%BD%BF%E7%94%A8-redis-%E7%95%B6%E4%BD%9C-api-rate-limit-%E7%9A%84%E4%B8%89%E7%A8%AE%E6%96%B9%E6%B3%95/</link><pubDate>Sun, 18 Oct 2020 08:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2020/2020-10-18-%E4%BD%BF%E7%94%A8-redis-%E7%95%B6%E4%BD%9C-api-rate-limit-%E7%9A%84%E4%B8%89%E7%A8%AE%E6%96%B9%E6%B3%95/</guid><description>&lt;p>最近公司 API 服務被 Client 不預期的高頻存取，造成後端 DB 很大的負擔，開始評估各種 API Rate Limit 的方案，其中一個最常見的作法就是靠 Redis，但具體的方案其實有蠻多種，參考以下影片整理三種作法&lt;/p>
&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/HnSb8DFU5UA"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;p>順便推薦一下 RedisLabs 所推出的 GUI 管理工具 &lt;code>RedisInsights&lt;/code>，可以快速分析 Redis 中 Key Space 的使用 / Profiling 一段時間內哪些 Key 被大量存取等等，基本的 Redis CLI 操作就更不用提了，對比之前用的 &lt;code>medis&lt;/code> 功能強化不少，尤其是&lt;code>管理/監控這一塊的功能&lt;/code>&lt;br>
目前是免費的，支援 Cluster Mode，連接 AWS ElasticCache 也沒問題，十分推薦&lt;/p>
&lt;h2 id="rate-limit-全觀">Rate Limit 全觀&lt;/h2>
&lt;p>要設計 Rate Limit 機制時需要考量幾個面向&lt;/p>
&lt;h3 id="who">Who&lt;/h3>
&lt;p>該如何識別要限制的對象？&lt;br>
最直覺是透過 IP，但是使用 IP 最大的風險是 如果是大客戶，他一個人的流量遠超過其他小客戶，對公司的價值顯然也是遠遠重要，如果用 IP 很容易有誤殺的情況，把有價值的用戶阻擋在外&lt;/p>
&lt;p>其他的作法可以用 JWT Token / API Key 等個別用戶識別的方式，需要針對自家的業務場景去判斷&lt;/p>
&lt;h3 id="how">How&lt;/h3>
&lt;p>該使用怎樣的方式計算限制的方式？&lt;br>
通常是在某個時間區段內，限制只能存取多少次的計算模式，有三種方式可以參考&lt;/p>
&lt;h3 id="static-time-window---固定時間區段">static time window - 固定時間區段&lt;/h3>
&lt;p>例如說每一分鐘為一個單位，這一分鐘內只能存取五次&lt;br>
這樣的方式十分簡單，但可能會有短時間內超量的問題，例如說 0:59 存取 4 次，接著 1:01 存取4 次，分開在兩個時間區段都是合法，但是才隔兩秒就存取 8 次，這可能不會是希望的結果&lt;/p>
&lt;p>實作方式，以目前每週 160 k 下載的 &lt;code>express-rate-limit&lt;/code> 中 redis 版本 &lt;a class="link" href="https://www.npmjs.com/package/rate-limit-redis" target="_blank" rel="noopener"
>rate-limit-redis&lt;/a> 是以下做法&lt;/p>
&lt;ol>
&lt;li>先計算出該時間段的鍵值，例如 01:00 ~ 01:59 的鍵值都是 &lt;code>01&lt;/code>&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">var&lt;/span> &lt;span class="nx">expiryMs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">Math&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">round&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1000&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="nx">options&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">expiry&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="2">
&lt;li>增加 key 並更新 ttl 時間，incr 會回傳當下增加後的值，藉此判斷是否超過限制&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">options&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">client&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">multi&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">.&lt;/span>&lt;span class="nx">incr&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">rdskey&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">.&lt;/span>&lt;span class="nx">pttl&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">rdskey&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">.&lt;/span>&lt;span class="nx">exec&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>因為有 ttl，所以不用擔心 key 的刪除，這個方法簡單直覺儲存成本也很低&lt;/p>
&lt;p>為了嚴格限制&lt;code>任意時間區段內的最大存取數量&lt;/code>，參考以下文章提及兩種做法 &lt;a class="link" href="https://engineering.classdojo.com/blog/2015/02/06/rolling-rate-limiter/" target="_blank" rel="noopener"
>Better Rate Limiting With Redis Sorted Sets
&lt;/a>&lt;/p>
&lt;h3 id="token-bucket">token bucket&lt;/h3>
&lt;p>每一個用戶都有一個對應的 bucket，只有 token 足夠時可以進行操作，每隔一段時間會回補 token 數量，好處是可以制定多種操作的 token 需要數量，像是更繁雜的操作需要消耗更多的 token ，更有彈性應對不同的限制方案&lt;/p>
&lt;p>資料結構使用 Redis 的 &lt;code>Hash&lt;/code>，演算法大致如下&lt;/p>
&lt;ol>
&lt;li>用戶要操作的時候，如果此時沒有紀錄，先插入一筆 Hash &lt;code>user: 當下 的 timestamp =&amp;gt; token 初始化數量&lt;/code>&lt;/li>
&lt;li>後續操作時，取出上一次操作的 timestamp，接著回補這一段時間需要補充的 Token 數量&lt;/li>
&lt;li>接著扣除操作所需的 Token 數，查看是否有符合限制&lt;/li>
&lt;/ol>
&lt;p>需注意這種做法會有 &lt;code>Race Condition&lt;/code> 問題，如果一個用戶同時有兩個操作，在第三步驟檢查時，會誤以為自己都有足夠的 token，除非使用 &lt;code>Lua script&lt;/code>，Redis 才會將&lt;code>多個操作視為 atomic 避免 Race Condition&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/BitMEX/node-redis-token-bucket-ratelimiter" target="_blank" rel="noopener"
>node-redis-token-bucket-ratelimiter&lt;/a> 便是採用 Lua script 作法，讓我們來欣賞一下&lt;/p>
&lt;ol>
&lt;li>取得參數，並指定 &lt;code>redis.replicate_commands()&lt;/code>，這是在調用 &lt;code>$ redis eval&lt;/code> 時要產生隨機 IO 時需要提前執行的指令 &lt;a class="link" href="https://redis.io/commands/eval" target="_blank" rel="noopener"
>Redis - EVAL script numkeys key&lt;/a>，這一篇有易懂的解釋 &lt;a class="link" href="http://mysql.taobao.org/monthly/2019/01/06/" target="_blank" rel="noopener"
>Redis · 引擎特性 · Lua脚本新姿势&lt;/a>，基本上就是為了符合 Redis 在持久化以及副本資料時的功能，在 5.0 以後是默認選項； &lt;br>
接著就是分別計算上一次更新時間 &lt;code>initialUpdateMS&lt;/code> / 殘留的 token 數 &lt;code>prevTokens&lt;/code>&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-lua" data-lang="lua">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">-- valueKey timestampKey | limit intervalMS nowMS [amount]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">valueKey&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">KEYS&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="c1">-- &amp;#34;limit:1:V&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">timestampKey&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">KEYS&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="c1">-- &amp;#34;limit:1:T&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">limit&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tonumber&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ARGV&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">intervalMS&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tonumber&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ARGV&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">amount&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">math.max&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tonumber&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ARGV&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">]),&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">force&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ARGV&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s2">&amp;#34;true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">lastUpdateMS&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">prevTokens&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">-- Use effects replication, not script replication;; this allows us to call &amp;#39;TIME&amp;#39; which is non-deterministic&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">redis.replicate_commands&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">time&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">redis.call&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;TIME&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">nowMS&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">math.floor&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">time&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">1000&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">time&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="mi">1000&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">initialTokens&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">redis.call&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;GET&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">valueKey&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">initialUpdateMS&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">false&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">if&lt;/span> &lt;span class="n">initialTokens&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="kc">false&lt;/span> &lt;span class="kr">then&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">-- If we found no record, we temporarily rewind the clock to refill&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">-- via addTokens below&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">prevTokens&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">lastUpdateMS&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nowMS&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">intervalMS&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">else&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">prevTokens&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">initialTokens&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">initialUpdateMS&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">redis.call&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;GET&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">timestampKey&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">if&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">initialUpdateMS&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="kc">false&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="kr">then&lt;/span> &lt;span class="c1">-- this is a corruption&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">-- 如果資料有問題，需要回推 lastUpdateMS 時間，也就是用現在時間回推殘存 Token 數量的回補時間&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">lastUpdateMS&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">nowMS&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="p">((&lt;/span>&lt;span class="n">prevTokens&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">limit&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">intervalMS&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">else&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">lastUpdateMS&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">initialUpdateMS&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">end&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">end&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="2">
&lt;li>接著計算上一次到現在需要回補的 Token &lt;code>addTokens&lt;/code> / 這一次運算配額夠不夠 &lt;code>netTokens&lt;/code> / 如果下一次要嘗試需要等多久的時間 &lt;code>retryDelta&lt;/code>&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-lua" data-lang="lua">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">addTokens&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">math.max&lt;/span>&lt;span class="p">(((&lt;/span>&lt;span class="n">nowMS&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">lastUpdateMS&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">intervalMS&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">limit&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">-- calculated token balance coming into this transaction&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">grossTokens&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">math.min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">prevTokens&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">addTokens&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">limit&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">-- token balance after trying this transaction&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">netTokens&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">grossTokens&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">amount&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">-- time to fill enough to retry this amount&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">retryDelta&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">rejected&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">false&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">local&lt;/span> &lt;span class="n">forced&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">false&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">if&lt;/span> &lt;span class="n">netTokens&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="kr">then&lt;/span> &lt;span class="c1">-- we used more than we have&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">if&lt;/span> &lt;span class="n">force&lt;/span> &lt;span class="kr">then&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">forced&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">true&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">netTokens&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="c1">-- drain the swamp&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">else&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">rejected&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">true&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">netTokens&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">grossTokens&lt;/span> &lt;span class="c1">-- rejection doesn&amp;#39;t eat tokens&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">end&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">-- == percentage of `intervalMS` required before you have `amount` tokens&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">retryDelta&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">math.ceil&lt;/span>&lt;span class="p">(((&lt;/span>&lt;span class="n">amount&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">netTokens&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">limit&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">intervalMS&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">else&lt;/span> &lt;span class="c1">-- polite transaction&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">-- nextNet == pretend we did this again...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">local&lt;/span> &lt;span class="n">nextNet&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">netTokens&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">amount&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">if&lt;/span> &lt;span class="n">nextNet&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="kr">then&lt;/span> &lt;span class="c1">-- ...we would need to wait to repeat&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">-- == percentage of `invervalMS` required before you would have `amount` tokens again&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">retryDelta&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">math.ceil&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">math.abs&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">nextNet&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">limit&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">intervalMS&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">end&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">end&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="3">
&lt;li>如果成功操作 ( rejected == false )，則延長 key 的過期時間&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-lua" data-lang="lua">&lt;span class="line">&lt;span class="cl">&lt;span class="kr">if&lt;/span> &lt;span class="n">rejected&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="kc">false&lt;/span> &lt;span class="kr">then&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">redis.call&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;PSETEX&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">valueKey&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">intervalMS&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">netTokens&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">if&lt;/span> &lt;span class="n">addTokens&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="mi">0&lt;/span> &lt;span class="ow">or&lt;/span> &lt;span class="n">initialUpdateMS&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="kc">false&lt;/span> &lt;span class="kr">then&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">-- we filled some tokens, so update our timestamp&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">redis.call&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;PSETEX&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">timestampKey&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">intervalMS&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">nowMS&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">else&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">-- we didn&amp;#39;t fill any tokens, so just renew the timestamp so it survives with the value&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">redis.call&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;PEXPIRE&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">timestampKey&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">intervalMS&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">end&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">end&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="sliding-time-window---滑動時間區段">sliding time window - 滑動時間區段&lt;/h3>
&lt;p>最後一個是使用 sorted set，可以使用 &lt;code>$ redis.multi&lt;/code> 將多個 sorted set 的指令串再一起 Atomic 執行所以能夠避免 Race Condition 狀況&lt;br>
具體想法是&lt;/p>
&lt;ol>
&lt;li>用一個 sorted set 儲存所有的 timestamp&lt;/li>
&lt;li>request 進來後，先用 &lt;code>ZREMRANGEBYSCORE&lt;/code> 捨棄 time window 以外的 key&lt;/li>
&lt;li>取得 sorted set 剩餘的所有元素 &lt;code>ZRANGE(0, -1)&lt;/code>&lt;/li>
&lt;li>加上這一次的操作 &lt;code>ZADD&lt;/code>，並延長 sorted set 的 ttl&lt;/li>
&lt;li>接著算整個 sorted set 的元素量，就知道存取幾次了&lt;/li>
&lt;/ol>
&lt;p>需要特別注意，這邊如果第五步判斷失敗也會被計算在 limit 當中，因為第四步已經先加上去了，如果&lt;code>在第三步先判斷數量夠不夠再去更新 sorted set，中間的時間差就有可能發生 Race Condition&lt;/code>，所以要嚴格限制必須要這麼做，除非又要包成 lua script&lt;/p>
&lt;p>這會導致一個風險，如果 Client 真的失控一直打，那他會無止盡的失敗，因為每一次的失敗操作都會被加入 sorted set 當中，但其實都沒有真的執行到&lt;/p>
&lt;p>模組請參考 &lt;a class="link" href="https://github.com/peterkhayes/rolling-rate-limiter" target="_blank" rel="noopener"
>rolling-rate-limiter&lt;/a>，程式碼在這&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="kr">const&lt;/span> &lt;span class="nx">batch&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">client&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">multi&lt;/span>&lt;span class="p">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">batch&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">zremrangebyscore&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">key&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">clearBefore&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">addNewTimestamp&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">batch&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">zadd&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">key&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">String&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">now&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="nx">uuid&lt;/span>&lt;span class="p">());&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">batch&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">zrange&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">key&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;WITHSCORES&amp;#39;&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">batch&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">expire&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">key&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">ttl&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">return&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="nb">Promise&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="nx">resolve&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">reject&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">=&amp;gt;&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">batch&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">exec&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="nx">err&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">result&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">=&amp;gt;&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">err&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="nx">reject&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">err&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// 加完後才來計算是不是扣打足夠
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="kr">const&lt;/span> &lt;span class="nx">zRangeOutput&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">addNewTimestamp&lt;/span> &lt;span class="o">?&lt;/span> &lt;span class="nx">result&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="nx">result&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="nx">as&lt;/span> &lt;span class="nb">Array&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="nx">unknown&lt;/span>&lt;span class="o">&amp;gt;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">zRangeResult&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">getZRangeResult&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">zRangeOutput&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">timestamps&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">extractTimestampsFromZRangeResult&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">zRangeResult&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="nx">resolve&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">timestamps&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="結論">結論&lt;/h2>
&lt;p>Rate Limit 看似簡單，但也有不少的眉角要去考量，之前一直都沒有客製 Redis 中 lua script 的部分，也是蠻有趣的&lt;/p></description></item><item><title>Elasticsearch 教學 - API 操作</title><link>https://yuanchieh.page/posts/2020/2020-07-15-elasticsearch-%E6%95%99%E5%AD%B8-api-%E6%93%8D%E4%BD%9C/</link><pubDate>Wed, 15 Jul 2020 08:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2020/2020-07-15-elasticsearch-%E6%95%99%E5%AD%B8-api-%E6%93%8D%E4%BD%9C/</guid><description>&lt;p>以下內容包含基本的 CRUD 操作，Elasticsearch 提供良好的 REST API 呼叫介面，以下模擬情境為書店，旗下有 amazon / eslite 多家書店，每一書店儲存書本相關的資料，如書名、頁數、簡介等&lt;/p>
&lt;p>另外還有一些系統配置與進階功能，看到 Alias 功能覺得十分有趣，讓維運有更多的彈性跟方法去調整資料儲存與硬體架構&lt;/p>
&lt;p>如果想之前架構層面，可以參考 &lt;a class="link" href="https://yuanchieh.page/post/2020/2020-07-08_elasticsearch-%E4%BB%8B%E7%B4%B9%E8%88%87%E8%A9%95%E4%BC%B0/" target="_blank" rel="noopener"
>Elasticsearch 系統介紹與評估&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>基本名詞解釋，Index = MongoDB 的 Collection / MySQL 的 Table；
Document = MongoDB Document / MySQL Row&lt;/p>
&lt;/blockquote>
&lt;h2 id="基本操作-crud">基本操作 CRUD&lt;/h2>
&lt;h3 id="常見的回傳值">常見的回傳值&lt;/h3>
&lt;p>不論請求是否成功，通常會返回 _index / _type / _id / _version / _shard 等資訊&lt;br>
&lt;code>_version&lt;/code> 是用來追蹤 document 被改動的次數；&lt;br>
&lt;code>_found&lt;/code> 代表文件是否存在&lt;/p>
&lt;h3 id="建立">建立&lt;/h3>
&lt;ol>
&lt;li>如果系統已經有規劃 _id&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ curl -XPUT http://localhost:9200/amazon/book/1?op_type&lt;span class="o">=&lt;/span>create
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="2">
&lt;li>如果沒有 _id 則由 Elasticsearch 生成，預設生成的 &lt;code>_id 是 22字元長 + Base64 編碼 + URL 合法的字串&lt;/code>&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ curl -XPOST http://localhost:9200/amazon/book
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="刪除">刪除&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ curl -XDELETE http://localhost:9200/amazon/book/1
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>可以看到回傳值 _version 也會被增加&lt;/p>
&lt;h3 id="更新--部分更新">更新 / 部分更新&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">$ curl -XPUT http://localhost:9200/amazon/book/1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">// 部分更新
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ curl -XPOST http://localhost:9200/amazon/book/1/_update
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>對 Elasticsearch 來說，所有的資料都是不可變的，所以更新其實是建立新的文檔並刪除舊的&lt;/p>
&lt;p>另外有個動詞是 &lt;code>Indexing&lt;/code>，也就是建立與更新合在一起，沒有文檔時建立、存在時就更新&lt;/p>
&lt;h4 id="scripting">scripting&lt;/h4>
&lt;p>有時候我們會希望基於現有的 document 欄位進行更新，例如說瀏覽次數 +1 等等的功能，可以透過 scripting 語法&lt;br>
如&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">curl -XPOST curl http://localhost:9200/amazon/book/iVKeNXMBpRlP8dKifEma/_update -H &lt;span class="s1">&amp;#39;Content-Type: application/json&amp;#39;&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>-d &lt;span class="s1">&amp;#39;{ &amp;#34;script&amp;#34;: &amp;#34;ctx._source.page_num += 1&amp;#34; }&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>在 Body 中夾帶 &lt;code>script&lt;/code>，並指定欄位與操作即可，像這邊我是將書籍的頁面 +1&lt;/p>
&lt;h4 id="upsert">upsert&lt;/h4>
&lt;p>有時候欄位要更新時可能不存在，可以透過 upsert 指定欄位不存在時的行為&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="s1">&amp;#39;{ &amp;#34;script&amp;#34;: &amp;#34;ctx._source.page_num += 1&amp;#34;, &amp;#34;upsert&amp;#34;: { &amp;#34;page_num&amp;#34;: 100 } }&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="樂觀鎖與-_version">樂觀鎖與 _version&lt;/h3>
&lt;p>當每次有寫的操作，document 的 _version 都會被 +1，這是為了實踐樂觀鎖提供在併發狀況下的保護，在所有的操作中可以加入 querystring &lt;code>?version=&lt;/code> 確保版號
例如我要查找 id=&amp;ldquo;iVKeNXMBpRlP8dKifEma&amp;rdquo; 的書籍且確保是 version 1&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">curl http://localhost:9200/amazon/book/iVKeNXMBpRlP8dKifEma?version&lt;span class="o">=&lt;/span>&lt;span class="m">1&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>如果有其他人已經更動過書籍導致 version 不再是 1，此操作會拋出 &lt;code>409&lt;/code> 錯誤&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="s2">&amp;#34;reason&amp;#34;&lt;/span>:&lt;span class="s2">&amp;#34;[iVKeNXMBpRlP8dKifEma]: version conflict, current version [4] is different than the one provided [1]&amp;#34;&lt;/span>,&lt;span class="s2">&amp;#34;index_uuid&amp;#34;&lt;/span>:&lt;span class="s2">&amp;#34;gSaILK3KSH6UCpOeYBGKcQ&amp;#34;&lt;/span>,&lt;span class="s2">&amp;#34;shard&amp;#34;&lt;/span>:&lt;span class="s2">&amp;#34;0&amp;#34;&lt;/span>,&lt;span class="s2">&amp;#34;index&amp;#34;&lt;/span>:&lt;span class="s2">&amp;#34;amazon&amp;#34;&lt;/span>&lt;span class="o">}&lt;/span>,&lt;span class="s2">&amp;#34;status&amp;#34;&lt;/span>:409
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>Warning：樂觀鎖僅適用於單文檔更新，Elasticsearch 沒有 Transaction 概念，所以沒有多文檔更新的一致性保證&lt;/p>
&lt;/blockquote>
&lt;h3 id="查詢">查詢&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ curl -XGET http://localhost:9200/amazon/book/1
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>如果想要針對多筆 document 查詢
需指定多筆的 index/type/id，如果某一個檔案不存在回傳值得 _found 就會是 false&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">跨 index 查詢
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ curl http://localhost:9200/_mget -H &lt;span class="s1">&amp;#39;Content-Type: application/json&amp;#39;&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>-d &lt;span class="s1">&amp;#39;{ &amp;#34;docs&amp;#34;: [ { &amp;#34;_index&amp;#34;: &amp;#34;amazon&amp;#34;, &amp;#34;_type&amp;#34;: &amp;#34;book&amp;#34;, &amp;#34;_id&amp;#34;: 5 }, { &amp;#34;_index&amp;#34;: &amp;#34;amazon&amp;#34;, &amp;#34;_type&amp;#34;: &amp;#34;book&amp;#34;, &amp;#34;_id&amp;#34;: &amp;#34;iVKeNXMBpRlP8dKifEma&amp;#34; } ] }
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s1">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s1">也可以在同一個 index/type 底下查詢，只要標注 id 就好
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s1">$ curl http://localhost:9200/amazon/book/_mget -H &amp;#39;&lt;/span>Content-Type: application/json&lt;span class="s1">&amp;#39; \
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s1">-d &amp;#39;&lt;/span>&lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;ids&amp;#34;&lt;/span>: &lt;span class="o">[&lt;/span> 1, &lt;span class="s2">&amp;#34;iVKeNXMBpRlP8dKifEma&amp;#34;&lt;/span> &lt;span class="o">]&lt;/span> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="批次寫入操作">批次寫入操作&lt;/h3>
&lt;p>如果我們想要一次建立多個檔案，或是刪除等，甚至是混雜各種查詢一次性呼叫，可以使用 batch&lt;br>
Elasticsearch 執行 Batch 時會同時&lt;code>獨立處理，結果也需要去對應的 Response 查詢&lt;/code>，如果有 Shard 就會分散到對應的 Shard 最後再把結果合併
如果操作是 create/index/update 的話，下一行是放 document 內容&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">curl http://localhost:9200/_bulk -H &lt;span class="s1">&amp;#39;Content-Type: application/json&amp;#39;&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>-d $&lt;span class="err">&amp;#39;&lt;/span>&lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;create&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span>&lt;span class="s2">&amp;#34;_index&amp;#34;&lt;/span>:&lt;span class="s2">&amp;#34;amazon&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;_type&amp;#34;&lt;/span>:&lt;span class="s2">&amp;#34;book&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;_id&amp;#34;&lt;/span>: &lt;span class="m">2&lt;/span> &lt;span class="o">}&lt;/span>&lt;span class="se">\n&lt;/span> &lt;span class="o">{&lt;/span>&lt;span class="s2">&amp;#34;name&amp;#34;&lt;/span>:&lt;span class="s2">&amp;#34;....&amp;#34;&lt;/span>,&lt;span class="s2">&amp;#34;page_num&amp;#34;&lt;/span>:991,&lt;span class="s2">&amp;#34;publish_date&amp;#34;&lt;/span>:&lt;span class="s2">&amp;#34;2017/05/16&amp;#34;&lt;/span>,&lt;span class="s2">&amp;#34;intro&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;....&amp;#34;&lt;/span>&lt;span class="o">}&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="o">{&lt;/span>&lt;span class="s2">&amp;#34;delete&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span> &lt;span class="s2">&amp;#34;_index&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;amazon&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;_type&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;book&amp;#34;&lt;/span>, &lt;span class="s2">&amp;#34;_id&amp;#34;&lt;/span>: &lt;span class="m">5&lt;/span> &lt;span class="o">}&lt;/span> &lt;span class="o">}&lt;/span>&lt;span class="se">\n&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>需注意 Body 中是以 &lt;code>\n&lt;/code> 當作新的指令開始，且&lt;code>最後一筆紀錄也要以 \n 結尾&lt;/code>&lt;/p>
&lt;blockquote>
&lt;p>為什麼 Elasticsearch 不用 JSON Array 當作 Body 呢？&lt;br>
這是因為如果是 Array 的話，Node 接收到之後還要去拆解 Array，接著決定哪些 Query 是屬於哪個 Shard 在包一層 Array；
直接使用 JSON Object 加上 \n 可以不用額外的記憶體空間，用換行字符拆解 Query 就好，節省許多不必要開銷&lt;/p>
&lt;/blockquote>
&lt;h2 id="搜尋">搜尋&lt;/h2>
&lt;p>Elasticsearch 在搜尋上彈性很大，可以跨 index / 跨 type 搜尋&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">curl http://localhost:9200/_search
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>指定條件部分，可以用 querystring 或是 Body 夾帶，推薦後者因為彈性與可維護性更高&lt;/p>
&lt;h4 id="指定某欄位的條件搜尋">指定某欄位的條件搜尋&lt;/h4>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">curl http://localhost:9200/amazon/book/_search?q&lt;span class="o">=&lt;/span>name:Elasticsearch
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>用 &lt;code>q=${欄位名稱}:${條件}&lt;/code>，如果有多筆則用&lt;code>+&lt;/code>連結&lt;/p>
&lt;h4 id="某文檔任一欄位符合條件搜尋">某文檔任一欄位符合條件搜尋&lt;/h4>
&lt;p>在 Elasticsearch 中，每個文件都有一個特出欄位 &lt;code>_all&lt;/code>，也就是把文件中所有的字串格式欄位都拼接起來&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">curl http://localhost:9200/amazon/book/_search?q&lt;span class="o">=&lt;/span>Elasticsearch
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="mapping">Mapping&lt;/h3>
&lt;p>為了更好的支援搜尋，Elasticsearch 在寫入文件時會有建立 Schema，可以透過以下指令查詢&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">curl http://localhost:9200/amazon/_mapping
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>型別有分成 text / number 系列(int, long) / date / boolean / object / geo_point 等等 &lt;a class="link" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html" target="_blank" rel="noopener"
>非常多種&lt;/a>&lt;br>
如果欄位是 Array，則以第一個元素的型別為主，且同一 Array 中元素必須都是同型別&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-json" data-lang="json">&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;amazon&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;mappings&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;properties&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;intro&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;type&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;text&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;fields&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;keyword&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;type&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;keyword&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;ignore_above&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">256&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;page_num&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;type&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;long&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;publish_date&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;type&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;date&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;format&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;yyyy/MM/dd HH:mm:ss||yyyy/MM/dd||epoch_millis&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="err">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>也可以主動針對 Index 設定 Schema 與調整型別設定，例如說索引的深度與數量等，預設 Elasticsearch 會把每個欄位都建立索引，所以記憶體消耗非常驚人&lt;/p>
&lt;blockquote>
&lt;p>Warning: 型別設定後只能新增欄位，不能更動既有的型別或 Indexing，最好是一開始就設定好，不然要 ReIndex ，詳見後續&lt;/p>
&lt;/blockquote>
&lt;h3 id="建立-mapping">建立 Mapping&lt;/h3>
&lt;p>先刪除 amazon Index，重新建立 Index 與 Mapping&lt;br>
假設我希望 page_num 欄位是 Integer 且不要建立索引&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ curl -XPUT http://localhost:9200/amazon/_mapping -H &lt;span class="s1">&amp;#39;Content-Type: application/json&amp;#39;&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> --data &lt;span class="s1">&amp;#39;{ &amp;#34;properties&amp;#34;: { &amp;#34;page_num&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;integer&amp;#34;, &amp;#34;index&amp;#34;: false } } }&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>重新將資料寫入後，其餘的欄位 Elasticsearch 會幫忙補上型別，page_num 因為已經存在則不會改變 &lt;br>
需要注意如果 &lt;code>index指定false&lt;/code> 則使用 &lt;code>/_search?q&lt;/code> 會無法搜尋&lt;/p>
&lt;h3 id="analyzer">Analyzer&lt;/h3>
&lt;p>如果只能針對條件做篩選，這一般的資料庫也做得到，真正讓 Elasticsearch 區別於一般資料庫的地方在於 Analyzer&lt;br>
每個文檔的欄位除了型別定義與索引外，還可以指定該欄位如何被分析，例如說最基本的&lt;code>斷詞&lt;/code> &amp;ldquo;中華民國&amp;rdquo; 要拆成 &amp;ldquo;中&amp;rdquo;、&amp;ldquo;華&amp;rdquo;、&amp;ldquo;民&amp;rdquo;、&amp;ldquo;國&amp;rdquo; 還是 &amp;ldquo;中華&amp;rdquo;、&amp;ldquo;民國&amp;quot;等有多種方式，決定如何斷詞會影響查詢&lt;br>
另外像&lt;code>語意分析&lt;/code>，如果我們想搜尋「Quick fox jumps」，我們不單希望字面上完全符合，而是找到類似下者的文檔 &lt;code>A quick brown fox jumps over the lazy dog&lt;/code>&lt;/p>
&lt;p>所以 Analyzer 主要分成三個部分&lt;/p>
&lt;ol>
&lt;li>&lt;code>character filter&lt;/code>&lt;br>
決定字元如何處理，像是轉換數字格式 / 去除 HTML tag 等&lt;/li>
&lt;li>&lt;code>tokenizer&lt;/code>&lt;br>
決定字元如何組合成字串，英文預設是用空白，每個 Analyzer 一定也只能有一個 tokenizer&lt;/li>
&lt;li>&lt;code>token filter&lt;/code>&lt;br>
將字串做處理，例如全部轉小寫 / 過濾同義詞等&lt;/li>
&lt;/ol>
&lt;h4 id="測試-analyzer">測試 Analyzer&lt;/h4>
&lt;p>如果不知道要怎麼選擇 Analyzer，可以看文件找出&lt;a class="link" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-analyzers.html" target="_blank" rel="noopener"
>內建的 Analyzer&lt;/a>並透過 API 去測試，指定不同的 Analyzer 與測試字串&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ curl http://localhost:9200/_analyze -H &lt;span class="s1">&amp;#39;Content-Type: application/json&amp;#39;&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> --data &lt;span class="s1">&amp;#39;{ &amp;#34;analyzer&amp;#34;: &amp;#34;standard&amp;#34;, &amp;#34;text&amp;#34;:&amp;#34;this is a test&amp;#34; }&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ curl http://localhost:9200/_analyze -H &lt;span class="s1">&amp;#39;Content-Type: application/json&amp;#39;&lt;/span> &lt;span class="se">\ &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> --data &lt;span class="s1">&amp;#39;{ &amp;#34;filter&amp;#34;: [&amp;#34;lowercase&amp;#34;], &amp;#34;char_filter&amp;#34; : [&amp;#34;html_strip&amp;#34;], &amp;#34;tokenizer&amp;#34;: &amp;#34;whitespace&amp;#34;, &amp;#34;text&amp;#34;:&amp;#34;this &amp;lt;a&amp;gt;iS&amp;lt;/a&amp;gt; A Test&amp;#34; }&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>可以看到回傳值是 Analyzer 會如何 parse 字串並產生索引的 keyword，更多的參數可以參考文件 &lt;a class="link" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-analyze.html" target="_blank" rel="noopener"
>Analyze API&lt;/a> &lt;br>
如果需要支援中文，則需要另外安裝 plugin&lt;/p>
&lt;h4 id="調整欄位的-analyzer">調整欄位的 Analyzer&lt;/h4>
&lt;p>可以在 Index 下建立客製化的 Analyzer，例如我建立一個 &lt;code>my_intro_analyzer&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ curl -XPUT http://localhost:9200/amazon/_settings -H &lt;span class="s1">&amp;#39;Content-Type: application/json&amp;#39;&lt;/span> --data &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> &lt;span class="s1">&amp;#39;{ &amp;#34;analysis&amp;#34;: { &amp;#34;analyzer&amp;#34;: { &amp;#34;my_intro_analyzer&amp;#34;: { &amp;#34;filter&amp;#34;: [&amp;#34;lowercase&amp;#34;], &amp;#34;char_filter&amp;#34; : [&amp;#34;html_strip&amp;#34;], &amp;#34;tokenizer&amp;#34;: &amp;#34;whitespace&amp;#34; } } } }&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>透過 Mapping API 去更改欄位的 Analyzer，同樣是不能更改既有的 Index，且只能指定 Analyzer 而不能在欄位中自訂 tokenizer 等&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ curl -XPUT http://localhost:9200/amazon -H &lt;span class="s1">&amp;#39;Content-Type: application/json&amp;#39;&lt;/span> --data &lt;span class="se">\ &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s1">&amp;#39;{ &amp;#34;mappings&amp;#34;: { &amp;#34;properties&amp;#34;: { &amp;#34;intro&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;text&amp;#34;, &amp;#34;analyzer&amp;#34;: &amp;#34;my_intro_analyzer&amp;#34; } } }, &amp;#34;settings&amp;#34;: { &amp;#34;analysis&amp;#34;: { &amp;#34;analyzer&amp;#34;: { &amp;#34;my_intro_analyzer&amp;#34;: { &amp;#34;filter&amp;#34;: [&amp;#34;lowercase&amp;#34;], &amp;#34;char_filter&amp;#34; : [&amp;#34;html_strip&amp;#34;], &amp;#34;tokenizer&amp;#34;: &amp;#34;whitespace&amp;#34; } } } } }&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>看起來 Indexing 深度與 Analyzer 分析的 Token 數都需要設定上限，否則預設值會變成記憶體怪獸!&lt;/p>
&lt;/blockquote>
&lt;h2 id="dsl">DSL&lt;/h2>
&lt;p>前面提到搜尋時可以用 querystring 加上條件，但為了設定更複雜且彈性的查詢語法，可以使用 Elasticsearch 自訂的查詢語言&lt;/p>
&lt;h3 id="query">Query&lt;/h3>
&lt;p>如果今天想要找欄位中是否有相近的值，可以用 &lt;code>match&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ curl http://localhost:9200/amazon/_search -H &lt;span class="s1">&amp;#39;Content-Type: application/json&amp;#39;&lt;/span> --data &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> &lt;span class="s1">&amp;#39;{ &amp;#34;query&amp;#34;: { &amp;#34;match&amp;#34;: { &amp;#34;name&amp;#34;: &amp;#34;Distributed&amp;#34; } } }&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="filter">Filter&lt;/h3>
&lt;p>如果今天想要找欄位中完全一模一樣值，可以用 &lt;code>term&lt;/code> 接篩選條件&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ curl http://localhost:9200/amazon/_search -H &lt;span class="s1">&amp;#39;Content-Type: application/json&amp;#39;&lt;/span> --data &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> &lt;span class="s1">&amp;#39;{ &amp;#34;query&amp;#34;: { &amp;#34;term&amp;#34;: { &amp;#34;name&amp;#34;: &amp;#34;Elasticsearch: The Definitive Guide: A Distributed Real-Time Search and Analytics Engine 1st Edition, Kindle Edition&amp;#34; } } }&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="組合多種條件">組合多種條件&lt;/h3>
&lt;p>如果今天要搜尋的條件比較複雜，例如說我希望&lt;code>名稱一定要包含 Distributed&lt;/code>，頁數&lt;code>最好&lt;/code>在200至500頁或是出版年份在今年(但兩者必須至少符合一項)&lt;br>
可以用 &lt;code>bool&lt;/code> 搭配 &lt;code>must&lt;/code> 必須符合 + &lt;code>should&lt;/code> 應該符合，搭配 &lt;code>minimum_should_match&lt;/code> 可以決定條件的符合程度&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">curl http://localhost:9200/amazon/_search -H &lt;span class="s1">&amp;#39;Content-Type: application/json&amp;#39;&lt;/span> --data &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>&lt;span class="s1">&amp;#39;{ &amp;#34;query&amp;#34;: { &amp;#34;bool&amp;#34;: { &amp;#34;must&amp;#34;: { &amp;#34;match&amp;#34;: { &amp;#34;name&amp;#34;: &amp;#34;Distributed&amp;#34; } }, &amp;#34;minimum_should_match&amp;#34;: 1, &amp;#34;should&amp;#34;: [ { &amp;#34;range&amp;#34;: { &amp;#34;page_num&amp;#34;: { &amp;#34;gt&amp;#34;: 200, &amp;#34;lt&amp;#34;: 500 } } }, { &amp;#34;range&amp;#34;: {&amp;#34;publish_date&amp;#34;: { &amp;#34;gt&amp;#34;: &amp;#34;2020/01/01&amp;#34; } } } ] } } }&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="系統配置與設定">系統配置與設定&lt;/h2>
&lt;h3 id="sharding-相關">Sharding 相關&lt;/h3>
&lt;h4 id="1-設定-index-的-sharding-與-replica-數量">1. 設定 Index 的 sharding 與 replica 數量&lt;/h4>
&lt;p>有兩種方式，一種是建立 Index 時就指定，第二種是建立 Index 後續調整&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">1. 建立 Index 指定
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">curl -XPUT http://localhost:9200/amazon -H &lt;span class="s1">&amp;#39;Content-Type: application/json&amp;#39;&lt;/span> --data &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>&lt;span class="s1">&amp;#39;{ &amp;#34;index&amp;#34;: { &amp;#34;number_of_shards&amp;#34;: 2, &amp;#34;number_of_replicas&amp;#34;: 0 } }&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2. 後續動態調整
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">curl -XPUT http://localhost:9200/amazon/_settings -H &lt;span class="s1">&amp;#39;Content-Type: application/json&amp;#39;&lt;/span> --data &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>&lt;span class="s1">&amp;#39;{ &amp;#34;index&amp;#34;: { &amp;#34;number_of_replicas&amp;#34;: 0 } }&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>需注意 sharding number 最好一開始就設定好，可以配置稍微多一點 Primary shard 方便後續 scale out&lt;br>
後續如果要動態調整很麻煩，要把 Index 設成 read-only 並透過 Split API 修改 / 或是用 Reindex 方式重建新的 Index&lt;/p>
&lt;h4 id="2-指定-index-使用的機型">2. 指定 Index 使用的機型&lt;/h4>
&lt;p>有時候我們會希望某些熱門的 Index 使用較好的硬體，其他冷門的使用差一點的硬體，Elasticsearch 在機器運作時可以打上標記 &lt;code>--node.box_type&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ ./bin/elasticsearch --node.box_type strong
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>指定 Index 要存放的機型&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ POST /logs_2014-09-30/_settings
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;index.routing.allocation.include.box_type&amp;#34;&lt;/span> : &lt;span class="s2">&amp;#34;strong&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>結合後續的 Alias 可以配置出更符合實際應用的設定&lt;/p>
&lt;h4 id="index-template">Index template&lt;/h4>
&lt;p>當建立新的 Index 時，可以指定 template 套用設定，就不用每次都要打設定，Elasticsearch 在 7.8 版本中，可以指定 component template 與 index template；&lt;br>
component template 是小單位可以被用來組合的；而 index template 則是 Index 直接套用的&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">// Component template
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">PUT _component_template/other_component_template
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;template&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;mappings&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;properties&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;ip_address&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;type&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;ip&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">// Index template，只要 Index 開頭是 bar 就會套用
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">PUT _index_template/template_1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;index_patterns&amp;#34;&lt;/span>: &lt;span class="o">[&lt;/span>&lt;span class="s2">&amp;#34;bar*&amp;#34;&lt;/span>&lt;span class="o">]&lt;/span>,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;template&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;settings&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;number_of_shards&amp;#34;&lt;/span>: &lt;span class="m">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;mappings&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;_source&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;enabled&amp;#34;&lt;/span>: &lt;span class="nb">false&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;properties&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;host_name&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;type&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;keyword&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;created_at&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;type&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;date&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;format&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;EEE MMM dd HH:mm:ss Z yyyy&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;aliases&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;mydata&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;priority&amp;#34;&lt;/span>: 10,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;composed_of&amp;#34;&lt;/span>: &lt;span class="o">[&lt;/span>&lt;span class="s2">&amp;#34;component_template1&amp;#34;&lt;/span>, ....&lt;span class="o">]&lt;/span>,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;version&amp;#34;&lt;/span>: 3,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;_meta&amp;#34;&lt;/span>: &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;description&amp;#34;&lt;/span>: &lt;span class="s2">&amp;#34;my custom&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="reindex-與-alias">Reindex 與 Alias&lt;/h3>
&lt;p>先介紹 &lt;code>Alias&lt;/code>，看到這個功能讓我覺得十分驚豔，可以將維運與開發拆分的更加獨立&lt;br>
今天假設因為資料的格式問題 / Sharding 重新分配等問題需要&lt;code>Index 需要重建&lt;/code>，Alias 就能派上用場&lt;/p>
&lt;p>他的概念就好像檔案連結，可以取一個連結名稱，但同時對應到多個實際的檔案路徑，例如說我有兩個 Index 想要分開儲存 /amazon + /eslite&lt;br>
但我希望查詢時可以有一個共同的 endpoint 取名叫 /bookstore，就可以用 Alias 連結 /amazon 與 /eslite&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ curl -XPUT http://localhost:9200/eslite/_alias/bookstore
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ curl -XPUT http://localhost:9200/amazon/_alias/bookstore
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ curl http://localhost:9200/boostore/_search
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">// 同時返回 amazon / eslite 底下的文檔
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ curl http://localhost:9200/*/_alias/bookstore
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">// 查詢哪些 Index 有設定 &lt;span class="nb">alias&lt;/span> 為 bookstore
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ curl -X DELETE http://localhost:9200/amazon/_alias/bookstore
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">// 刪除 &lt;span class="nb">alias&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>雖然搜尋的時候也可以直接指定多個 Index 如 &lt;code>curl http://localhost:9200/amazon,eslite/_search&lt;/code>，但如果要增減 Index 項目就需要改程式碼，十分不乾淨&lt;/p>
&lt;p>另外更大的好處在於同一個 Index 要升級時，實際儲存可以用版號如 index_name_v1，用 alias 指定 index_name；&lt;br>
接著在建立新的 index_name_v2 換成新的 Index，完成後在切換 index_name 的指向就能 zero downtime 切換 index 了&lt;/p>
&lt;blockquote>
&lt;p>查詢時指定 alias 就可 / 寫入時如果 alias 下只有一個 index 就不用指定；超過一個必須指定寫入的 index&lt;/p>
&lt;/blockquote>
&lt;h3 id="拆分-index-與-alias-應用">拆分 Index 與 Alias 應用&lt;/h3>
&lt;p>假設今天我們拿 Elasticsearch 當作 Logging Service，通常是越近期的資料越熱門，時間久之後舊資料可能要移除或轉出保存&lt;br>
在系統設計上，我們要考量幾個點&lt;/p>
&lt;blockquote>
&lt;ol>
&lt;li>儲存時區分新資料與舊資料&lt;/li>
&lt;/ol>
&lt;/blockquote>
&lt;ol start="2">
&lt;li>搜尋時希望新資料與部分舊資料都可以被查詢&lt;/li>
&lt;li>舊資料的定期刪除與冷保存&lt;/li>
&lt;/ol>
&lt;p>書中建議，Log 依照時間區間建立新的 Index，例如每個依照每個月份儲存 &lt;code>2020-05&lt;/code> 就單放五月份的 Log&lt;br>
建立新的 Index 時可以透過 template 綁定預設值，就不用每次都要手動預先建立 Index 了&lt;br>
假設查詢時會希望搜尋近期 3 個月的資料，與其每次都指定 3 個 Index，可以透過 &lt;code>Alias&lt;/code> 簡化查詢語法&lt;/p>
&lt;p>拆分多個 Index 好處是調整非常彈性，例如說舊的 Index 可以&lt;code>取消 Replica / 移到較差的硬體 / 單獨備份 / 整個砍掉(效率遠比砍 document 好)&lt;/code>&lt;/p>
&lt;h2 id="總結">總結&lt;/h2>
&lt;p>礙於篇幅，其他還有處理自然語言 / 地理位置資料 / 實際上線的注意事項等等進階議題，只能等之後真的有用上再來分享&lt;/p></description></item><item><title>Elasticsearch 系統介紹與評估</title><link>https://yuanchieh.page/posts/2020/2020-07-08-elasticsearch-%E7%B3%BB%E7%B5%B1%E4%BB%8B%E7%B4%B9%E8%88%87%E8%A9%95%E4%BC%B0/</link><pubDate>Wed, 08 Jul 2020 08:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2020/2020-07-08-elasticsearch-%E7%B3%BB%E7%B5%B1%E4%BB%8B%E7%B4%B9%E8%88%87%E8%A9%95%E4%BC%B0/</guid><description>&lt;p>最近有一些自建搜尋引擎的需要，所以找上了 Elasticsearch 這一套開源的分散式的 NoSQL Database，這一篇文章主要分享自己如何評估 Elasticsearch，著重在系統的架構與內部實作機制，教學預計會拉到另外一篇文章&lt;/p>
&lt;p>以下內容大多參考此本書：&lt;code>《Elasticsearch: The Definitive Guide: A Distributed Real-Time Search and Analytics Engine》&lt;/code>，雖然是 2015 的書，但內容相當的豐富，還有豐富的內部實作機制/Cluster架構等等的補充，除了 api 有些參數要更新外，不會因為時間而抹滅他的價值，包含了有趣的浪漫故事&lt;/p>
&lt;blockquote>
&lt;p>Elasticsearch 原作者其實是為了幫老婆寫一個食譜搜尋引擎而開始的，但過了好幾年 Elasticsearch 都變成公司了但老婆依然還沒拿到說好的食譜搜尋引擎&amp;hellip;. (截至 2015年)&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/20200708/bookcover.jpg"
loading="lazy"
>&lt;/p>
&lt;h2 id="terminology-與基礎介紹">Terminology 與基礎介紹&lt;/h2>
&lt;p>Elasticsearch 是建構在 Lucene 這個 Java 開發的搜尋引擎上，增加了分散式與 API 呼叫的介面；&lt;br>
資料層級分成 &lt;code>Index &amp;gt; Document&lt;/code>，每個 Index 當第一筆 Document 建立後會有隱式的欄位型別，後續的 Document 都要遵守型別，其中 &lt;code>Index&lt;/code> 這個詞蠻容易誤會，因為他除了代表最上層的資料集合外，也代表索引的同義詞&lt;br>
Elasticsearch 儲存時是用 JSON 格式，可以對每個欄位設定型別，同時可以指定是否支援全文搜尋&lt;br>
為了支援全文搜尋，Elasticsearch 使用 Reverted index，也就是用一張表紀錄一個詞在哪些 Document 中的欄位出現過&lt;/p>
&lt;blockquote>
&lt;p>Warning: 在 6.x.x 版時 Elasticsearch 移除了 Type 層級，主要是因為當一個 Index 下有多個 Type，假設多個 Type 有相同名稱的欄位，對於 Lucence 來說會把兩個相同名稱欄位都當作同一個，所以如果想要兩個不同 Type 中相同名稱欄位設定不同型別是會拋出錯誤的 (ex. Index 下有 User / Twitter 兩個 Type，且兩個 Type 都有 user_name，則 user_name 必須是相同型別)，所以經過考量後就移除了&lt;br>
參考文件 &lt;a class="link" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/removal-of-types.html" target="_blank" rel="noopener"
>Removal of mapping types&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>在建立索引時，Elasticsearch 會將欄位經過 &lt;code>Analyzer&lt;/code> 處理，也就是 charaterizer -&amp;gt; tokenizer -&amp;gt; token filter&lt;br>
所以能夠支援像過濾介系詞 / 將文字轉成小寫或是同義詞轉換 / 支援不同語言的斷詞等靈活的語言處理流程，所以才能夠提供別於一般資料庫死板的全文搜尋&lt;/p>
&lt;p>在資料更新與查詢時，Elasticsearch 提供近乎即時的操作，同時查詢支援依照條件篩選 (Filter) 或是依據關聯度排序 (Query)&lt;br>
前者像是 &lt;code>給我 id 是 123 的資料&lt;/code>這類 yes/no 問題；後者是回答 &lt;code>幫我找出跟 Mary 相關的文檔&lt;/code> 這類模糊搜尋的結果&lt;/p>
&lt;h3 id="架構介紹">架構介紹&lt;/h3>
&lt;p>Elasticsearch 支援分散式，可以在 Index 層級指定要 Sharding 配置方式，Shard 有兩種角色 &lt;code>Primary / Replica&lt;/code>，前者負責讀寫而後者負責從 Primary 備份資料並分散讀的查詢，每一個 Shard 執行獨立的 Lucene，可視為獨立的 Worker
即使在單機上跑，Elasticsearch 也會按照配置，將資料拆分儲存&lt;/p>
&lt;p>如果 Cluster 此時增加機器，Elasticsearch 會&lt;code>自動將 Shard 分散到各個節點上&lt;/code>，如果有 Replica 則&lt;code>盡可能分散風險讓每台機器都有備援資料&lt;/code> &lt;br>
Cluster 之間會有一個 Master，Master 主要管理整個 Cluster / 加入、移除節點 / 建立 Index 等，例如查詢/寫入都是個節點能夠獨立完成，所以不需要擔心 Master 會成為系統的 Single Point of Failure&lt;br>
節點發生問題，Cluster 會自動票選 Master 並重新做資料搬移的動作 &lt;br>
實際上 Node 有分很多類型，像是 Master Node 負責管理 Cluster / Data Node 儲存資料 / Ingest Node 預處理流程等等&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/20200708/cluster.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="服務評估">服務評估&lt;/h2>
&lt;p>主要是針對各種維運上的點進行考量，看到 &lt;code>分散式&lt;/code>資料庫都會有三個特點&lt;/p>
&lt;ol>
&lt;li>&lt;code>**Replica**&lt;/code>: 資料如何備援&lt;/li>
&lt;li>&lt;code>**Sharding**&lt;/code>: 如何拆分資料集&lt;/li>
&lt;li>&lt;code>**Cluster**&lt;/code>: 如何水平擴展機器&lt;/li>
&lt;/ol>
&lt;p>一般來說分散式資料庫的 Replica 都是由 active slave 擔任，即時備份所有的更新，同時能夠支援讀取的分擔，各家提供的功能都差不多；&lt;br>
至於 Cluster / Sharding 則各家資料庫的實作與考量各有不同，同時考量到 &lt;code>CAP&lt;/code> 在可用性與資料一致性之間做取捨這是我覺得最有趣的地方&lt;/p>
&lt;p>實際評估上會去思考以下幾個案例，同時以我比較熟悉的 MongoDB / Redis 作為對比&lt;/p>
&lt;ol>
&lt;li>基礎資料庫&lt;br>
a. 寫資料時如何保證 Durability&lt;br>
b. Concurrency 下的 Consistency 保證是什麼&lt;/li>
&lt;li>Sharding&lt;br>
a. Sharding 的依據是什麼 / 是否能夠動態增減 shard&lt;br>
b. Query 如何 routing 到正確的 shard 上面&lt;/li>
&lt;li>Cluster&lt;br>
a. Cluster 基本架構要如何搭建&lt;br>
b. Cluster 調整時需要做什麼改動&lt;br>
c. Cluster 增減 node 時會有什麼變化&lt;br>
d. Cluster 在什麼情況下會不可用&lt;/li>
&lt;/ol>
&lt;h3 id="基礎資料庫">基礎資料庫&lt;/h3>
&lt;h4 id="寫資料時如何保證-durability">寫資料時如何保證 Durability&lt;/h4>
&lt;p>Elasticsearch 為了平衡 Durability 與效能，所以當 Reverted Index 建立後就是 &lt;code>不可變 immutable&lt;/code>的，這樣的好處是性能帶來很大的提升，資料載入 memory 後不用擔心會變動 / mulit thread 也不用擔心資料過期的問題等等&lt;br>
但資料不可避免會遇到更新或刪除的需求，所以 Elasticsearch 採用 Segment 方式，&lt;code>每次建立 Index 後就是一個獨立的 Segment&lt;/code>，累積一批修改後在建立一個新的 Segment&lt;br>
查詢資料時就同時查找多個 Segment，如果同筆資料在多個 Segment 都有紀錄，則採取最新一筆的資料&lt;/p>
&lt;p>實際的Elasticsearch 內部儲存機制的方式參考下圖&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/20200708/design.png"
loading="lazy"
>&lt;/p>
&lt;p>儲存機制如下&lt;/p>
&lt;ol>
&lt;li>新的修改產生，寫進 in-memory buffer 中，此時資料不能被搜尋&lt;/li>
&lt;li>&lt;code>[Refresh]&lt;/code> 固定時間 refresh 到 file cache (灰色的 Segment，代表還沒真正儲存到硬碟上)，此時資料可以被搜尋 (預設每 10秒)&lt;/li>
&lt;li>&lt;code>[Flush]&lt;/code> 固定時間 file cache 透過 &lt;code>fsync&lt;/code> 寫入硬碟，此時才是真正的持久化 (預設每 30分鐘或是 Translog過大時)&lt;/li>
&lt;li>每次 Flush 會產生新的 Segment，但如果 Segment 太多會造成檔案過多性能反而下降，會固定時間合併多個 Segment&lt;br>
但要小心 Segment 合併會吃掉大量的記憶體與 CPU，所以也不能夠太頻繁，可以指定 &lt;code>max_num_segments&lt;/code> 參數&lt;/li>
&lt;li>Translog 是為了確保 2~3 步驟如果機器發生問題，可以透過 Translog 回復資料&lt;br>
Translog 將每筆操作順序寫入硬碟，當第三步 flush 後一併清空&lt;br>
但 Translog 本身也有 fsync 的頻率，預設是 5 秒鐘，所以有機會&lt;code>丟失 5秒鐘內的資料&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>Redis 在持久化保存有分 RDB 與 AOF，RDB 是透過保存整份 Snapshot / AOF 則是寫入每筆操作 log 預設每秒 fsync 到硬碟上&lt;/p>
&lt;h4 id="concurrency-下的-consistency-保證是什麼">Concurrency 下的 Consistency 保證是什麼&lt;/h4>
&lt;p>對 Elasticsearch 進行寫入操作時，針對 Request Level 可以做不同的保證性，預設是 &lt;code>sync&lt;/code>，也就是 Primary + Replica 都寫入成功才返回，資料不用擔心會不見；&lt;br>
可以調整成 &lt;code>async&lt;/code>，只要 Primary 寫入成功就返回，但可能資料會不見； &lt;br>
但書中提到建議還是用 &lt;code>sync&lt;/code>，因為如果 Elasticsearch 此時負載較高，可以讓 Request 較晚回覆產生 back preasure，否則可能會讓系統乘載過多的 Query&lt;/p>
&lt;p>在併發的狀況下，Elasticsearch 採用&lt;code>樂觀鎖&lt;/code>，透過_version去比對更動是否為正確的版本，預設的_version 是遞增的數字，也可以用自定義的 _version&lt;/p>
&lt;h3 id="sharding">Sharding&lt;/h3>
&lt;h4 id="sharding-的依據是什麼--是否能夠動態增減-shard">Sharding 的依據是什麼 / 是否能夠動態增減 shard&lt;/h4>
&lt;p>Elasticsearch 在建立 Index 時，可以指定 sharding 的數量，設定後如果要更動，就必須要先關閉 Index 寫入並調整設定 &lt;br>
至於資料如何分配到 shard，則是由內部的 &lt;code>hash function 對 id 做運算&lt;/code>，Elasticsearch 會自動 balance 資料&lt;/p>
&lt;p>MongoDB 則是需要對 collection 指定 shard key，可以分成 range shard / hash shard，前者可自己指定 shard 要儲存的 key 範圍，後者同樣有內部 hash function 決定，MongoDB 會自行負責 balance；&lt;br>
Redis cluster 預設有 16384 個坑，透過 hash 運算(CRC16 mod 16384)分散 key 到現有的 Node 上面，如果動態增減 cluster Redis 會自行處理資料搬移&lt;/p>
&lt;h4 id="query-如何-routing-到正確的-shard-上面">Query 如何 routing 到正確的 shard 上面&lt;/h4>
&lt;p>Elasticsearch 每一個 Node 都能夠處理 Query，會在內部自己 routing 到資料所在的 Node 上，另外為了效能，如果是讀取且有 replica，Elasticsearch 會用 &lt;code>Round-Robin&lt;/code> 去分散讀取的壓力&lt;/p>
&lt;p>MongoDB 則需要 Mongos 去處理 query，所以多一個服務要架設，也造成服務多一個中斷的可能；&lt;br>
Redis Cluster 也是每一個 Node 都能處理 Query&lt;/p>
&lt;h3 id="cluster">Cluster&lt;/h3>
&lt;h4 id="cluster-基本架構要如何搭建">Cluster 基本架構要如何搭建&lt;/h4>
&lt;p>Elasticsearch 在 Cluster 架構上非常彈性，要幾個 Node 都可以，同時可以針對不同的 Indices 去調整 sharding / replica 數量，Elasticsearch 會以&lt;code>容錯度最高的方式自動分配&lt;/code>&lt;br>
但建議還是 Cluster 還是 3 台以上，才可以讓可用性更高&lt;/p>
&lt;blockquote>
&lt;p>如果只有兩台，發生 Network partitioning，假設要保證 Consistency 要過多數的小 Cluster 能夠運作(避免 split brain)，則兩邊各一台就會服務中斷，在 Network partitioning 下沒有任何的容錯性&lt;br>
所以 Cluster 基本都 3台起跳且選擇奇數&lt;/p>
&lt;/blockquote>
&lt;p>MongoDB Cluster 只少要 3 個 Node (至少兩個可儲存的 Node)，如果是 Sharding Cluster 則需要 Config Server (3台) + Replica set (3台起跳) * n，外加 Mongos&lt;br>
Redis Cluster 則也沒有限制，要加幾個 Node 都可以，如果要備援則設定 slave node&lt;/p>
&lt;h4 id="cluster-調整時需要做什麼改動">Cluster 調整時需要做什麼改動&lt;/h4>
&lt;p>Elasticsearch 再增加新的 Cluster Node 時&lt;code>不需要額外的設定&lt;/code>，只要確保 Network 可以 multicast 且設定同一個 cluster name，就會自己加進去&lt;/p>
&lt;p>MongoDB 需要改 Config Server 設定檔 / Redis Cluster 也是&lt;/p>
&lt;h4 id="cluster-增減-node-時會有什麼變化">Cluster 增減 node 時會有什麼變化&lt;/h4>
&lt;p>Elasticsearch 再設定檔，可以指定 Primary 與 Replica 的數量，並平均分散到每一個 Node 上&lt;br>
例如說 Primary 2 + replica 1，則會產生 P1 / P2 + R1 / R2，假設目前有兩個 Node 他會自動分配成 P1 + R2 / P2 + R1 分散風險，掛了一台資料也不會掉&lt;/p>
&lt;p>MongoDB 的 Cluster Node 主要有兩種 secondary / 僅投票用的 Arbiter (撇除 Primary)&lt;br>
Redis Cluster 沒有特別區分 Node 性質&lt;/p>
&lt;h4 id="cluster-在什麼情況下會不可用">Cluster 在什麼情況下會不可用&lt;/h4>
&lt;p>Elasticsearch / MongoDB / Redis Cluster 這方面都是類似的，當發生 partitioning 時，只有超過半數的 cluster 可以運作&lt;/p></description></item><item><title>MongoDB 批次處理大量數據</title><link>https://yuanchieh.page/posts/2020/2020-02-06-mongodb-%E6%89%B9%E6%AC%A1%E8%99%95%E7%90%86%E5%A4%A7%E9%87%8F%E6%95%B8%E6%93%9A/</link><pubDate>Thu, 06 Feb 2020 22:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2020/2020-02-06-mongodb-%E6%89%B9%E6%AC%A1%E8%99%95%E7%90%86%E5%A4%A7%E9%87%8F%E6%95%B8%E6%93%9A/</guid><description>&lt;p>本篇分享 MongoDB 在批次查訊大量數據時的小技巧&lt;/p>
&lt;p>在查詢小筆數據時，往往我們就是用 &lt;code>find().toArray()&lt;/code> 直接回傳結果，需要簡單的分頁就搭配 &lt;code>limit() / skip()&lt;/code> 即可完成&lt;br>
但如果需要分析數據跑過整個 collection，不可能用 find() 一次拉回所有的資料，透過 skip() 批次處理，如果 collection 資料不多還好，如果幾十萬筆、幾百萬筆資料效能回非常的低落，因為 skip 的話每次查詢 DB 都必須要重頭開始跳過指定筆數資料，才能回傳，所以查詢時間會隨著筆數增加而趨近於指數倍增長&lt;/p>
&lt;p>目前已知有兩種做法，可以有效輪詢整個 collection 而不拖垮 DB 效能&lt;br>
一種是 &lt;code>Cursor&lt;/code>，但是在實務上我個人並沒有採用，原因是 Cursor 每次只能透過 &lt;code>.next()&lt;/code> 取得一筆資料，如果希望一次拉個上千筆資料處理就無法做到；&lt;br>
另一種是本次要分享的方式，透過遞迴查詢，保持性能情況下跑完整個 Collection，實務上每天應用在有千萬筆資料的 Collection 而沒有太大的問題&lt;/p>
&lt;h2 id="遞回查詢">遞回查詢&lt;/h2>
&lt;p>說穿了其實很簡單，透過有建立 index 的索引，按照遞增或遞減排序，每批次取出部分數據後，下次查詢的條件改為取出數據的最後一位，一路到 Collection 結束&lt;/p>
&lt;p>以下是程式碼部分&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;span class="lnt">61
&lt;/span>&lt;span class="lnt">62
&lt;/span>&lt;span class="lnt">63
&lt;/span>&lt;span class="lnt">64
&lt;/span>&lt;span class="lnt">65
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="kr">const&lt;/span> &lt;span class="nx">MongoClient&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">require&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;mongodb&amp;#39;&lt;/span>&lt;span class="p">).&lt;/span>&lt;span class="nx">MongoClient&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">const&lt;/span> &lt;span class="nx">dbUrl&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;mongodb://127.0.0.1:27017&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">MongoClient&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">connect&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">dbUrl&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kr">async&lt;/span> &lt;span class="kd">function&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">err&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">client&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">console&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">log&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">err&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">testDB&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">client&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">db&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;test&amp;#34;&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">userCollection&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">testDB&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">collection&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;users&amp;#34;&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kr">await&lt;/span> &lt;span class="nx">iterateCollection&lt;/span>&lt;span class="p">({&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">sourceCollection&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">userCollection&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">query&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">age&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="mi">20&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">batchSize&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">order&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s2">&amp;#34;asc&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">console&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">log&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">result&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">client&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">close&lt;/span>&lt;span class="p">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">async&lt;/span> &lt;span class="kd">function&lt;/span> &lt;span class="nx">iterateCollection&lt;/span>&lt;span class="p">({&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">sourceCollection&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">query&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">batchSize&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">order&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">})&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">let&lt;/span> &lt;span class="nx">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[];&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">let&lt;/span> &lt;span class="nx">sort&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">_id&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kd">let&lt;/span> &lt;span class="nx">_query&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">...&lt;/span>&lt;span class="nx">query&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">};&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">order&lt;/span> &lt;span class="o">===&lt;/span> &lt;span class="s2">&amp;#34;asc&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">sort&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">_id&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">while&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">queryResults&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kr">await&lt;/span> &lt;span class="nx">sourceCollection&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">find&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">_query&lt;/span>&lt;span class="p">).&lt;/span>&lt;span class="nx">limit&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">batchSize&lt;/span>&lt;span class="p">).&lt;/span>&lt;span class="nx">sort&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">sort&lt;/span>&lt;span class="p">).&lt;/span>&lt;span class="nx">toArray&lt;/span>&lt;span class="p">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">queryResults&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">length&lt;/span> &lt;span class="o">===&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">){&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">break&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">_query&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">$lt&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">queryResults&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nx">queryResults&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">length&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">].&lt;/span>&lt;span class="nx">_id&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">order&lt;/span> &lt;span class="o">===&lt;/span> &lt;span class="s2">&amp;#34;asc&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">_query&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">$gt&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">queryResults&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nx">queryResults&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">length&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">].&lt;/span>&lt;span class="nx">_id&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1">// process data and push to result
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="c1">// result.push(queryResults.map(result =&amp;gt; result._id));
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="nx">result&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Redis Lock (Redlock) 分散式 lock 原理分析與實作</title><link>https://yuanchieh.page/posts/2020/2020-01-14_redis-lock-redlock-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E8%88%87%E5%AF%A6%E4%BD%9C/</link><pubDate>Tue, 14 Jan 2020 05:21:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2020/2020-01-14_redis-lock-redlock-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E8%88%87%E5%AF%A6%E4%BD%9C/</guid><description>&lt;p>先前公司遇到 Client 在不明狀況下連續呼叫註冊用戶的 API 兩次，導致用戶被重複建立，導致後續的 API 操作與資料分析異常，所以決定加上 Lock 機制避免重複建立的問題&lt;/p>
&lt;p>剛好在 Redis 官網看到 Redlock，一種 Redis 作者 antirez 基於 Redis 設計的分散式 lock 機制，並且已經有了 Nodejs 版本的實作，所以就決定採用這套方法，也確實解決了問題&lt;/p>
&lt;p>本次部落格會摘錄官方說明 &lt;a class="link" href="https://redis.io/topics/distlock" target="_blank" rel="noopener"
>Distributed locks with Redis&lt;/a>，並整理 Martin Kleppmann 提出質疑 &lt;a class="link" href="http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html" target="_blank" rel="noopener"
>How to do distributed locking&lt;/a>與作者再次回復 &lt;a class="link" href="http://antirez.com/news/101" target="_blank" rel="noopener"
>Is Redlock safe?&lt;/a>&lt;/p>
&lt;p>題外話介紹 Martin Kleppmann，他就是《Designing Data-Intensive Applications》一書的作者，目前仍是我最推薦的工程書籍，可以參考之前的筆記&lt;br>
&lt;a class="link" href="https://yuanchieh.page/post/2018-03-28_designing-data-intensive-applications-%E4%B8%8A/" target="_blank" rel="noopener"
>技術筆記 Designing Data-Intensive Applications 上&lt;/a>&lt;br>
&lt;a class="link" href="https://yuanchieh.page/post/2018-04-19_designing-data-intensive-applications-%E4%B8%8B/" target="_blank" rel="noopener"
>技術筆記 Designing Data-Intensive Applications 下&lt;/a>&lt;/p>
&lt;h1 id="redlock-簡介">Redlock 簡介&lt;/h1>
&lt;p>當我們在設計分散式 Lock 機制時，有三點原則必須考量到&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Safety&lt;/strong> &lt;br>
當 Lock 被取走後，在釋放之前不能有另一個 Client 取得 Lock，也就是 &lt;code>mutual exclusive&lt;/code>&lt;/li>
&lt;li>&lt;strong>DeadLock Free&lt;/strong>&lt;br>
Lock 必須在一段時間後(TTL) 自動釋放，避免握住 Lock 的 Client 跨掉而 Lock 從此不能被釋放&lt;/li>
&lt;li>&lt;strong>Fault Tolerance&lt;/strong>&lt;br>
整體系統不能有單一節點失敗的可能，必須考量系統容錯性&lt;/li>
&lt;/ol>
&lt;p>後續解說演算法實作時，會不斷去檢視這三點原則是否被滿足&lt;/p>
&lt;p>需注意到&lt;code>容錯機制&lt;/code>可能會聯想到 Master / Slave 架構，但是在 Redis 中 Slave 資料備份是非同步的，所以當 Master 掛掉到 Slave 接手，中間的時間差 Client 有機會取得多個相同 Lock，這會違反第一點原則，Cluster 架構同理&lt;/p>
&lt;p>所以這裡作者提議的容錯機制主要基於 &lt;code>Multi-Master&lt;/code> 機制，後續會有更深入的解釋&lt;/p>
&lt;h2 id="單機原則">單機原則&lt;/h2>
&lt;p>再考量分散式設計之前，讓我們先思考單一台 Redis 如何實作 Lock 機制&lt;/p>
&lt;h3 id="取得-lock">取得 Lock&lt;/h3>
&lt;p>當要取得 Lock，可以用以下的指令&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-md" data-lang="md">&lt;span class="line">&lt;span class="cl">SET resource_name my_random_value NX PX 30000
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;code>NX&lt;/code> 表示只有當 &lt;code>resource_name&lt;/code> 不存在才創建這個 Key，避免重複建立，符合第一點原則 &lt;br>
&lt;code>Px 30000&lt;/code> 表示 Key 的 TTL 是 30秒，符合第二點原則&lt;/p>
&lt;h3 id="釋放-lock">釋放 Lock&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-lua" data-lang="lua">&lt;span class="line">&lt;span class="cl">&lt;span class="kr">if&lt;/span> &lt;span class="n">redis.call&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;get&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">KEYS&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">ARGV&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="kr">then&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">return&lt;/span> &lt;span class="n">redis.call&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;del&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">KEYS&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">else&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">return&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">end&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>在釋放 Key 時，必須先檢查 Key 對應的 Value是不是我們一開始塞進去的值，也就是上個步驟的 &lt;code>my_random_value&lt;/code>，這是要確保移除的 Lock 是當初我們取得的 Lock，試想一下情況&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-md" data-lang="md">&lt;span class="line">&lt;span class="cl">&lt;span class="k">1.&lt;/span> Client A 取得 Lock
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">2.&lt;/span> Client A 時間超過 TTL，Redis 移除 Lock
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">3.&lt;/span> Client B 取得相同 Lock，因為 Client A 超時所以 Client B 可以取得 Lock
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">4.&lt;/span> Client A 此時要釋放 Lock
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>步驟四如果沒有檢查，Client A 不小心移除了 Client B 的 Lock，此時就會破壞第一點原則&lt;/p>
&lt;h3 id="random-string">Random String&lt;/h3>
&lt;p>Random String 的產生機制，可以取 &lt;code>/dev/urandom&lt;/code> 的 20 bytes，/dev/urandom 是*unix 系統產生偽亂數的方式，依據設定的不同可能是從環境噪音、網路數據封包等外在物理現象，這樣的做法可以保證較好的隨機性，也可以用其他簡單的方式，例如取系統時間加上 client_id 等等，取決於實作者的設計&lt;/p>
&lt;h2 id="套用至分散式系統">套用至分散式系統&lt;/h2>
&lt;h3 id="取得-lock-1">取得 Lock&lt;/h3>
&lt;p>假設目前有 N 台 Redis master，這 N 台都跑在獨立的環境上而非使用 Cluster 架構，假設 N=5，以下是實作步驟&lt;/p>
&lt;ol>
&lt;li>取得當前時間 T1&lt;/li>
&lt;li>用相同的 Key / Value 依序取得 N 台的 Lock，在取得 Lock 時要設定連線Timeout，此 Timeout(ex. 5~50ms) 應該遠小於 Lock 的 TTL (ex. 10s)，避免 Client 浪費太多時間在等死掉的 Redis Server，Client 因儘速取得 Lock&lt;/li>
&lt;li>當取得 Lock 後，假設此時時間為 T2，Client 檢查 T2-T1 是否大於 Lock 有效時間 TTL，只有當&lt;code>時間有效且大多數的 Redis Servre(過半數，也就是 &amp;gt;=3)&lt;/code> 才算是有效取得 Lock&lt;/li>
&lt;li>此時 Lock 僅剩有效時間是 T2 - T1&lt;/li>
&lt;li>如果 Client 取得 Lock 失敗 (例如有效時間是負數、無法取得過半 Redis Master Lock)，Client 必須對每一台 Redis Master 發送釋放 Lock 指令，即使該台 Redis Master 沒有給他 Lock&lt;/li>
&lt;/ol>
&lt;p>分散式代表各個程序沒有同步的時間上，而且每台機器因為計時器的物理性質，會有時間偏差的問題(Clock Drift 問題) &lt;br>
時間計算會影響第三步驟的有效時間，所以需要減去一點偏差當作補償，但現實世界的時間計算頂多就幾個毫秒的誤差&lt;/p>
&lt;p>所以實際 Lock 的有效時間會是 &lt;code>TTL - (T2-T1) - CLOCK_DRIFT&lt;/code>&lt;/p>
&lt;h3 id="retry">Retry&lt;/h3>
&lt;p>如果 Client 取得 Lock 失敗，應該在一定秒數後隨機 delay 一段時間，再次重新嘗試，隨機 delay 是為了錯開同時多個 Client，讓較快者可以先取得 Lock，如果 Client 沒有取得 Lock，應該儘速釋放 Lock&lt;/p>
&lt;h3 id="釋放-lock-1">釋放 Lock&lt;/h3>
&lt;p>同時向所有的 Redis Master 釋放 Lock&lt;/p>
&lt;h2 id="檢驗演算法">檢驗演算法&lt;/h2>
&lt;p>因為再依序取得 Lock 會有時間差，假設 Client 從第一個 Redis Master 取得 Lock 時間為 &lt;code>T1&lt;/code>，最後一個 Master 回傳時間為 &lt;code>T2&lt;/code>，那麼第一個 Lock 僅剩的生命時間是 &lt;code>TTL - (T2 - T1) - Clock Drift&lt;/code>，這也就是最小有效時間 MIN_VALIDITY；Clock Drift 是上述的時間誤差；(T2-T1) 則是取 Lock 的等待時間&lt;/p>
&lt;p>假設 Client 取 Lock 時間 (T2-T1) &amp;gt; TTL，也就是 Client 取到最後一個 Lock 時第一個 Lock 已經失效了，那此時就會全部釋放，不會有錯誤產生&lt;/p>
&lt;p>假設 Client 成功取得 Lock，那在先前的條件保證，沒有其他用戶可以在 MIN_VALIDITY 內取得大多數 Master 的 Lock，也就不會破壞 Lock 的原則性&lt;/p>
&lt;blockquote>
&lt;p>要確保 MIN_VALIDITY 的時間內關鍵資源能夠運作完成，不然 TTL 過後 Lock 被其他人取走，Lock 就失去互斥原則&lt;/p>
&lt;/blockquote>
&lt;h2 id="性能故障復原">性能、故障復原&lt;/h2>
&lt;p>Redis 常用於高性能需求的場景，我們會希望 Lock 取得/釋放可以越快，增加 throughput 與降低延遲，在過程最好的方式是 Client 同時向多台 Master 取 Lock&lt;/p>
&lt;p>另外考量到故障復原的部分，假設今天取得 Lock 後 Master 故障了，假使沒有開 &lt;code>AOF&lt;/code> 儲存機制，那可能 Lock 沒有保存到磁碟上，復原時遺失就有機會違反第一點原則&lt;br>
假使有開 &lt;code>AOF&lt;/code>，也記得要調整 &lt;code>fsync&lt;/code> 頻率，最保險是設成 always，但這會影響性能&lt;/p>
&lt;p>但除了即時資料備份到磁碟上外，還可以考慮另一種做法，當 Master 故障復原後，&lt;code>延遲重啟的時間大於 TTL&lt;/code>，也就是說讓原先 Master 上的 Lock 都釋放或自動失效，之後再重新加入就能避免違反安全原則，不過要小心如果超過多數的 Server 故障，需要等相對長的時間才能重新運作，此階段 Lock 都無法取得&lt;/p>
&lt;p>最後如果有餘裕可以設計延長 Lock，讓握有 Lock 的 Client 可以延長手中的 Lock&lt;/p>
&lt;p>以上是摘錄自官網文件的整理&lt;/p>
&lt;h2 id="nodejs-package---redlock-實作">Nodejs Package - Redlock 實作&lt;/h2>
&lt;p>看完演算法，來看一下 Nodejs 版本的實作 &lt;a class="link" href="https://github.com/mike-marcacci/node-redlock" target="_blank" rel="noopener"
>mike-marcacci/node-redlock&lt;/a>&lt;/p>
&lt;p>他在 &lt;code>Redlock.prototype._lock&lt;/code> 部分實現 Lock 機制&lt;/p>
&lt;p>截幾個關鍵片段，輪詢所有的 server&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="k">return&lt;/span> &lt;span class="nx">self&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">servers&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">forEach&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kd">function&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">server&lt;/span>&lt;span class="p">){&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="nx">request&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">server&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">loop&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>request 主要封裝 lock 的 script，支援如果同時多個 resource 要鎖可以一起鎖&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">request&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kd">function&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">server&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">loop&lt;/span>&lt;span class="p">){&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="nx">server&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nb">eval&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">self&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">lockScript&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">resource&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">length&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">...&lt;/span>&lt;span class="nx">resource&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">value&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">ttl&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">loop&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">};&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>這一段考量到 drift 問題，檢查 Lock 的有效時間，並且只有在取得多數 Redis Server 同意才往下繼續&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// Add 2 milliseconds to the drift to account for Redis expires precision, which is 1 ms,
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// plus the configured allowable drift factor
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="kr">const&lt;/span> &lt;span class="nx">drift&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">Math&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">round&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">self&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">driftFactor&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="nx">ttl&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">const&lt;/span> &lt;span class="nx">lock&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="nx">Lock&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">resource&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">value&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">start&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nx">ttl&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="nx">drift&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">attempts&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// SUCCESS: there is concensus and the lock is not expired
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="k">if&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">votes&lt;/span> &lt;span class="o">&amp;gt;=&lt;/span> &lt;span class="nx">quorum&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="nx">lock&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">expiration&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nb">Date&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">now&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="nx">resolve&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">lock&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>主要關鍵是這幾個部分，其餘的就是封裝&lt;/p>
&lt;h2 id="martin-kleppmann-的質疑">Martin Kleppmann 的質疑&lt;/h2>
&lt;h4 id="中斷導致-lock-有效判斷錯誤">中斷導致 Lock 有效判斷錯誤&lt;/h4>
&lt;p>在分散式系統設計中，時間是一個非常難以掌握的因素，程序可能因為各種狀況而導致時間序錯亂，例如說系統時間不準、網路延遲、程式運作遇到垃圾回收、作業系統切換 Process 導致中斷等，所以各種檢查機制都有可能因而出現錯誤，例如以下的例子
&lt;img src="https://yuanchieh.page/post/img/unsafe-lock.png"
loading="lazy"
>&lt;/p>
&lt;ol>
&lt;li>Client1 取得 Lock 後&lt;/li>
&lt;li>結果遇到 GC 暫停運作&lt;/li>
&lt;li>Lock 超過 TTL 自動釋放，此時&lt;/li>
&lt;li>Client2 成功取得 Lock，並更新 DB 紀錄&lt;/li>
&lt;li>接著 Client 從 GC 中恢復，他以為自己手上有 Lock 可以去更新 DB&lt;/li>
&lt;/ol>
&lt;p>這樣就違反了 Lock 的安全性原則&lt;/p>
&lt;p>直覺解法是在更新 DB 之前 Client 再去檢查 Lock 的時效性，但 GC 可能卡在檢查完之後的那一個點，所以設定再多檢查都是沒用的&lt;/p>
&lt;p>實際解法也蠻直覺的，系統全域有個不斷遞增的發號機制，每取一次 Lock 就配一個數字，在 DB 更新的時候，檢查對應的數字是不是有大於上次更新的數字，就可以避免掉上述提到的問題，就是 &lt;code>Fencing 機制&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/fencing-tokens.jpeg"
loading="lazy"
>&lt;/p>
&lt;h3 id="太快樂觀預估時間的複雜性">太快樂觀預估時間的複雜性&lt;/h3>
&lt;p>TTL 的「時間」計算有實作問題，Redis 目前使用 &lt;code>gettimeofday&lt;/code> 而非 &lt;code>monotonic clock&lt;/code> 的時間&lt;br>
前者是系統時間，這是可以被調動，例如 NTP Server 同步 / Admin 手動調整等，所以時間可能大幅度前後跳動&lt;br>
而後者是每當 timmer 發出 interrupt 就 &lt;code>持續遞增永不回頭&lt;/code>，所以在判斷兩個點的絕對時間差用後者會比較精準&lt;/p>
&lt;p>試想如果 Client1 取得 Lock 後 Redis 時間跳轉立刻 Lock 失效，結果 Client2 又可以拿到 Lock，就會違反安全性原則&lt;/p>
&lt;p>此外 Martin Kleppmann 認為 Redlock &lt;code>預設太多時間因素是可預期的&lt;/code>，像是網路延遲、時鐘偏移等問題，但這不是分散式演算法正確的設計方式，所以 Redlock 的安全性是建立在半同步系統當中(意即各種時間因素是有上限且可以被假設的)，而不是真正的分散式設計&lt;/p>
&lt;h2 id="antirez-再次回復">antirez 再次回復&lt;/h2>
&lt;p>以上兩點主要是被質疑的部分，接著看 antirez 回覆&lt;/p>
&lt;h3 id="當自動釋放機制導致-lock-的-mutual-exlusive-機制失效時">當自動釋放機制導致 Lock 的 Mutual Exlusive 機制失效時&lt;/h3>
&lt;p>在 Martin 第一點質疑中，他覺得要加上遞增的 Token 當作保護機制，避免 Client 手上 Token 過期還去更新 Resource，達到&lt;code>強保證性&lt;/code>&lt;/p>
&lt;p>讓我們先回過頭來想為什麼我們會需要分散式 Lock，正是因為我們的關鍵資源本身沒辦法一次只服務一個請求 (&lt;code>linearizable&lt;/code>)，如我自身案例是 API Server 同時有多台&lt;/p>
&lt;p>而 Martin 提出的系統全域有個遞增 Token，關鍵資源在操作時會先去檢查 Token，這本身就是個 linearizable store，讓所以的操作不再併發而變成線性逐一處理，這本身就與分散式的現況矛盾&lt;/p>
&lt;p>再者如果有個遞增 Token 系統，那 Redlock 在產生 Lock 的 Value 時，用這個遞增 Token 取代原本的隨機字串也有一樣的效果&lt;/p>
&lt;p>又或是根本不需要遞增函數，只要把隨機字串也記錄到關鍵資源上，在操作時去比對先後兩者是否相同，同樣有 Fencing 的效果&lt;/p>
&lt;h3 id="基於時間的過多理想化假設">基於時間的過多理想化假設&lt;/h3>
&lt;p>作者承認 Redis 應該改用 monotonic time，但是看來還沒有個結論是否要修正 &lt;a class="link" href="https://github.com/antirez/redis/issues/416" target="_blank" rel="noopener"
>Redis Repo - (#416) Use monotonic clock when available&lt;/a>，主要問題在於並非所有系統都支援 monotonic time API&lt;/p>
&lt;p>關於時間跳動的問題，作者並沒有給出很明確的答案，但看來只能盡量避免(例如 Admin 不要改動系統時間)而不是從演算法的部分改進，因為目前 Redis 還不是用 monotonic time API&lt;/p>
&lt;p>接著考量一個情況&lt;/p>
&lt;ol>
&lt;li>取得當前時間&lt;/li>
&lt;li>取得 Lock&lt;/li>
&lt;li>計算當前時間&lt;/li>
&lt;li>檢查 Lock 是否還在有效期間&lt;/li>
&lt;li>如果有 Lock，則繼續處理&lt;/li>
&lt;/ol>
&lt;p>在步驟一到三，不論是網路延遲、程序中斷等時間問題，都沒有關係，因為步驟四會再次檢查 Lock&lt;/p>
&lt;p>但如果是在第四步到第五步之間，這時候&lt;code>沒有任何有自動釋放機制的分散式 Lock&lt;/code> 可以保證 Mutual Exclusive，只能靠關鍵資源本身的機制，這就回到上一步說的 Fencing 機制，例如說 DB 就寫入遞增 Token 或隨機字串，讓後者不能更新&lt;/p>
&lt;blockquote>
&lt;p>所以 Redlock 安全嗎？&lt;/p>
&lt;/blockquote>
&lt;p>答案取決於對於安全的要求有多高，&lt;/p>
&lt;ol>
&lt;li>配置多台 Redis Server 並開啟 fsync = always 的 Redlock 機制&lt;/li>
&lt;li>在系統時間沒有大幅度跳動的情況下&lt;/li>
&lt;li>Lock TTL 保證大於關鍵資源的運行時間或是在關鍵資源處有 fencing 機制&lt;/li>
&lt;/ol>
&lt;p>符合這三點 Redlock 就是安全的&lt;br>
正因為我們沒有其他方法避免 Race Condition，才會採用 Redlock 或是其他樂觀鎖的處理機制&lt;/p></description></item><item><title>MongoDB Isolation 與 Transaction</title><link>https://yuanchieh.page/posts/2018/2018-10-14-mongodb-isolation-%E8%88%87-transaction/</link><pubDate>Sun, 14 Oct 2018 01:39:58 +0000</pubDate><guid>https://yuanchieh.page/posts/2018/2018-10-14-mongodb-isolation-%E8%88%87-transaction/</guid><description>&lt;p>在 MongoDB中，其 Isolation 與 SQL標準定義的 Isolation Level不同，畢竟NoSQL注重於海量讀寫 、集群式的應用場景，自然所面對的問題也就差異很多，但也因此在面臨 Concurrency 時的讀寫保證問題，以下是閱讀官方文件並整理的結果。&lt;/p>
&lt;p>&lt;a class="link" href="https://docs.mongodb.com/manual/core/read-isolation-consistency-recency/" target="_blank" rel="noopener"
>&lt;strong>Read Isolation, Consistency, and Recency - MongoDB Manual&lt;/strong>&lt;/a>&lt;/p>
&lt;h2 id="isolation-level">Isolation level&lt;/h2>
&lt;p>正如同 SQL 不同的 Isolation 試圖在每一層解決不同的問題 (dirty read/ unrepeatable read / phantom read) 的問題，同樣在 MongoDB中也有幾種Isolation level&lt;/p>
&lt;h3 id="read-uncommitted">Read Uncommitted&lt;/h3>
&lt;p>Client 可以讀取那些寫入但尚未持久化的資料&lt;/p>
&lt;ol>
&lt;li>Client 會讀取到尚未 durable 的資料，以及寫入MongoDB後在該寫入Client 收到成功訊息之前&lt;br>
( A writes → MongoDB accept → B read A’s write → A accept success)&lt;/li>
&lt;li>如果是多行寫入的操作(如 updateMany)，Client 可能會讀到更新未完全的文檔 (如果一次更新五個文檔，可能讀到三個更新後文檔，但每個文檔如果更新多個欄位，MongoDB保證不會讀取到部分更新欄位的文檔)&lt;/li>
&lt;li>Client 可能讀到之後被roll back 的數據&lt;/li>
&lt;/ol>
&lt;p>這是預設的 Isolation Level&lt;/p>
&lt;p>在 MongoDB 4.0之後才加入 多文檔的 transaction 保證，在沒有 transaction 保證下多文檔讀取會有幾個問題&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Non-point-in-time read&lt;/strong>&lt;br>
&lt;code>A read d1 ~ d5 → B update d3 → A 可能會讀到B更新的 d3&lt;/code>&lt;br>
也就是在讀取發生的該時機點沒有產生 snapshot，可以理解成 unrepeatable read&lt;/li>
&lt;li>&lt;strong>Non-serializable operations&lt;/strong>&lt;br>
&lt;code>A read d1 → B write d2 → B write d1 → A read d2&lt;/code> &lt;br>
對於 d1 來說，是 A 先讀接著換 B 寫 / 對於 d2 來說，是 B寫再換 A讀；&lt;br>
這個情況導致兩者的讀寫相依順序剛好顛倒，所以沒辦法序列化讀寫順序&lt;/li>
&lt;li>&lt;strong>Miss match read&lt;/strong>&lt;br>
**同樣是讀取中有更新發生，可能會導致更新的文檔與讀取的條件發生錯置，原本符合條件的可能更新後不符合種種&lt;/li>
&lt;/ol>
&lt;h3 id="cursor-snapshot">Cursor Snapshot&lt;/h3>
&lt;p>用 cursor 讀取在某些情況下可能會將同一個文檔返回多次，因為同期間文檔可能因為更新等因素而改變了位置&lt;/p>
&lt;p>但如果文檔中有 unique key，則同個文檔僅會返回一次&lt;/p>
&lt;h3 id="real-timeorder">Real Time Order&lt;/h3>
&lt;p>允許同一個文檔的多組 thread 讀寫宛如單一 thread 讀寫一般，亦即在同一個文檔中會以序列化方式執行讀寫請求&lt;/p>
&lt;h3 id="causal-consistency">Causal Consistency&lt;/h3>
&lt;p>因果一致性，例如刪除符合某特定條件的文檔，接著讀取同樣條件，後者狀況依賴於前者，於是前後兩者便有了因果關係；&lt;br>
MongoDB 3.6+ 提供 writeConcern:majority / readConcern:majory 外加因果性的保證&lt;/p>
&lt;ol>
&lt;li>Read your writes&lt;br>
寫入後緊接著讀取寫入的資料&lt;/li>
&lt;li>Monotonic reads&lt;br>
讀取資料的結果不可以是比上一次讀取結果更早的結果&lt;br>
例如 w1 → w2 → r1 → r2，w2 相依於 w1，r1 這裏相依於 w2 ，那麼 r2 不可能讀取到 w1 的結果&lt;/li>
&lt;li>Monotonic writes&lt;br>
因果序先於其他寫入者必然先發生寫入&lt;br>
也就是 w1 → w2，w1 / w2 之間可能還有其他的寫入操作，但是 w1 必然比 w2 早執行&lt;/li>
&lt;li>Writes follow reads&lt;br>
要在讀取之後寫入的寫入事件必然發生於讀取之後&lt;br>
也就是 r1 → w1，則r1 必然發生於 w1 之前&lt;/li>
&lt;/ol>
&lt;h2 id="write-concern-與-readconcern">Write Concern 與 Read Concern&lt;/h2>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/1__F__a3X__box50qZOllKb__D1g.jpeg"
loading="lazy"
alt="截自 MongoDB 官方文件 https://docs.mongodb.com/manual/core/causal-consistency-read-write-concerns/"
>
截自 MongoDB 官方文件&lt;/p>
&lt;p>&lt;a class="link" href="https://docs.mongodb.com/manual/core/causal-consistency-read-write-concerns/" target="_blank" rel="noopener"
>https://docs.mongodb.com/manual/core/causal-consistency-read-write-concerns/&lt;/a>&lt;/p>
&lt;p>MongoDB 在讀寫有不同的 Isolation Level可以設定，也就是 Read Concern / Write Concern，不同的Level對應不同的&lt;code>一致性與可用性的考量&lt;/code>，交錯後有多種組合狀況，Isolation level 可以定義在&lt;code>連線 session&lt;/code>、&lt;code>Transaction&lt;/code>、&lt;code>單次操作&lt;/code>&lt;/p>
&lt;h3 id="write-concern">Write Concern&lt;/h3>
&lt;p>Write Concern 主要是指 &lt;code>當 Client 送出寫入請求後，Server會在什麼條件下回應Client 已經成功寫入了&lt;/code>，總共有三個參數可以使用&lt;/p>
&lt;ol>
&lt;li>w: &lt;br>
寫入保證條件&lt;/li>
&lt;li>j: &lt;br>
Boolean，是否寫入 disk journal 後才返回&lt;/li>
&lt;li>wtimeout: &lt;br>
多久後發生timeout避免鎖死，&lt;code>0&lt;/code> 代表不需要 timeout 設計&lt;/li>
&lt;/ol>
&lt;p>其中 w 又有幾種選項&lt;/p>
&lt;ol>
&lt;li>&lt;code>&amp;lt;number&amp;gt;&lt;/code>:
對應幾個 mongod server 收到寫入請求才會回應成功訊息&lt;br>
&lt;code>0&lt;/code> 代表不需要回應，但可能會回傳 network / socket 相關錯誤&lt;br>
&lt;code>1&lt;/code> 預設值，寫入請求被 standalone mongod 或是 primary 收到&lt;br>
&lt;code>超過 1&lt;/code> 僅適用於 replica set，也就是 primary + secondary 總共幾個收到才會回應成功&lt;/li>
&lt;li>&lt;code>majority&lt;/code>&lt;br>
擁有投票權的節點*過半數都收到寫入請求，對應的 j 變數如果沒有宣告則看系統的預設值 &lt;code>[writeConcernMajorityJournalDefault](https://docs.mongodb.com/manual/reference/replica-configuration/#rsconf.writeConcernMajorityJournalDefault &amp;quot;writeConcernMajorityJournalDefault&amp;quot;)&lt;/code> &lt;br>
Arbiter 雖然有投票權，但是不算在其中，因為沒有儲存資料&lt;/li>
&lt;li>&lt;code>&amp;lt;tag&amp;gt;&lt;/code>&lt;br>
在設定 replica set 可以指定 tag，此處的 tag 表示寫入請求被送往符合的 replica set&lt;/li>
&lt;/ol>
&lt;h3 id="read-concern">Read Concern&lt;/h3>
&lt;h4 id="local">local&lt;/h4>
&lt;p>最低的讀取保證，讀到的資料不保證已經被 majority 寫入且可能資料會 rollback&lt;/p>
&lt;h4 id="available">available&lt;/h4>
&lt;p>基本上跟 local一樣，只有在 shard cluster 的時候 available 是最低延遲的讀取請求，並不會更新 sharding中的中繼資料(does not contact the shard’s primary nor the config servers for updated &lt;a class="link" href="https://docs.mongodb.com/manual/core/sharded-cluster-config-servers/" target="_blank" rel="noopener"
>metadata&lt;/a>.)&lt;/p>
&lt;p>因此可能會讀取到 &lt;strong>orphaned document&lt;/strong> (某些資料已經搬移到其他chunk但是在原始位置因為錯誤或是意外shutdown導致沒有清除，需要額外清除 &lt;a class="link" href="https://docs.mongodb.com/manual/reference/command/cleanupOrphaned/#dbcmd.cleanupOrphaned" target="_blank" rel="noopener"
>cleanupOrphaned&lt;/a>&lt;/p>
&lt;h4 id="majority">majority&lt;/h4>
&lt;p>&lt;code>保證讀取到的資料是被replica set 中的多數確認過，且不會 rollback&lt;/code>，注意是 acknowledge 而不一定是 durable，要對應看writeConcern!&lt;/p>
&lt;p>如果是在多文檔transaction中，除非 writeConcern 是 majority，否則 同在 transaction 中的 readConcern 不能提供保證。&lt;/p>
&lt;p>但需要注意 &lt;code>majority 僅能確保讀取資料不會 rollback，但是不保證能讀到最新資料&lt;/code>&lt;/p>
&lt;p>官方建議在 primary-secondary-arbiter PSA架構下關閉 majority，因為複製不會到 arbiter，所以要達到 majority條件就是 primary-secondary 兩台都成功寫入才算成功，會給系統帶來比較大的負擔，容錯性也變差*&lt;/p>
&lt;h4 id="linearizable">linearizable&lt;/h4>
&lt;p>基於 majority 提供更強的保證，&lt;code>保證寫入後的讀取都不會讀到更舊的資料&lt;/code>，除了選擇讀取的節點外，還會去跟多數節點確認，之後才返回值，所以效能需求又高出一截；&lt;/p>
&lt;p>為什麼還需要跟多數節點在確認呢？&lt;br>
主要是怕 network partitioning，也就是因為網路延遲而導致原本的 replica set 被分割，例如原本 3台變成 1 + 2，而 2台一組的部分因為還符合多數可以產生新的 primary，此時如果有人去讀(majority) 1那一台就可能取得舊資料，因為 1徹底跟其他節點分離；&lt;br>
加上 linearizable可以避免掉此問題，詳細可參考此問答 &lt;a class="link" href="https://stackoverflow.com/questions/42615319/the-difference-between-majority-and-linearizable" target="_blank" rel="noopener"
>https://stackoverflow.com/questions/42615319/the-difference-between-majority-and-linearizable&lt;/a>&lt;/p>
&lt;h4 id="snapshot">snapshot&lt;/h4>
&lt;p>只在多文檔 transaction 中生效，文檔沒有過多敘述，但推敲應該也就是保證在同一個 transaction 中不會讀取到 transaction 之後的更動。&lt;/p>
&lt;h3 id="讀取的實例說明">讀取的實例說明&lt;/h3>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/1__YKPt3WxP__8WzvsmvFwZSKw.jpeg"
loading="lazy"
alt="截自 MongoDB 官方文件"
>
截自 MongoDB 官方文件&lt;/p>
&lt;h4 id="readconcern-majority">readConcern: majority&lt;/h4>
&lt;ol>
&lt;li>t0 : primary 收到寫入請求，因為這時 primary 值還是 write_prev&lt;/li>
&lt;li>t1：secondary1 收到寫入同步請求，此時 primary / secondary 還是 write_prev&lt;/li>
&lt;li>t2：secondary2 收到寫入同步請求，此時值也都還是 write_prev&lt;/li>
&lt;li>t3：因為writeConcern是 majority，此時 primary 收到 secondary1的回覆，此時 primary才變成 write_new，並且回復 client 寫入成功，但是 secondary1 還是停留在 write_prev&lt;/li>
&lt;li>t4：primary 收到 secondary2 回覆&lt;/li>
&lt;li>t5：secondary1收到 primary1，此時 snapshot才更新為 write_new&lt;/li>
&lt;li>t5：secondary2 動作同上&lt;/li>
&lt;/ol>
&lt;h4 id="readconcern-local">readConcern: local&lt;/h4>
&lt;ol>
&lt;li>t0：primary 此時值是 write_new&lt;/li>
&lt;li>t1：secondary1 此時值是 write_new&lt;/li>
&lt;li>t2：secondary2 此時值是 write_new&lt;/li>
&lt;/ol>
&lt;p>readConcern: majority 讀取時是透過 snapshot，根據此篇&lt;a class="link" href="https://yq.aliyun.com/articles/60553?spm=a2c4e.11155435.0.0.21623312JJZa8i" target="_blank" rel="noopener"
>文章MongoDB readConcern 原理解析&lt;/a> 指出&lt;/p>
&lt;blockquote>
&lt;p>MongoDB 会起一个单独的snapshot 线程，会周期性的对当前的数据集进行 snapshot，并记录 snapshot 时最新 oplog的时间戳，得到一个映射表&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>只有确保 oplog 已经同步到大多数节点时，对应的 snapshot 才会标记为 commmited，用户读取时，从最新的 commited 状态的 snapshot 读取数据，就能保证读到的数据一定已经同步到的大多数节点。&lt;/p>
&lt;/blockquote>
&lt;h2 id="結語">結語&lt;/h2>
&lt;p>這篇主要整理與理解一些官方文件的資料與設定，並沒有什麼太重大的結論，更進一步可以看一下，條列在 Causal Consistency 下的不同讀寫保證&lt;/p>
&lt;p>&lt;a class="link" href="https://docs.mongodb.com/manual/core/causal-consistency-read-write-concerns/" target="_blank" rel="noopener"
>&lt;strong>Causal Consistency and Read and Write Concerns - MongoDB Manual&lt;/strong>&lt;/a>&lt;/p>
&lt;h3 id="註記">註記&lt;/h3>
&lt;h4 id="擁有投票權">擁有投票權&lt;/h4>
&lt;p>在MongoDB的 Replica set中，只有以下幾種狀態有投票權 (voting node)&lt;/p>
&lt;ol>
&lt;li>primary&lt;/li>
&lt;li>secondary&lt;/li>
&lt;li>startup2：節點載入成員的設定檔正式成為 replica set的一員並開始初始化同步與索引建立&lt;/li>
&lt;li>recovering：當節點尚未準備讀取請求時，等到 client 覺得ok便會轉為 secondary，這部分沒有明說 recovering 中做了什麼&lt;/li>
&lt;li>arbiter&lt;/li>
&lt;li>rollback：當舊的 primary 因為某些因素被剔除，之後選出了新的 primary，舊的 primary 後來恢復同步發現有些寫入當初沒有同步，此時舊的 primary會選擇 rollback 這些沒有同步的資料&lt;/li>
&lt;/ol>
&lt;p>目前 MongoDB的 replica set最多只能有 50個成員，其中最多只能有 7 名成員有投票權；其他沒有投票權的成員可以當作備份或是讀取請求的節點。&lt;/p>
&lt;h4 id="replica-set容錯性問題">Replica Set 容錯性問題&lt;/h4>
&lt;p>replica set 規定是要在超過多數的形況下才能運作，所以最低必須要有三個可投票節點才能成立，試想以下狀況&lt;/p>
&lt;ol>
&lt;li>3台機器，可以容錯一台，需要保證 67%的機器運作正常&lt;/li>
&lt;li>4台機器，也是僅可容錯一台，需要保證 75%的機器運作正常&lt;/li>
&lt;/ol>
&lt;p>這也是為什麼會推薦使用奇數台的機器；&lt;/p>
&lt;p>在 PSA下，Arbiter 不能同步資料，所以 write: majority 必須同步寫入 primary + secondary，所以系統容錯就變差，同時加重機器的負擔。&lt;/p></description></item><item><title>MongoDB Shard Cluster 架設</title><link>https://yuanchieh.page/posts/2018/2018-09-08-mongodb-shard-cluster-%E6%9E%B6%E8%A8%AD/</link><pubDate>Sat, 08 Sep 2018 07:53:36 +0000</pubDate><guid>https://yuanchieh.page/posts/2018/2018-09-08-mongodb-shard-cluster-%E6%9E%B6%E8%A8%AD/</guid><description>&lt;p>在大量資料需要儲存下，可以將 MongoDB做 Sharding 與 Replica Set 設置，增加DB的吞吐量與可用性。&lt;/p>
&lt;p>參考 MongoDB的官網，可以很簡單的就架起 Shard Cluster 架構，以下簡單記錄實作過程。&lt;br>
目前使用 v3.4，不採用最新版 4.0 是因為公司環境用 3.4，但看了文件好像差不太多。&lt;/p>
&lt;p>&lt;a class="link" href="https://www.mongodb.com/presentations/webinar-everything-you-need-know-about-sharding?jmp=docs" target="_blank" rel="noopener"
>&lt;strong>Webinar: Everything You Need to Know about Sharding&lt;/strong>&lt;/a>&lt;/p>
&lt;p>強烈建議看完這部一小時的影片，整個觀念非常清楚。&lt;/p>
&lt;p>資料庫設定必須從最一開始的&lt;br>
「會有多少資料要儲存？ 結構大概是如何？ 需要保存多久或是有什麼業務需求？寫入會大概是怎樣情況？讀取又會是如何？會需要高吞吐量又或是低延遲嗎？」&lt;br>
這些因子會根本性決定資料庫的設計，包含 是否要 sharding / database、collection、index 如何設計，甚至是主機的規格與地點選擇。&lt;/p>
&lt;h3 id="架構圖">架構圖&lt;/h3>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/1__HijPG3lhbfiPMS2sHD9mpg.jpeg"
loading="lazy"
alt="截圖自官網"
>
截圖自官網&lt;/p>
&lt;p>主要有三個部分：&lt;/p>
&lt;ol>
&lt;li>Mongos：對外連接 DB Client 接收對DB的讀寫，接著再根據 Config Server 決定到哪個 Shard 讀寫(會cache住查詢結果)&lt;/li>
&lt;li>Config Server：紀錄 metadata與資料在哪個 shard 上，3.4之後&lt;code>必須是replica set 架構&lt;/code>&lt;/li>
&lt;li>Shard：分片儲存資料處，&lt;code>建議採用 replica set 架構&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>最基本要開 1台 Mongos / 3 台 Config Server / 2 組Shard Replica Set 共 11台，分享一下我在 AWS 上開 11台 t2.nano 配 EBS 一天大概兩美金。&lt;br>
以下預設每台機器都安裝好 &lt;a class="link" href="mailto:mongo@3.4" >mongo@3.4&lt;/a>&lt;/p>
&lt;h3 id="實作">實作&lt;/h3>
&lt;h4 id="config-server">Config server&lt;/h4>
&lt;p>因為有些設定檔寫成 config file比較方便，以下是我的 mongo.conf&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-conf" data-lang="conf">&lt;span class="line">&lt;span class="cl">&lt;span class="c"># mongod.conf
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c"># for documentation of all options, see:
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c"># [http://docs.mongodb.org/manual/reference/configuration-options/](http://docs.mongodb.org/manual/reference/configuration-options/)
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c"># where to write logging data.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span>&lt;span class="nv">systemLog&lt;/span>&lt;span class="err">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nv">destination&lt;/span>&lt;span class="err">:&lt;/span> &lt;span class="nv">file&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nv">logAppend&lt;/span>&lt;span class="err">:&lt;/span> &lt;span class="kc">true&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nv">path&lt;/span>&lt;span class="err">:&lt;/span> &lt;span class="err">/&lt;/span>&lt;span class="nv">var&lt;/span>&lt;span class="err">/&lt;/span>&lt;span class="nv">log&lt;/span>&lt;span class="err">/&lt;/span>&lt;span class="nv">mongodb&lt;/span>&lt;span class="err">/&lt;/span>&lt;span class="nv">mongod.log&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c"># Where and how to store data.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span>&lt;span class="nv">storage&lt;/span>&lt;span class="err">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nv">dbPath&lt;/span>&lt;span class="err">:&lt;/span> &lt;span class="err">/&lt;/span>&lt;span class="nv">home&lt;/span>&lt;span class="err">/&lt;/span>&lt;span class="nv">ec2-user&lt;/span>&lt;span class="err">/&lt;/span>&lt;span class="nv">fs&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nv">journal&lt;/span>&lt;span class="err">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nv">enabled&lt;/span>&lt;span class="err">:&lt;/span> &lt;span class="kc">true&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c"># how the process runs
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span>&lt;span class="nv">processManagement&lt;/span>&lt;span class="err">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nv">fork&lt;/span>&lt;span class="err">:&lt;/span> &lt;span class="kc">true&lt;/span> &lt;span class="c"># fork and run in background
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span> &lt;span class="nv">pidFilePath&lt;/span>&lt;span class="err">:&lt;/span> &lt;span class="err">/&lt;/span>&lt;span class="nv">var&lt;/span>&lt;span class="err">/&lt;/span>&lt;span class="nv">run&lt;/span>&lt;span class="err">/&lt;/span>&lt;span class="nv">mongodb&lt;/span>&lt;span class="err">/&lt;/span>&lt;span class="nv">mongod.pid&lt;/span> &lt;span class="c"># location of pidfile
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c"># network interfaces
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span>&lt;span class="nv">net&lt;/span>&lt;span class="err">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nv">port&lt;/span>&lt;span class="err">:&lt;/span> &lt;span class="nv">27017&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nv">bindIp&lt;/span>&lt;span class="err">:&lt;/span> &lt;span class="mf">172.31.26.157&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mf">127.0.0.1&lt;/span> &lt;span class="c"># Listen to local interface only, comment to listen on all interfaces.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">sharding&lt;/span>&lt;span class="err">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nv">clusterRole&lt;/span>&lt;span class="err">:&lt;/span> &lt;span class="nv">configsvr&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">replication&lt;/span>&lt;span class="err">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nv">replSetName&lt;/span>&lt;span class="err">:&lt;/span> &lt;span class="nv">config_replica&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>三個參數要注意，其他都是預設值&lt;/p>
&lt;ol>
&lt;li>sharding：&lt;br>
關於sharding的設定，記得config server 都必須設成&lt;code>clusterRole: configsvr&lt;/code>&lt;/li>
&lt;li>replication：&lt;br>
每個replica set 都要一組 name分辨&lt;/li>
&lt;li>net：&lt;br>
注意 bindIp 除了 127.0.0.1 外，還要加一個其他機器可以查找的ip，因為replica set 機器間必須要可以溝通，這邊我是用內部IP&lt;br>
另外 127.0.0.1也要保留，有些權限操作必須用 localhost(如關閉Server)&lt;/li>
&lt;/ol>
&lt;p>啟動 server 指令是&lt;/p>
&lt;p>sudo mongod &amp;ndash;config mongo.conf &amp;ndash;fork &amp;ndash;syslog&lt;/p>
&lt;p>加 &lt;code>—-fork&lt;/code>是為了跑在背景，三台 config server 都一樣，接著選一台當作 Primary，進入後做 replica set 設定&lt;/p>
&lt;p>這部分因為我看一開始的config 不能寫在一起，必須要 &lt;code>mongod啟動後再執行&lt;/code>，我是另外寫script，接著直接喂進 mongo shell 執行&lt;/p>
&lt;p>replica.js，_id對應是剛才的 replicaSetName，members就是三台 config server，注意要是可以連線的 ip。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">rs&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">initiate&lt;/span>&lt;span class="p">({&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">_id&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s2">&amp;#34;config_replica&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">configsvr&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">members&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">{&lt;/span>&lt;span class="nx">_id&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">host&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s2">&amp;#34;172.31.26.157:27017&amp;#34;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">{&lt;/span>&lt;span class="nx">_id&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">host&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s2">&amp;#34;172.31.23.205:27017&amp;#34;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">{&lt;/span>&lt;span class="nx">_id&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">host&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s2">&amp;#34;172.31.16.98:27017&amp;#34;&lt;/span>&lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">})&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>指令是&lt;/p>
&lt;p>&lt;code>mongo &amp;lt; replica.js&lt;/code>&lt;/p>
&lt;h4 id="sharding-cluster">Sharding Cluster&lt;/h4>
&lt;p>這部分也差不多，只差在 mongo.conf的sharding 參數&lt;/p>
&lt;p>sharding:&lt;br>
clusterRole: shardsvr&lt;/p>
&lt;p>剩下的 replica set 設定都跟 config server 一樣&lt;/p>
&lt;h4 id="mongos">Mongos&lt;/h4>
&lt;p>接下來是Mongos，同樣用mongo.conf 啟動 &lt;code>mongos&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// mongos.conf
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="nx">sharding&lt;/span>&lt;span class="o">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">configDB&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">config_replica&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="mf">172.31&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="mf">26.157&lt;/span>&lt;span class="o">:&lt;/span>&lt;span class="mi">27017&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mf">172.31&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="mf">23.205&lt;/span>&lt;span class="o">:&lt;/span>&lt;span class="mi">27017&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mf">172.31&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="mf">16.98&lt;/span>&lt;span class="o">:&lt;/span>&lt;span class="mi">27017&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>執行指令&lt;/p>
&lt;blockquote>
&lt;p>sudo mongos &amp;ndash;config mongos.conf &amp;ndash;fork &amp;ndash;syslog&lt;/p>
&lt;/blockquote>
&lt;p>接著就是設定 sharding，這邊一樣寫個 js script&lt;/p>
&lt;p>sh.addShard( &amp;ldquo;&lt;replSetName>/&lt;ip1>,&lt;ip2>,&lt;ip3>&amp;rdquo;)&lt;br>
&amp;hellip;. 有幾個加幾個&lt;/p>
&lt;p>這樣就完成了&lt;/p>
&lt;p>接著可以登入 mongo shell 檢查&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">sh&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">status&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>影片建議將 mongos 與 APP Server 放在一起&lt;/p>
&lt;/blockquote>
&lt;h3 id="設定-sharding">設定 Sharding&lt;/h3>
&lt;p>架設好了之後，接著就是要設定 sharding 機制，目前可以針對某個DB的某個Collection 的 Key 做 hash shard / range shard，&lt;br>
range shard 是當 key 在某個範圍內就往哪邊塞；&lt;br>
hash shard 則是會把 key 做 hash 比較容易分散。&lt;/p>
&lt;p>// 以下指令在 mongo shell&lt;br>
// 首先啟動sharding&lt;br>
sh.enableSharding(&amp;quot;&lt;database>&amp;quot;)&lt;/p>
&lt;p>// 針對某個 collection 設定&lt;br>
sh.shardCollection(&amp;quot;&lt;database>.&lt;collection>&amp;quot;, { &lt;key> : &lt;direction>})&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// example
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="nx">sh&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">shardCollection&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;test.test2&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;name&amp;#34;&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s2">&amp;#34;hashed&amp;#34;&lt;/span>&lt;span class="p">})&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">sh&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">shardCollection&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;test.test&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;name&amp;#34;&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">})&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>必須注意到如果在sharding 前collection裡面就有值，要先建立 index 才可以設定 shard。&lt;/p>
&lt;p>查看狀態可以用 &lt;code>sh.status()&lt;/code>&lt;/p>
&lt;h4 id="注意事項">注意事項&lt;/h4>
&lt;p>有蠻多小細節與限制要注意&lt;/p>
&lt;h4 id="chunk-size">Chunk Size：&lt;/h4>
&lt;p>Chunk 是分片儲存的一個單位，每當有寫入紀錄時會塞到Chunk中，如果超過Chunk Size ，Balancer 平衡器就會把Chunk 拆成兩半分散到不同的Shard去&lt;/p>
&lt;p>所以如果 Chunk size 太小會造成過度頻繁的拆分與搬遷，導致性能低落；&lt;br>
如果Chunk size 過大則會造成資料分散不均勻&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// in Mongos server -&amp;gt; mongo shell
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="nx">use&lt;/span> &lt;span class="nx">config&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">db&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">settings&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">save&lt;/span>&lt;span class="p">(&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="nx">_id&lt;/span>&lt;span class="o">:&lt;/span>&lt;span class="s2">&amp;#34;chunksize&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">value&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="o">&amp;lt;&lt;/span>&lt;span class="nx">sizeInMB&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="p">}&lt;/span> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>特別注意，MongoDB初始化的 chunk size 為 1，也就是所有的寫入一開始都會往一個 chunk 塞，導致後續的再平衡很消耗性能，所以建議要調整 numInitialChunks 或是自行初始化 chunk size。&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>&lt;a class="link" href="https://docs.mongodb.com/manual/reference/method/sh.shardCollection/" target="_blank" rel="noopener"
>https://docs.mongodb.com/manual/reference/method/sh.shardCollection/&lt;/a>&lt;br>
&lt;a class="link" href="https://docs.mongodb.com/manual/tutorial/create-chunks-in-sharded-cluster/" target="_blank" rel="noopener"
>https://docs.mongodb.com/manual/tutorial/create-chunks-in-sharded-cluster/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h4 id="sharding-key">sharding key:&lt;/h4>
&lt;p>已知 chunk 超過size 會由 Balancer 負責平衡，如果可以在一開始選好一點的 sharding key 就能避免太多次的拆分與平衡，讓資料均勻的散佈。&lt;/p>
&lt;p>選擇 range shard，要&lt;code>避免選擇會遞增的Key，例如預設的_id&lt;/code> ，預設_id 是會隨著 timestamp 而遞增，這會導致插入新資料都只會插到同一個 chunk 中，勢必要不斷的拆分！&lt;/p>
&lt;p>如果要用 _id，就很適合用 hash shard，因為透過 hash function 遞增的key也比較會被均勻分散；&lt;br>
在配置 hash shard上，如果一開始 collection 是空的，MongoDB可以設定 &lt;code>numInitialChunks&lt;/code>要初始化多少個 chunk；&lt;br>
但要記得 &lt;code>key 不能是 float&lt;/code> ，因為 hash function 會把 key 先轉乘 64 bit int，所以 2.1 / 2.2 / 2.9 都會被分散到同一個 chunk 上。&lt;/p>
&lt;p>參考影片的步驟，&lt;/p>
&lt;ol>
&lt;li>如果選則 data center id 不是好的id，因為可能造成資料不平均&lt;/li>
&lt;li>如果選擇 timestamp 不是好 id ，因為是遞增，所以新增會插到同一個 chunk&lt;/li>
&lt;li>如果選擇 hash(timestamp) 不是好 id，因為讀取時會需要到多個 shard&lt;/li>
&lt;li>選擇 device_id 配合 hash shard 是個不錯選擇(假設 device_id 是固定的且每個 device 生成差不多的資料)&lt;/li>
&lt;li>但如果讀取大多是要讀某個裝置近期某個時間的資料，那改用 (device_id, timestamp) 的組合 key 最理想。&lt;/li>
&lt;/ol>
&lt;p>1. Cardinality 高度異質性&lt;br>
2. Write distributed 寫入分布均勻&lt;br>
3. Query isolation 讀取可以集中於同一個 shard&lt;br>
4. reliability 如果某個shard掛了，盡量不要影響到所有的搜尋&lt;br>
5. Index locality 盡量讓讀取可以套用最多的索引&lt;/p>
&lt;blockquote>
&lt;p>注意：shard key 設定了就不能改變，如果要改就必須重新 sharding，務必謹慎。&lt;/p>
&lt;/blockquote>
&lt;h4 id="指令限制">指令限制&lt;/h4>
&lt;p>根據文件 ，針對單一文檔操作如 updateOne / deleteOne必須附帶 shard key；&lt;/p>
&lt;p>$group 不能使用，必須改用 mapReduce / aggregate 方法。&lt;/p>
&lt;p>每個 shard key 都必須是 index或是 compound index的prefix，同時可以設定為 unique，但必須遵守&lt;br>
1. 如果該文檔已經 sharded，不能把其他欄位設為 unique&lt;br>
2. 如果其他欄位是 unique，則無法對此文檔 shard&lt;br>
總之，要unique 只能是 shard key欄位。&lt;/p>
&lt;h3 id="tag-aware-shard">Tag-Aware Shard&lt;/h3>
&lt;p>除了range shard / hash shard之外，還可以針對個別 shard 做標記，接著就可以透過條件設定讓某些資料固定儲存在該shard上，這樣最大的好處是可以做&lt;code>地理位置優化&lt;/code> ，例如美國用戶就可以讀寫在美國區的 shard上。&lt;/p>
&lt;p>1. 先增加Tag&lt;br>
sh.addShardTag(&lt;shard name>, &amp;ldquo;EU&amp;rdquo;)&lt;/p>
&lt;p>2. 指定 tag shard 的條件，可以設置多個&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">sh&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">addTagRange&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;chat.messages&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">{&lt;/span> &lt;span class="s2">&amp;#34;country&amp;#34;&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="s2">&amp;#34;US&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;userid&amp;#34;&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="nx">MinKey&lt;/span> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">{&lt;/span> &lt;span class="s2">&amp;#34;country&amp;#34;&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="s2">&amp;#34;US&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;userid&amp;#34;&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="nx">MaxKey&lt;/span> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;NA&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">sh&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">addTagRange&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;chat.messages&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">{&lt;/span> &lt;span class="s2">&amp;#34;country&amp;#34;&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="s2">&amp;#34;DE&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;userid&amp;#34;&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="nx">MinKey&lt;/span> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">{&lt;/span> &lt;span class="s2">&amp;#34;country&amp;#34;&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="s2">&amp;#34;DE&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;userid&amp;#34;&lt;/span> &lt;span class="o">:&lt;/span> &lt;span class="nx">MaxKey&lt;/span> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;EU&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>接著 mongodb 就會自動平衡&lt;/p>
&lt;h3 id="參考資料">參考資料&lt;/h3>
&lt;p>非常詳細的簡中文章：&lt;a class="link" href="http://www.cnblogs.com/zhoujinyi/p/4635444.html" target="_blank" rel="noopener"
>http://www.cnblogs.com/zhoujinyi/p/4635444.html&lt;/a>&lt;/p>
&lt;h3 id="備註">備註&lt;/h3>
&lt;p>根據官網，最好要有安全設定與角色配置，實作上必須要特別留意。&lt;/p></description></item><item><title>PostgreSQL json 操作</title><link>https://yuanchieh.page/posts/2018/2018-08-23-postgresql-json-%E6%93%8D%E4%BD%9C/</link><pubDate>Thu, 23 Aug 2018 08:36:20 +0000</pubDate><guid>https://yuanchieh.page/posts/2018/2018-08-23-postgresql-json-%E6%93%8D%E4%BD%9C/</guid><description>&lt;p>Postgresql 可以用欄位 jsonb 型別儲存 json 格式的資料，並提供不少內建的函式可以協助查詢，以下稍微整理一些常用的情景。&lt;/p>
&lt;h3 id="示範資料庫">示範資料庫&lt;/h3>
&lt;p>&lt;a class="link" href="https://www.db-fiddle.com/f/vk8sCioCh1RstjSWXsZnWr/4" target="_blank" rel="noopener"
>&lt;strong>DB Fiddle - SQL Database Playground&lt;/strong>&lt;/a>&lt;/p>
&lt;p>基本就是是 Orders / Products 兩張表，Orders 中資料用 data jsonb 格式存儲，Products 則是常規的欄位定義。&lt;/p>
&lt;p>Orders 資料大約長這樣&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-json" data-lang="json">&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;id&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;cost&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">200&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;products&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[{&lt;/span>&lt;span class="nt">&amp;#34;id&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nt">&amp;#34;nums&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">},&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="nt">&amp;#34;id&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nt">&amp;#34;nums&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">}],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;details&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>&lt;span class="nt">&amp;#34;title&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;memo&amp;#34;&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h4 id="操作-json">操作 JSON&lt;/h4>
&lt;p>如果是要做 json 的欄位索取，可以用 &lt;code>-&amp;gt;&lt;/code> ，如果要回傳字串結果用 &lt;code>-&amp;gt;&amp;gt;&lt;/code>&lt;/p>
&lt;p>例如說 &lt;code>data-&amp;gt;’details’-&amp;gt;&amp;gt;’title’&lt;/code> 就會回傳 &lt;code>“memo”&lt;/code>&lt;/p>
&lt;p>陣列也可以指定哪個位置，例如 &lt;code>data-&amp;gt;’product’-&amp;gt;0-&amp;gt;’id’&lt;/code>&lt;/p>
&lt;p>使用上如果是 key 用 &lt;code>`&lt;/code> 單引號括著，如果是陣列位置才不需要，不然會一直回傳 null&lt;/p>
&lt;p>另外要特別注意的是&lt;code>-&amp;gt;&amp;gt;&lt;/code> 都是回傳字串，所以如果要跟其他類型做比對，需要自己做格式轉換，例如 &lt;code>Cast( data-&amp;gt;&amp;gt;”id” as int ) = id&lt;/code> 拿 data.id 跟 int 型別的自增主鍵做比對&lt;/p>
&lt;h4 id="陣列長度">陣列長度&lt;/h4>
&lt;p>如果是想要知道陣列的長度是多少，可以用 jsonb_array_elements&lt;/p>
&lt;p>例如 &lt;code>jsonb_array_length(data-&amp;gt;’products’) &amp;gt; 2&lt;/code> ，這會直接回傳 int&lt;/p>
&lt;h4 id="key-是否存在">Key 是否存在&lt;/h4>
&lt;p>有三種用法，&lt;code>?’比對key’ ?|[’比對key1’, ’比對key2’] ?&amp;amp;[’比對key1’, ’比對key2’]&lt;/code> ，結果回傳 boolean&lt;/p>
&lt;p>例如找出 data 中包含`detail`欄位的資料&lt;br>
 &lt;code>select * from Orders where data?’detail’;&lt;/code>&lt;/p>
&lt;p>?| 則是後者陣列中只要命中一個就為 true，?&amp;amp; 則是要陣列中所有的元素都存在才是 true。&lt;/p>
&lt;h4 id="攤平陣列">攤平陣列&lt;/h4>
&lt;p>算是做第一正規化，我希望透過 Join Products 計算每筆訂單的總額，但因為 Orders 中的 data-&amp;gt;product 是陣列，所以需要 &lt;code>jsonb_array_elements&lt;/code> ，&lt;code>jsonb_array_elements&lt;/code> 會直接回傳 set&lt;/p>
&lt;p>&lt;code>select jsonb_array_elements(data-&amp;gt;’products’) as product_item from Orders;&lt;/code> 這樣就可以做到第一正規化&lt;/p>
&lt;p>接著蠻神奇的是可以直接將 Order 與 &lt;code>jsonb_array_elements&lt;/code> 做 CROSS JOIN&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">select&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Orders&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">Sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">Cast&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">product_item&lt;/span>&lt;span class="o">-&amp;gt;&amp;gt;&lt;/span>&lt;span class="s1">&amp;#39;nums&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">as&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="err">\&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Products&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">price&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Orders&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">jsonb_array_elements&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">data&lt;/span>&lt;span class="o">-&amp;gt;&lt;/span>&lt;span class="s1">&amp;#39;products&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">as&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">product_item&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">left&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">join&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Products&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">on&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">Cast&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">product_item&lt;/span>&lt;span class="o">-&amp;gt;&amp;gt;&lt;/span>&lt;span class="s1">&amp;#39;id&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">as&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Products&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">group&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">by&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Orders&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">id&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>但結果竟然不是預期的笛卡爾積 N*M，而是會自動幫你把屬於該訂單的 product 對應好，到現在還想不透怎麼會這樣。&lt;/p>
&lt;h4 id="json-vsjsonb">json vs jsonb&lt;/h4>
&lt;p>Postgresql 支援兩種合法 json 可插入的格式 &lt;code>json&lt;/code> &lt;code>jsonb&lt;/code> ，但兩者有些微的差異&lt;/p>
&lt;ol>
&lt;li>json&lt;br>
以純文字型態插入，包含空白、換行，同時保持原本的鍵值順序&lt;/li>
&lt;li>jsonb&lt;br>
以二進制方式儲存，會把重複的鍵值去除(後者覆蓋前者)&lt;/li>
&lt;/ol>
&lt;p>jsonb 支援 index，在插入時需要較長的時間，但是查詢速度較快，是比較通用的選擇格式。&lt;/p>
&lt;p>但如果有需要保持原本鍵值順序、或是單純想保留原本的 json 格式才使用 &lt;code>json&lt;/code> 格式&lt;/p>
&lt;p>參考資料&lt;br>
&lt;a class="link" href="https://my.oschina.net/swingcoder/blog/489769" target="_blank" rel="noopener"
>https://my.oschina.net/swingcoder/blog/489769&lt;/a>、&lt;a class="link" href="https://stackoverflow.com/questions/22654170/explanation-of-jsonb-introduced-by-postgresql" target="_blank" rel="noopener"
>https://stackoverflow.com/questions/22654170/explanation-of-jsonb-introduced-by-postgresql&lt;/a>&lt;/p>
&lt;h3 id="結語">結語&lt;/h3>
&lt;p>有看到一些實驗是把 Postgresql 當作 NoSQL 使用，但個人覺得還是偏玩票性質，關聯式資料庫還是遵守正規化設計，僅把 json 當作額外的彈性就好&lt;/p></description></item><item><title>MySQL Explain分析與Index設定查詢優化</title><link>https://yuanchieh.page/posts/2018/2018-07-30-mysql-explain%E5%88%86%E6%9E%90%E8%88%87index%E8%A8%AD%E5%AE%9A%E6%9F%A5%E8%A9%A2%E5%84%AA%E5%8C%96/</link><pubDate>Mon, 30 Jul 2018 10:14:40 +0000</pubDate><guid>https://yuanchieh.page/posts/2018/2018-07-30-mysql-explain%E5%88%86%E6%9E%90%E8%88%87index%E8%A8%AD%E5%AE%9A%E6%9F%A5%E8%A9%A2%E5%84%AA%E5%8C%96/</guid><description>&lt;p>資料庫日積月累資料量逐步攀升，MySQL在一般查詢是透過全表搜尋，所以大量的資料會導致查詢等方式越來越慢；&lt;br>
MySQL提供索引建置，一般的索引透過 B+ Tree，在記憶體中快速查找資料所在位置，將搜尋從 O(n) 約*降至O(log n)，索引支援Where / Order by / Range中的條件判斷。&lt;/p>
&lt;p>以下產生User / Order兩張百萬筆資料的Table&lt;br>
1. 並試著用Explain 分析SQL語法&lt;br>
2. 透過索引設定比較前後的查詢速度優化&lt;/p>
&lt;h3 id="table">Table&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">CREATE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">TABLE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;users&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;id&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">11&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NOT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NULL&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">AUTO_INCREMENT&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;uuid&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">char&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">36&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">CHARACTER&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">SET&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">utf8mb4&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">COLLATE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">utf8mb4_bin&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">DEFAULT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NULL&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;age&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">11&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">DEFAULT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NULL&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;firstName&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">varchar&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">255&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">DEFAULT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NULL&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;lastName&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">varchar&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">255&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">DEFAULT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NULL&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;createdAt&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">datetime&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NOT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NULL&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;updatedAt&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">datetime&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NOT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NULL&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">PRIMARY&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">KEY&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;id&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">ENGINE&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">InnoDB&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">AUTO_INCREMENT&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1000001&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">DEFAULT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">CHARSET&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">utf8mb4&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">CREATE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">TABLE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;orders&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;id&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">11&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NOT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NULL&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">AUTO_INCREMENT&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;uuid&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">char&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">36&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">CHARACTER&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">SET&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">utf8mb4&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">COLLATE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">utf8mb4_bin&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">DEFAULT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NULL&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;cost&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">11&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">DEFAULT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NULL&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;user_id&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">11&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">DEFAULT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NULL&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;user_uuid&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">varchar&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">255&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">DEFAULT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NULL&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;tradeNo&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">varchar&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">255&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">DEFAULT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NULL&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;createdAt&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">datetime&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NOT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NULL&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;updatedAt&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">datetime&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NOT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">NULL&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">PRIMARY&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">KEY&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;id&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">ENGINE&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">InnoDB&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">AUTO_INCREMENT&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">750001&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">DEFAULT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">CHARSET&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">utf8mb4&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="explain">Explain&lt;/h3>
&lt;p>Explain可以用於分析 SELECT / DELETE / UPDATE / INSERT / REPLACE 語句，條列出執行SQL語句時會使用到的 Table與欄位資訊，實際回傳的欄位有&lt;/p>
&lt;ol>
&lt;li>select_type: &lt;br>
SELECT查詢的狀態，常見有幾種型別
&lt;ul>
&lt;li>SIMPLE：簡單查詢&lt;/li>
&lt;li>PRIMARY：主查詢，相對於子查詢Subquery&lt;/li>
&lt;li>UNION：在UNION語句中的非首個SELECT&lt;/li>
&lt;li>SUBQUERY：子查詢&lt;br>
如果非SELECT則為其他動詞如DELETE&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>table: &lt;br>
也就是使用的Table名稱&lt;/li>
&lt;li>partitions:&lt;br>
如果有使用 partition功能才會顯示&lt;/li>
&lt;li>type: &lt;br>
&lt;code>type&lt;/code> 參數非常重要，這會決定此次SQL語句使用索引狀況，由優至劣順序介紹&lt;br>
&lt;strong>const / system&lt;/strong>&lt;br>
查詢用上primary / unique key，也就是條件剛好匹配一個行，因為只讀取一行所以速度最快；&lt;br>
system是特殊類的const，用於查詢 system相關的表，如&lt;br>
&lt;code>explain select * from 'proxies_priv' where user=’root’&lt;/code>
&lt;strong>eq_ref&lt;/strong> :用於多表 join下，如果在條件判斷 = 上用了&lt;code>PRIMARY KEY&lt;/code> 或&lt;code>UNIQUE NOT NULL&lt;/code>也就是條件剛好匹配一個行&lt;br>
此範例的 join select就是用上&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#jointype_eq_ref" target="_blank" rel="noopener"
>&lt;code>eq_ref&lt;/code>&lt;/a>因為 user.id是 primary key&lt;br>
&lt;code>explain select * from orders left join users on users.id = orders.user_id where orders.cost &amp;gt; 100;&lt;/code>&lt;br>
&lt;strong>ref&lt;/strong>&lt;br>
用於多表 join下，如果是用leftmost prefix key或是非 &lt;code>[eq_ref](https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#jointype_eq_ref)&lt;/code> 條件中的key，也就是可能會匹配多行 
&lt;ul>
&lt;li>index_merge：&lt;br>
如果查詢用上多個key，例如&lt;br>
&lt;code>explain select id from users where id = 2 or id=100 or uuid=’21d9dadb-038f-427d-8ef1-c2b3aa0994e6';&lt;/code>&lt;br>
(id / uuid 都是 index)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>range
將key用於範圍查詢，如
&lt;ul>
&lt;li>&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/comparison-operators.html#operator_equal" target="_blank" rel="noopener"
>=&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/comparison-operators.html#operator_not-equal" target="_blank" rel="noopener"
>&amp;lt;&amp;gt;&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/comparison-operators.html#operator_greater-than" target="_blank" rel="noopener"
>&amp;gt;&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/comparison-operators.html#operator_greater-than-or-equal" target="_blank" rel="noopener"
>&amp;gt;=&lt;/a>`,&lt;/li>
&lt;li>&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/comparison-operators.html#operator_less-than" target="_blank" rel="noopener"
>&amp;lt;&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/comparison-operators.html#operator_less-than-or-equal" target="_blank" rel="noopener"
>&amp;lt;=&lt;/a>,&lt;/li>
&lt;li>&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/comparison-operators.html#operator_is-null" target="_blank" rel="noopener"
>IS NULL&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/comparison-operators.html#operator_equal-to" target="_blank" rel="noopener"
>&amp;lt;=&amp;gt;&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/comparison-operators.html#operator_between" target="_blank" rel="noopener"
>BETWEEN&lt;/a>,&lt;/li>
&lt;li>&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/string-comparison-functions.html#operator_like" target="_blank" rel="noopener"
>LIKE&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/comparison-operators.html#function_in" target="_blank" rel="noopener"
>IN()&lt;/a>` &lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>index：&lt;br>
全表索引檢索，常用於索引可覆蓋查詢欄位，所以不需要到磁碟讀取資料&lt;br>
ALL：&lt;br>
最差的查詢方式，全表搜尋&lt;/li>
&lt;/ul>
&lt;ol start="6">
&lt;li>possible_keys：&lt;br>
可能會用上的key&lt;/li>
&lt;li>key：&lt;br>
實際用上的key&lt;/li>
&lt;li>key_len：&lt;br>
實際key使用的比對長度&lt;/li>
&lt;li>ref：&lt;br>
用在與索引比對的常數或欄位，如&lt;br>
&lt;code>explain delete from users where id=1;&lt;/code> ref值為 const，因為是1；&lt;br>
如果比對的是欄位則會出現欄位名，如 &lt;code>index_search.orders.user_id&lt;/code>&lt;/li>
&lt;li>rows：&lt;br>
MySQL預計要讀取的行數&lt;/li>
&lt;li>filtered：&lt;br>
MySQL根據條件預計會篩選掉的比例，以百分比顯示，所以最大值為100，也就是每個 rows都用上&lt;/li>
&lt;li>Extra：&lt;br>
額外補充，有幾個值需要留意&lt;br>
＊Using filesort：&lt;br>
MySQL在排序上需要做額外的處理，會耗費大量的性能。&lt;br>
* Using Where：&lt;br>
有加入條件判斷，如果不是要刻意掃全表，理論上都會出現這個值；&lt;br>
如果Extra沒有出現Using Where 且 type為 ALL/ index，小心就落入了全表掃描。&lt;br>
* Using index：&lt;br>
索引搜尋且覆蓋索引，就不用再額外讀取實際的row 資料。&lt;/li>
&lt;/ol>
&lt;h3 id="實際使用">實際使用&lt;/h3>
&lt;p>我透過 nodejs塞入百萬筆假資料，可以參考連結取得&lt;/p>
&lt;h4 id="right-join-和-leftjoin差異">RIGHT JOIN 和 LEFT JOIN差異&lt;/h4>
&lt;p>users / orders Table目前只有 id是 primary key，比對以下兩個語句，兩者執行速度天差地遠&lt;/p>
&lt;p>&lt;code>explain select * from users left join orders on orders.user_id = users.id;&lt;/code>&lt;/p>
&lt;p>&lt;code>explain select * from users right join orders on orders.user_id = users.id;&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/outer-join-simplification.html" target="_blank" rel="noopener"
>MySQL內部會把RIGTH JOIN轉換成LEFT JOIN&lt;/a>，所以其實就是比較先執行 users 還是 orders，在內部 &lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/nested-join-optimization.html" target="_blank" rel="noopener"
>JOIN是多層 for loop查找&lt;/a>並比對 on 的條件判斷；&lt;br>
在這個案例中， 後者的執行速度會遠快於前者因為後者先loop orders，接著拿 orders.user_id去 users中比對users.id，而 user.id是 primary key所以速度非常快；&lt;br>
反之 orders.user_id沒有索引，只能全表掃描。&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/1__vXNThgMlQU72iv7kH3dXiw.png"
loading="lazy"
alt="explain select * from users right join orders on orders.user_id = users.id;"
>&lt;/p>
&lt;p>&lt;code>explain select * from users right join orders on orders.user_id = users.id;&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/1__fp99dWZ32mfR0yvRKL2Xfw.jpeg"
loading="lazy"
alt="explain select * from users right join orders on orders.user_id = users.id;"
>&lt;/p>
&lt;p>&lt;code>explain select * from users right join orders on orders.user_id = users.id;&lt;/code>&lt;/p>
&lt;h4 id="子查詢">子查詢&lt;/h4>
&lt;p>如果我想要條列所有訂單數超過兩筆的用戶，並同時顯示{用戶所有資料，訂單數}，可能有幾種做法&lt;/p>
&lt;ol>
&lt;li>從users , temp table取資料，temp table 是暫存 訂單數超過2的 table，兩者做 INNER JOIN &lt;br>
&lt;code>select users.*, temp.order_count from (select user_id, count(distinct orders.id) as order_count from orders group by orders.user_id having order_count &amp;gt; 2) temp INNER JOIN users on users.id = temp.user_id;&lt;/code>&lt;/li>
&lt;li>orders 先INNER JOIN users，接著才計算訂單數&lt;br>
&lt;code>select users.*, count(distinct orders.id) as order_count from orders INNER JOIN users on users.id = orders.user_id group by orders.user_id having order_count &amp;gt; 2;&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>第一點的問題是在子查詢 &lt;code>(select user_id, count(distinct orders.id) as order_count&lt;/code> 不可避免的要跑一次全表搜尋，但是暫存成 temp Table做INNER JOIN 又會在跑一次，等同於全表搜尋 orders兩次&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/1__Jeto7u4zaq9XDJ3fwSppRw.jpeg"
loading="lazy"
alt="1"
>
1&lt;/p>
&lt;p>為了避免多一次無謂的全表搜尋，先JOIN在 GROUP BY 效率就好很多。&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/1__yMDa4b2rpLrDLnY26N19ZQ.jpeg"
loading="lazy"
alt="2"
>
2&lt;/p></description></item><item><title>MySQL 關於地理位置的儲存與運算</title><link>https://yuanchieh.page/posts/2018/2018-06-21-mysql-%E9%97%9C%E6%96%BC%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AE%E7%9A%84%E5%84%B2%E5%AD%98%E8%88%87%E9%81%8B%E7%AE%97/</link><pubDate>Thu, 21 Jun 2018 22:15:22 +0000</pubDate><guid>https://yuanchieh.page/posts/2018/2018-06-21-mysql-%E9%97%9C%E6%96%BC%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AE%E7%9A%84%E5%84%B2%E5%AD%98%E8%88%87%E9%81%8B%E7%AE%97/</guid><description>&lt;p>最近突然好奇如何做LBS服務，最基本的應用場景就是找出某經緯度位置內方圓距離多少內的所有資料，所以就來研究一下MySQL如何處理地理位置。&lt;/p>
&lt;h2 id="spatial-reference-systemssrss-空間參考系統">Spatial Reference Systems(SRSs) 空間參考系統&lt;/h2>
&lt;p>&lt;a class="link" href="https://mysqlserverteam.com/spatial-reference-systems-in-mysql-8-0/" target="_blank" rel="noopener"
>&lt;strong>Spatial Reference Systems in MySQL 8.0&lt;/strong>&lt;/a>&lt;/p>
&lt;p>所有的幾何物件如點/線/面，都必須定義在同一個座標系統，例如說在XY軸平面上有一點(1,2)，但是座標系統可能是一個足球場/或是一台筆電螢幕，足球場上的座標(1,2)跟螢幕上的座標(1,2)是截然不同且無從比較起的。&lt;/p>
&lt;p>所以在定義幾何物件時，必須要同時宣告該物件所屬的座標系統，也就是 SRID(spatial reference system identifier)，MySQL和其他的DBMS都必須在相同的SRID下才能夠進行幾何運算。&lt;/p>
&lt;p>在MySQL 8.0中支援超過5000種SRSs，常見的有兩種：&lt;/p>
&lt;ol>
&lt;li>SRID 3857：&lt;br>
將地球表面投影至平面上，屬於笛卡爾座標系( &lt;a class="link" href="https://epsg.io/4499-cs" target="_blank" rel="noopener"
>Cartesian 2D CS&lt;/a>)，也就是XY軸相互垂直且單位長度一致。&lt;br>
常用於網頁上的地圖系統，如Google Map / Open Street Map等&lt;/li>
&lt;li>SRID 4326：&lt;br>
屬於真實空間座標系統，將地球視為橢圓體，也就是轉換成經緯度，座標軸彼此不是垂直的，經度最後都在南北極彙整。&lt;br>
常用於GPS&lt;/li>
&lt;/ol>
&lt;h2 id="語法使用">語法使用&lt;/h2>
&lt;p>&lt;a class="link" href="https://www.db-fiddle.com/f/bcr9MQnzYG9Acu9SUqyXRV/1" target="_blank" rel="noopener"
>&lt;strong>DB Fiddle - SQL Database Playground&lt;/strong>&lt;/a>&lt;/p>
&lt;p>創建欄位上，可以定義 GEOMETRY型別，欄位可以指定 SRID，需要索引可加上 SPATIAL INDEX(g)，InnoDB/MyISAM都支援。&lt;/p>
&lt;p>在插入欄位有兩種做法，一種是直接使用幾何形別，一種是透過 ST_GeomFromText 從字串轉換，目前只有看到後者可以指定 SRID&lt;br>
&lt;code>Insert into geom VALUES(Point(1,1), “word”);&lt;/code> &lt;br>
&lt;code>Insert into geom2 VALUES(ST_GeomFromText(‘POINT(1 1)’, 4326), “hello”);&lt;/code>
&lt;code>Insert into geom2 VALUES(ST_GeomFromText(‘POLYGON((0 0, 0 2, 2 2, 2 0, 0 0))’, 4326), “zip”); &lt;/code>&lt;/p>
&lt;p>MySQL支援多種幾何形別，例如Point / Line / Polygon等。&lt;/p>
&lt;p>運算上&lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/spatial-relation-functions-object-shapes.html#function_st-contains" target="_blank" rel="noopener"
>MySQL 8.0支援多種函式&lt;/a>，函式皆已 ST_開頭，例如&lt;br>
算兩點距離&lt;br>
&lt;code>SELECT ST_Distance((SELECT g from geom2 where name=’hello’), ST_GeomFromText(‘POINT(0 0)’, 4326)) AS distance;&lt;/code>&lt;/p>
&lt;p>判斷是否在某範圍內 (hello是 point 型別，zip 是 polygon型別，判斷)&lt;br>
&lt;code>SELECT ST_Within((SELECT g from geom2 where name=’hello’), (SELECT g from geom2 where name=’zip’))&lt;/code>&lt;/p>
&lt;h3 id="補經緯度距離換算">補：經緯度距離換算&lt;/h3>
&lt;p>在SRID 4326中，地球是偏橢圓狀，人們為了方便透過經緯度用網格做劃分，分辨地理位置的判別，所以要將經緯度換算回實際的距離需要有公式的轉換。&lt;/p>
&lt;p>&lt;a class="link" href="https://www.thoughtco.com/degree-of-latitude-and-longitude-distance-4070616" target="_blank" rel="noopener"
>&lt;strong>Learn How Far It Is From One Latitude Line to the Next&lt;/strong>&lt;/a>&lt;/p>
&lt;h3 id="經度換算">經度換算&lt;/h3>
&lt;p>經度差會隨著往南北極而遞減至零，在赤道大約是 111.321km，而南北緯 40度則為 85 km。&lt;/p>
&lt;h3 id="緯度換算">緯度換算&lt;/h3>
&lt;p>緯度間基本上是平行，所以每單位緯度差之間都是相近的，只是因為地球偏橢圓所以高緯度距離越長。&lt;br>
像是在赤道每一度緯度差實際距離是 110.567 km，在回歸線附近則是 110.948km，如果是在南北極則是 111.169 km，平均大約可以取 111 km。&lt;/p>
&lt;p>所以如果要用經緯度差換算實際距離，可以用 haversine 公式，詳細內容可以參考 Wiki&lt;br>
目前也存在多種換算公式，不同的運算複雜度帶來不同的運算準確度，可以再多加研究。&lt;/p>
&lt;p>&lt;a class="link" href="https://en.wikipedia.org/wiki/Haversine_formula" target="_blank" rel="noopener"
>&lt;strong>Haversine formula - Wikipedia&lt;/strong>&lt;/a>&lt;/p>
&lt;p>在MySQL 5.7中支援度上沒有這麼好，所以球型距離轉換公式需要自行換算，詳細可以參考此篇 &lt;a class="link" href="https://mysqlserverteam.com/mysql-5-7-and-gis-an-example/" target="_blank" rel="noopener"
>https://mysqlserverteam.com/mysql-5-7-and-gis-an-example/&lt;/a>&lt;/p></description></item><item><title>資料庫 Isolation level 與實際應用情境處理</title><link>https://yuanchieh.page/posts/2018/2018-05-28-%E8%B3%87%E6%96%99%E5%BA%AB-isolation-level-%E8%88%87%E5%AF%A6%E9%9A%9B%E6%87%89%E7%94%A8%E6%83%85%E5%A2%83%E8%99%95%E7%90%86/</link><pubDate>Mon, 28 May 2018 09:29:27 +0000</pubDate><guid>https://yuanchieh.page/posts/2018/2018-05-28-%E8%B3%87%E6%96%99%E5%BA%AB-isolation-level-%E8%88%87%E5%AF%A6%E9%9A%9B%E6%87%89%E7%94%A8%E6%83%85%E5%A2%83%E8%99%95%E7%90%86/</guid><description>&lt;p>Transaction 交易機制，可以讓單一或多筆操作聚合為單一的原子性操作，一次性成功寫入或失敗回滾，避免資料庫出現資料不一致的狀況。&lt;/p>
&lt;p>Isolation，關聯式資料庫的基本要素之一，描述當同時有多筆請求要讀寫同一筆資料時的處理狀況。&lt;/p>
&lt;p>以下參考 《Designing Data-Intensive Application》第七章與&lt;/p>
&lt;p>&lt;a class="link" href="https://medium.com/@mz026/%E9%80%8F%E9%81%8E-payment-service-%E8%88%87-db-isolation-level-%E6%88%90%E7%82%BA%E8%8E%AB%E9%80%86%E4%B9%8B%E4%BA%A4-a2d035049038" target="_blank" rel="noopener"
>&lt;strong>透過 Payment Service 與 DB Isolation Level 成為莫逆之交&lt;/strong>&lt;/a>&lt;/p>
&lt;p>越高層級的Isolation提升資料的一致性，但也帶來效能上的損耗，以下整理實際應用邏輯與對應適合的 Isolation設計。&lt;/p>
&lt;h3 id="dirty-write">Dirty Write&lt;/h3>
&lt;p>複寫其他尚未commit 的 transaction 更新。&lt;/p>
&lt;h3 id="dirty-read">Dirty Read&lt;/h3>
&lt;p>讀取到其他Transaction 更新但尚未 commit 的值。&lt;/p>
&lt;h3 id="read-skew-non-repeatable-read">Read Skew (Non Repeatable Read)&lt;/h3>
&lt;p>在同一個 transaction中，讀取的值會受到其他commit的 transaction 更新影響。&lt;/p>
&lt;h3 id="phantom-read">Phantom Read&lt;/h3>
&lt;p>當其他transaction 插入或刪除資料，會影響同一 transaction中先後的讀取。&lt;/p>
&lt;h3 id="lost-update">Lost Update&lt;/h3>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/1__itWWv776OilCVdD0NghGUg.jpeg"
loading="lazy"
>&lt;/p>
&lt;p>兩個Transaction都是走 &lt;code>先讀取某值 -&amp;gt; 基於某值運算 -&amp;gt; 更新原資料&lt;/code> ，例如說購票流程，必須先檢查票種的剩餘票券，如果有剩就建立訂單並扣除名額。&lt;/p>
&lt;p>這狀況如同 票券剛好剩一張，T1 / T2 同時讀取發現票券剛好為一，兩者都以為彼此可以買票，接著 T1 / T2 先後將票券數量改為零，雖然最後票券為零但 T1/T2卻分別消耗了兩次。&lt;/p>
&lt;h4 id="解法">解法&lt;/h4>
&lt;ol>
&lt;li>將語法改成 &lt;code>compare-and-set&lt;/code>，將原先讀取到的值帶回更新時的判斷式中合併成單一SQL，如 &lt;code>Update ticket where ticket.num = 1&lt;/code> ，這樣較晚更新的 transaction就會更新不到失敗 rollback。&lt;/li>
&lt;li>在MySQL中使用 &lt;code>select … for update&lt;/code> ，這是 exclusive row lock，當取得鎖後其他 transaction 如果要 &lt;code>select lock in share mode&lt;/code> / &lt;code>select ... for update&lt;/code> / &lt;code>update&lt;/code> / &lt;code>delete&lt;/code>都不能取得鎖，直到 commit；&lt;br>
從而避免並行讀取的錯誤。&lt;br>
(對比可以並行讀取的是 &lt;code>select … for share&lt;/code> ，但同樣會排斥寫鎖)&lt;/li>
&lt;/ol>
&lt;p>使用 &lt;code>select for update&lt;/code> 就可以避免 t2 在不知道 t1更新的情況下更新，因為 t2 的 &lt;code>select for update&lt;/code> 必須等到 t1更新後才能讀取，解決 Lost update 問題&lt;/p>
&lt;h3 id="write-skew-andphantom">Write Skew And Phantom&lt;/h3>
&lt;p>Write Skew是 Lost Update更廣泛地集合，同樣是讀取後修改，但Write Skew讀取與修改的對象可以是不同的(若相同則為 Lost Update)。&lt;/p>
&lt;p>例如說：&lt;br>
有張 會議室的表，上面記錄哪些會議室被佔用的時間紀錄如 (id1, from 12:00 to 13:00)，當 T1 / T2 同時想要預約同一間會議室同一個時段，在掃過兩者都以為沒有被佔用就插入新紀錄，結果就發生兩筆預約衝突。&lt;/p>
&lt;p>又或是 遊戲暱稱不可重複，T1/T2掃過全部用戶名稱沒有發生重複，插入後才發現 T1/T2的值是重複的。&lt;/p>
&lt;p>上面兩個範例是無法透過 Lost Update提供的解法，因為沒有一個特定的 row 可以去 lock。&lt;/p>
&lt;p>整體上發生Write Skew的條件是&lt;br>
1. Select 某些資料&lt;br>
2. 依據上一步的資料做判斷&lt;br>
3. Update / Delete 一些資料&lt;br>
Write Skew 就是發生於 2,3 步之間在重複第一動會發現Select結果是不一樣的，也就是phantom read 的出現。&lt;/p>
&lt;h4 id="解法-1">解法：&lt;/h4>
&lt;ol>
&lt;li>使用 serializable isolation。&lt;br>
在MySQL Inno DB serializable中 ，select是用表級共享鎖，也就是 select 後其他 select還是可以用，但是全表不能插入更新等&lt;/li>
&lt;li>Materializing conflicts 具象化衝突&lt;br>
Write Skew是Lost Update的超集合，換言之如果可以將 Write Skew 問題降維成 Lost Update，就可以從 range lock 降為 row lock提升性能。&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>會產生 Write Skew 在於插入/刪除時沒有特定的鎖可以預先鎖住該行，換言之如果可以預先鎖到就可以避免問題。&lt;/p>
&lt;/blockquote>
&lt;p>例如說會議室資料，假設我們先將所有的會議室與時間表全部插入資料庫中，這樣當有 transaction 要預約會議室，就可以用 &lt;code>select for update&lt;/code> 某行資料，就不會有其他人ˋ並行預約同一間同一個時段的會議室。&lt;br>
但這不是萬用解，有些狀況不能預先窮舉所有可能。&lt;/p>
&lt;p>這點在文章中，有個範例有用上Serializable， 退費使用ChargeRefund 一張表紀錄，而Order在另一張表，每次要產生退費時就必須先 讀取訂單相關的所有Refund計算額度，如果訂單還有足夠餘額才會創建新的 ChargeRefund 這時候符合Write Skew發生要素，所以他們是用 Serializable 去解；&lt;/p>
&lt;p>我們網站是會將目前訂單退費餘額紀錄在Order上，所以只要透過select for udpate 去鎖該筆訂單就好，不需要用到 Serializable。&lt;/p>
&lt;p>3. 加入判別條件&lt;br>
利用 Consistence 特性 同樣在會議室問題，如果創建個 unique cluster index (room_id, startAt, endAt) 或許就可以用關連式資料庫本身特性去解決，但同樣不是萬用解&lt;/p>
&lt;p>有趣的是，Serializable 在 MySQL中不是真正的序列化執行 Transaction，他還是可以並行處理的，文件中有提到 &lt;br>
「This level is like &lt;a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html#isolevel_repeatable-read" target="_blank" rel="noopener"
>REPEATABLE READ&lt;/a>, but InnoDB implicitly converts all plain &lt;a class="link" href="https://l.facebook.com/l.php?u=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F8.0%2Fen%2Fselect.html&amp;amp;h=ATOC4ffs6BKSHXBCJcrGevajNQd1g1s7qYsAzfsfTGRFoGXhpjXyzEyFHF19205nddtzOVldg9awOjZll47FXPJlnfY7PURwsQuhbtePwESQX3OagGbirEKa8zgg8CavRkrBQ0g8N8w" target="_blank" rel="noopener"
>SELECT&lt;/a> statements to &lt;a class="link" href="https://l.facebook.com/l.php?u=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F8.0%2Fen%2Fselect.html&amp;amp;h=ATNwi30GW1C8dJO6U-XEOj-Q557fHQWkGXKkDFZ6yWph7SMPBiVlJ0QKCFJ29k47XhsMI_UQyWDc9YPC-q95T1rMQEkMjkSA9EZnnTc6xuDMa1103rYbhLpEvN-_hGHDjL0735wh6luiAV2wdsIyY4kW" target="_blank" rel="noopener"
>SELECT … FOR SHARE&lt;/a> if &lt;a class="link" href="https://l.facebook.com/l.php?u=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F8.0%2Fen%2Fserver-system-variables.html%23sysvar_autocommit&amp;amp;h=ATMitbTaqVv4e7wb_690adrkhYA2FCc7KajjshqR_sU4mUUhp3xQ_Zwsxt8-cUaYdtUB-DW4y2HCSubCiiyJ-vSsiscL6D20NMmi3DmIfjWj_KijnMrUmkCJKRVHWId1NBHX7I81MIo" target="_blank" rel="noopener"
>autocommit&lt;/a> is disabled.」&lt;/p>
&lt;p>所以要避免 Write Skew，還是要去思考要鎖多少區間，或是鎖整張表，單單改成 Serializable是沒辦法解決問題的&lt;/p>
&lt;p>在 MySQL InnoDB中，select for update / select lock in share mode 在 Repeatable Read下，會加上 Next Key Lock，Next Key Lock等同於 row lock 加上 gap lock，gap則是根據 index 拆分區段，進而可以分區鎖定，阻擋幻讀的發生； 而select for update 在沒有 where 條件下基本上就等同於table lock。&lt;/p>
&lt;p>在研究過程中，有文章提到 SQL Standard 對於 isolation level定義模糊，各家資料庫的實作也略有差異，所以相對於採用預設的 isolation level，實際了解 locking 機制比較實在。&lt;/p>
&lt;h3 id="總結">總結：&lt;/h3>
&lt;p>在書中有提到 SQL標準對於 isolation level的定義是不太明確的，導致各個資料庫都會定義各自的isolation level，而且都會有些微的差異；&lt;/p>
&lt;p>所以與其盲目的去使用常見的四種 isolation level，更重要的事針對業務邏輯去分析到底 concurrency 發生的狀況以及如何防止 race condition。&lt;/p></description></item><item><title>MySQL FOREIGN KEY Constraints 整理</title><link>https://yuanchieh.page/posts/2018/2018-04-24-mysql-foreign-key-constraints-%E6%95%B4%E7%90%86/</link><pubDate>Tue, 24 Apr 2018 10:16:08 +0000</pubDate><guid>https://yuanchieh.page/posts/2018/2018-04-24-mysql-foreign-key-constraints-%E6%95%B4%E7%90%86/</guid><description>&lt;p>&lt;a class="link" href="https://dev.mysql.com/doc/refman/5.7/en/create-table-foreign-keys.html#foreign-keys-adding" title="https://dev.mysql.com/doc/refman/5.7/en/create-table-foreign-keys.html#foreign-keys-adding"
target="_blank" rel="noopener"
>MySQL :: MySQL 5.7 Reference Manual :: 13.1.18.6 Using FOREIGN KEY Constraints&lt;/a>&lt;/p>
&lt;p>整理閱讀MySQL v5.7的FOREIGN KEY Constraints文件，並針對細節在DB Fiddle加上範例，後續FOREIGN KEY縮寫FK。&lt;/p>
&lt;p>FK限制可保證資料關聯間的完整性，關係是建立child Table指定要與 parent Table的某欄位建立關聯，&lt;code>FOREIGN KEY&lt;/code> 必須在 child Table中指定，child / parent需使用相同的DB引擎且不可為 TEMPORARY Table。&lt;/p>
&lt;p>在宣告語法上，可以透過 [CONSTRAINT symbol ] 指定這筆關聯限制的名稱，但須注意名稱不可重複否則會出錯；&lt;br>
如果擔心就不要宣告 CONSTRAINT讓 DB Engine自動產生&lt;/p>
&lt;p>&lt;a class="link" href="https://www.db-fiddle.com/f/ocxrUaBoXDVM6i1xAmyZH1/1" title="https://www.db-fiddle.com/f/ocxrUaBoXDVM6i1xAmyZH1/1"
target="_blank" rel="noopener"
>DB Fiddle - SQL Database Playground&lt;/a>&lt;/p>
&lt;h2 id="foreign-key資料型別">FOREIGN KEY 資料型別&lt;/h2>
&lt;p>有趣的是，MySQL文件只說parent中的資料欄位與child FOREIGN KEY欄位的資料型別必須&lt;strong>類似&lt;/strong>而非一致，又可細分成三類&lt;/p>
&lt;ol>
&lt;li>integer：&lt;br>
_Size &amp;amp; Sign必須相同，例如說 TINYINT / INT 就是不一樣的&lt;/li>
&lt;li>string：&lt;br>
長度不一定要相同，因為不論是parent長或是child長，FOREIGN KEY在插入時必須parent存在該筆資料；&lt;br>
所以在插入不可超過欄位長度與資料必須存在的兩個條件下，字串長度的限制就不是這麼必要&lt;/li>
&lt;li>對於非位元型別的字串，character set 和 collation必須相同&lt;/li>
&lt;/ol>
&lt;h2 id="foreign-key限制">FOREIGN KEY 限制&lt;/h2>
&lt;p>除了上述的資料型別限制外，MySQL為了搜尋上避免 full table scan&lt;/p>
&lt;ol>
&lt;li>parent 的欄位必須是「某Index中的第一欄位」，例如 index(id) / index(id, uid, ….)，因為MySQL的Index順序是由左至右，所以如果是多欄位Index只要該欄位是在第一順位也可以當作建立 FK的欄位。&lt;br>
假設不符合條件，會直接出錯無法建立child Table。&lt;/li>
&lt;li>child 的FK欄位必須是「某Index中的第一欄位」，如果沒有會自動創建。&lt;/li>
&lt;li>FK可以是多欄位，但同樣要符合「某Index中的前面順位」&lt;/li>
&lt;li>又因為FK必須建立Index，所以像 TEXT / BLOB 就不可能是 FK選項。&lt;/li>
&lt;/ol>
&lt;h2 id="關聯操作">關聯操作&lt;/h2>
&lt;p>在定義FK時可以指定關聯操作，也就是如果 parent的對應FK欄位發生改變(UPDATE / DELETE)時 child FK欄位該怎麼應對，總共有幾種定義：&lt;/p>
&lt;ol>
&lt;li>CASCADE:&lt;br>
如果是 parent紀錄被刪除了，那對應FK的chlid紀錄也一併刪除；&lt;br>
如果是 parent FK更新了新值，則child 對應的FK會更新。&lt;/li>
&lt;li>SET NULL:&lt;br>
刪除更新 parent都會導致 child的 FK紀錄設為 Null，如果設定為 SET NULL 記得 「child FK 欄位不要加 NOT NULL 會衝突」。&lt;/li>
&lt;li>RESTRICT:&lt;br>
只要child中有包含該 FK值，完全不能刪除該筆parent或更新 parent的FK欄位。&lt;/li>
&lt;li>NO ACTION: &lt;br>
在MySQL等同於 &lt;code>RESTRICT&lt;/code>。&lt;/li>
&lt;li>SET DEFAULT:&lt;br>
在MySQL InnoDB中不支援。&lt;/li>
&lt;/ol>
&lt;p>&lt;a class="link" href="https://www.db-fiddle.com/f/acgvjzoA4B5sfy1RJb6Yyj/0" target="_blank" rel="noopener"
>&lt;strong>DB Fiddle - SQL Database Playground&lt;/strong>&lt;/a>&lt;/p>
&lt;h2 id="增加或刪除fk">增加或刪除FK&lt;/h2>
&lt;p>可以透過 &lt;code>ALTER TABLE&lt;/code> 來增加FK，透過 &lt;code>DROP TABLE&lt;/code> 指定刪除FK，但如果當初沒有使用 &lt;code>CONSTRAINT&lt;/code> 宣告FK的名稱，可以用 &lt;code>SHOW CREATE TABLE&lt;/code> 取得Table資料，即可得知系統自動創建的FK名稱。&lt;/p>
&lt;h2 id="暫時關閉-fk-constraits">暫時關閉 FK CONSTRAITS&lt;/h2>
&lt;p>當使用 &lt;code>mysqldump&lt;/code> 時，為了方便重建資料MySQL會自動先關閉FK CONSTRAITS的限制&lt;/p>
&lt;p>mysql&amp;gt; SET foreign_key_checks = 0;&lt;br>
mysql&amp;gt; SOURCE &lt;em>dump_file_name&lt;/em>;&lt;br>
mysql&amp;gt; SET foreign_key_checks = 1;&lt;/p>
&lt;p>但必須注意，即使關閉了在創建 FK時仍然不可以違背 FK資料型別的驗證，不然一樣會噴錯誤!&lt;/p>
&lt;p>關閉限制後刪除/更新都不會檢查 parent是否存在對應資料，即使重新開啟限制檢查也不會回溯，所以務必小心。&lt;/p></description></item><item><title>[技術筆記] Designing Data-Intensive Applications 下</title><link>https://yuanchieh.page/posts/2018/2018-04-19-%E6%8A%80%E8%A1%93%E7%AD%86%E8%A8%98-designing-data-intensive-applications-%E4%B8%8B/</link><pubDate>Thu, 19 Apr 2018 04:08:48 +0000</pubDate><guid>https://yuanchieh.page/posts/2018/2018-04-19-%E6%8A%80%E8%A1%93%E7%AD%86%E8%A8%98-designing-data-intensive-applications-%E4%B8%8B/</guid><description>&lt;p>上集:&lt;a class="link" href="https://yuanchieh.page/posts/2018/2018-03-28-%E6%8A%80%E8%A1%93%E7%AD%86%E8%A8%98-designing-data-intensive-applications-%E4%B8%8A/" target="_blank" rel="noopener"
>Designing Data-Intensive Applications 上&lt;/a>&lt;/p>
&lt;p>隨著軟體應用程式的發展，應用的侷限(bottleneck)從CPU移轉至資料的處理，資料的巨量、複雜性與改變的速度變成棘手的問題，也就是作者所定義的「Data-Intensive」資料密集的應用程式。&lt;/p>
&lt;p>第二部分主要探討分散式儲存資料會遇到的問題與解法，分散式系統有幾大優點：&lt;/p>
&lt;ol>
&lt;li>Scalability：&lt;br>
大幅增加系統的乘載能力&lt;/li>
&lt;li>Fault Tolerance / High Availability(HA)：&lt;br>
當單一節點失效時，不影響系統的運作&lt;/li>
&lt;li>Latency：&lt;br>
如果用戶散佈全球，可以透過多節點部署使用戶地理位置最近的資料中心，降低網路延遲&lt;/li>
&lt;/ol>
&lt;h2 id="ch5-replication">Ch5. Replication&lt;/h2>
&lt;p>Replication 也就是將相同的資料透過網路複製到多台機器上，有幾個好處&lt;br>
1. 讓用戶可以取得地理位置最近的資料&lt;br>
2. 即使部分機器失效，系統也可以繼續正常運作&lt;br>
3. 增加機器 &lt;strong>讀&lt;/strong> 的負載能力&lt;/p>
&lt;p>在架構上有三種 Single-Master / Multi-Master / Leaderless，Replication帶來許多好處，但是在系統實作面會有取多的衡量，例如說複本是要同步還是非同步、如何處理錯誤的複本節點、最終一致性的曲解、read-your-writes、monotonic-reads保證等問題。&lt;/p>
&lt;h3 id="leaders-and-followers">Leaders and Followers&lt;/h3>
&lt;p>每個擁有資料庫備份資料的節點稱為 replica，為了讓每筆寫入都可以被同步到replica上，常用的架構為 leader-base，也就是Leader 負責資料的寫入，並將資料同步到 Follower中保持同步。&lt;/p>
&lt;p>這種replication架構被廣泛使用，包含Oracle / PostgreSQL / MySQL / Kafka等。&lt;/p>
&lt;h3 id="sync-andasync">Sync and Async&lt;/h3>
&lt;p>當Leader接收到寫入，這時候要決定說是否等到同步完全部的 follower才回傳成功，如果是全部 follower說成功才成功便是 Sync，若非則 Async，也可以設定超過某數量 follower 變成 Semi-Async；&lt;/p>
&lt;p>Sync好處是確保follower都擁有最新的資料，避免用戶在follower讀取到過期資料，但缺點就是如果一個 follower卡住了就會阻擋整個系統運作，系統容錯能力就大幅下降；&lt;br>
Async好壞處則剛好相法，寫入回應速度快，系統容錯好但用戶可能會讀取到過期的資料。&lt;/p>
&lt;p>通常來說Leader-base系統都是以Async為主，因為讀取過期資料這點後續有其他方式可以彌補。&lt;/p>
&lt;h3 id="handle-nodeoutages">Handle Node Outages&lt;/h3>
&lt;p>當節點出錯要重新恢復時，會有不同的狀況，又可拆成 Leader / Follower來處理&lt;/p>
&lt;p>Follower出錯要恢復或是加入新節點比較容易，只要資料記錄有追上Leader最新資料即可&lt;/p>
&lt;p>但是Leader出錯就非常麻煩，必須要先 判定Leader死亡(通常透過Timeout) -&amp;gt; 選出新的Leader -&amp;gt; 整個系統承認新的Leader，並將寫入請求轉導到新的Leader上，這裡會有幾個容易出錯的地方&lt;/p>
&lt;p>例如說 舊的Leader如果是採用Async，有可能會有部分寫入尚未同步到備份中所以會遺失，在Github採用MySQL案例中就發生過掉資料結果 Primary Key重複的現象；&lt;br>
又或是程式沒設計好，意外選出多個Leader，產生人格分裂(Split brain)；&lt;br>
Timeout設定也很重要，太短會導致網路波動就造成不必要的Leader切換，太長則遺失的資料可能會很多，這部分很麻煩；&lt;/p>
&lt;p>基於這些理由，作者提到現在有蠻多公司都採用人工處理的方式。&lt;/p>
&lt;h3 id="implementation-of-replication-logs">Implementation of Replication Logs&lt;/h3>
&lt;ol>
&lt;li>Statement-based replication&lt;br>
最簡單的方式是直接將每筆寫入都pass到 replica上，但這會有幾個壞處，如 NOW() / RAND()等函式會因為執行的時候值而有所不同、Auto-Increment也會有所差異，此外還必須保證複製的過程寫入資料順序必須相同。&lt;/li>
&lt;li>Write-ahead log (WAL) shipping&lt;br>
將WAL的資料直接複製到replica就不會有上述的問題，但缺點是log相當底層，也就是會跟系統的儲存引擎嵌套很深，跨系統不易。&lt;/li>
&lt;li>Logical (row-based) log replication&lt;/li>
&lt;/ol>
&lt;h3 id="problems-with-replication-lag">Problems with Replication Lag&lt;/h3>
&lt;ol>
&lt;li>Reading Your Own Writes&lt;br>
當用戶更新資料到Leader上，如果該用戶馬上需要讀取該筆資料，可能Follower還沒有收到複製回傳了過期的資料；&lt;br>
解決方法有 &lt;br>
透過應用程式追蹤時間，當在更新後的一定時間內從Leader讀取資料、&lt;br>
用戶紀錄更新資料的時間，由資料庫確保從replica取出正確的資料&lt;/li>
&lt;li>Monotonic Reads&lt;br>
當用戶從多個replica讀取資料，可能某些replica同步比較慢導致用戶讀取多次資料卻不同；&lt;br>
可以綁定用戶在同一個replica讀取資料，避免不一致的資料狀況出現。&lt;/li>
&lt;li>Consistent Prefix Reads&lt;br>
同樣是因為replica同步有時間差，用戶可能會讀到順序錯亂的資料，例如問題勢必在答案之前出現(有問題才能有回答)&lt;/li>
&lt;/ol>
&lt;h3 id="multi-leader-replication">Multi-Leader Replication&lt;/h3>
&lt;p>多Leader的架構系統容錯性更好、寫入的性能也可以提昇，但缺點是資料衝突的情況會很多，當發生衝突時很多時候必須由應用程式來解決。&lt;/p>
&lt;h3 id="leaderless-replication">Leaderless Replication&lt;/h3>
&lt;p>寫入和讀取都一次使用多個節點，透過量來保證資料的正確性與系統容錯性，例如總共有5個node(n)，只要我們可以寫入3個以上節點(w)與讀取時讀到3個節點以上(r)，在符合 w + r &amp;gt; n的情況下，就可以保證會讀取到最新的資料，此時系統可以容忍 n-w 個節點失效。&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/1__ud8JMaGfu__JywzSmo0kLWw.png"
loading="lazy"
alt="https://tech.liuchao.me/2017/12/ddia-5/"
>
&lt;a class="link" href="https://tech.liuchao.me/2017/12/ddia-5/" target="_blank" rel="noopener"
>https://tech.liuchao.me/2017/12/ddia-5/&lt;/a>&lt;/p>
&lt;h2 id="ch6-partition">Ch6. Partition&lt;/h2>
&lt;p>Partition分片主要是提升系統的Scalability，當大量的資料可以被平均分散到節點上，寫入和讀取「理論上」就可以隨著節點數成線性成長；&lt;/p>
&lt;p>在實作上，Partition常與Replication做搭配，將資料分片並複製到其他節點上增加容錯空間&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/1__e5hRNbqh8dOc4lXntcu1ug.png"
loading="lazy"
alt="https://tech.liuchao.me/2017/12/ddia-6/"
>
&lt;a class="link" href="https://tech.liuchao.me/2017/12/ddia-6/" target="_blank" rel="noopener"
>https://tech.liuchao.me/2017/12/ddia-6/&lt;/a>&lt;/p>
&lt;p>有個良好的資料分片機制很重要，如果分片的方式不夠號，如遇上 hot-key產生歪斜skewed，導致資料不平均分散到節點上，會導致系統的性能無法得到顯著的提升，以下有兩種常見的分片機制&lt;/p>
&lt;h3 id="partitioning-by-keyrange">Partitioning by Key Range&lt;/h3>
&lt;p>一種常見的做法是將 Key排序並將某連續段的Key分片，這種做法好處是簡單實作、如果要範圍搜尋資料很方便；&lt;br>
缺點是容易會有 hot-key的問題。&lt;/p>
&lt;p>所以在套用上需要特別注意應用程式本身的資料Key特性，例如說感測器收集系統，採用 timestamp 當作key可以使後續日期範圍查詢非常容易，但缺點是當天的寫入都會集中在同一個partition上；&lt;br>
可以考慮改成用 感測器編號，這樣寫入就可以平均分散，但相對就變成範圍讀取比較麻煩。&lt;/p>
&lt;h3 id="partitioning-by-hash-ofkey">Partitioning by Hash of Key&lt;/h3>
&lt;p>可以透過 hash function將key轉成可平均分散的雜湊值，好處是寫入可以更平均分散，但缺點就是失去了範圍搜尋；&lt;/p>
&lt;p>Cassandra嘗試透過組合Key來融合上面兩種方式，Key的前半段用Hash決定partition位置，partition中則依照Key的後半段排序增強範圍搜尋；&lt;br>
例如說(user_id, update_timestamp)，透過user_id分散用戶的資料，但如果有需要取得某用戶的範圍資料更新就可以用update_timestamp。&lt;/p>
&lt;h3 id="partitioning-and-secondary-indexes">Partitioning and Secondary Indexes&lt;/h3>
&lt;p>先前提的是透過 Primary Key，但如果要查詢 Secondary Key就會遇到不同的問題，例如說 汽車資料是 {carId , name , color}等，主鍵是carId並依此來分片，但如果用戶要查詢 color = ‘red’的車子就需要另外處理&lt;/p>
&lt;h3 id="partitioning-secondary-indexes-bydocument">Partitioning Secondary Indexes by Document&lt;/h3>
&lt;p>在個別partition中自行維護各自資料的 Secondary index table，所以用戶的讀取請求需要送到每個partition中並整合，也就是 scatter /gather。&lt;br>
缺點就是讀取效率很差，因為可能某些partition回復比較慢整個請求就會被卡住。&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/1__3OY9Re3mGd__GuWpjogmvOA.png"
loading="lazy"
alt="https://tech.liuchao.me/2017/12/ddia-6/"
>
&lt;a class="link" href="https://tech.liuchao.me/2017/12/ddia-6/" target="_blank" rel="noopener"
>https://tech.liuchao.me/2017/12/ddia-6/&lt;/a>&lt;/p>
&lt;h3 id="partitioning-secondary-indexes-byterm">Partitioning Secondary Indexes by Term&lt;/h3>
&lt;p>與其個別partition分別維護Secondary index(local)，可以將相同的Secondary index紀錄統一儲存在某特定partition中，透過讀取該紀錄，再去所有紀錄所在的partition讀取資料即可。&lt;/p>
&lt;p>至於該筆 Secondary index要記錄在哪可以透過前述的兩種方式分散到不同node上。&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/1__yaaNNaAUaHSUFmodO0Dhtw.png"
loading="lazy"
alt="https://tech.liuchao.me/2017/12/ddia-6/"
>
&lt;a class="link" href="https://tech.liuchao.me/2017/12/ddia-6/" target="_blank" rel="noopener"
>https://tech.liuchao.me/2017/12/ddia-6/&lt;/a>&lt;/p>
&lt;p>這種方式提升讀取的效能，但缺點是寫入變得十分複雜，修改單一筆資料需要同步更新不同partition中的 Secondary Index，這在分散式中會有很多隱藏的問題。&lt;/p>
&lt;h3 id="rebalancing-partitions">Rebalancing Partitions&lt;/h3>
&lt;p>如果系統附載增加，可能會需要增加 partition的機器或是移除出錯的機器等，這時候會需要重新調整partition，將資料重新平衡到所有機器上。&lt;/p>
&lt;p>平衡的方式有&lt;/p>
&lt;ol>
&lt;li>hash mod N：&lt;br>
直接把 hash key mod {所有機器數}即可，但缺點是增加一台機器就會有大量資料需要搬移，造成不必要的負擔&lt;/li>
&lt;li>Fixed number of partitions：&lt;br>
將所有資料切成很多份，並平均分散到機器上，例如說 10台機器可以將資料分成 1000份，平均每台負擔 100份資料；&lt;br>
此時如果有新機器加入，這10台機器每台抽9~10份搬移即可，如果要移除舊機器反之；&lt;br>
這種方式有效降低不必要的資料搬移。&lt;/li>
&lt;/ol>
&lt;h3 id="dynamic-partitioning">Dynamic partitioning&lt;/h3>
&lt;p>使用 Key-range partition不太方便，如果一開始設定錯誤，會導致資料太過集中於部分節點，如果要重新設定又會很麻煩；&lt;br>
所以某些資料庫(HBase、RethinkDB)內部提供動態分割的方法，當發現 partition資料超過某個size，會自動分割並把資料分成兩個partition；&lt;br>
如果資料大量刪除，也會自動合併成單一個partition；&lt;br>
每個partition分散到一個節點上，而一個節點可能儲存多個partition。&lt;/p>
&lt;p>Dynamic partition可支援 key-range partition和 hash-key partition。&lt;/p>
&lt;h3 id="request-routing">Request Routing&lt;/h3>
&lt;p>當用戶要發送請求，如何得知該往哪個節點發送呢? &lt;br>
這個問題通稱為_service discovery_ ，任何透過網路的軟體都會遇上此問題，尤其是分散式系統。&lt;/p>
&lt;p>主要解法有三種方式，&lt;br>
client隨機發送請求到某節點，每個節點都有分片依據的紀錄；&lt;br>
統一一個負責routing的節點；&lt;br>
client端自行判斷紀錄分片的依據。&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/1__1HtoefsjWPhIJav0Zj__21g.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="ch8-the-trouble-with-distributed-systems">Ch8. The Trouble with Distributed Systems&lt;/h2>
&lt;h3 id="faults-and-partialfailures">Faults and Partial Failures&lt;/h3>
&lt;p>分散式系統傳遞資訊都是靠網路，但網路的本身是不可靠的，所以分散式系統最大的疑慮便是會有&lt;strong>部分錯誤&lt;/strong>的產生，在某些時刻我們無法得知操作是否完全成功，所以在設計上必須考量這一點，設計出可容忍錯誤(Fault-Tolerance)的系統。&lt;/p>
&lt;h3 id="unreliable-networks">Unreliable Networks&lt;/h3>
&lt;p>談論一些網路的不可靠性，對比Telephone circuit 用硬體與固定頻寬的連線方式傳輸資料，TCP為了增進總體使用量會有flow control導致傳輸速度無法估測。&lt;/p>
&lt;h3 id="unreliable-clocks">Unreliable Clocks&lt;/h3>
&lt;p>時間在電腦系統扮演重要角色，大致有兩個時間屬性 &lt;strong>區間&lt;/strong>(Duration，如計算request時間)、&lt;strong>確切時間&lt;/strong>(points in time，錯誤的時間log)，再分散式系統中時間很tricky，因為溝通不是即時的，透過網路傳遞訊息會產生不可預測的延遲；&lt;br>
再者每台電腦都有各自的石英震盪器計算時間，因為各種物理性質上的差異導致無法完全精準同步每台電腦的時間。&lt;/p>
&lt;h3 id="monotonic-versus-time-of-day-clocks">Monotonic Versus Time-of-Day Clocks&lt;/h3>
&lt;ol>
&lt;li>Time-of-day clocks(又稱 wall time)：&lt;br>
返回日曆時間，通常是透過NTP同步時間，但如果電腦時間太快或太慢，同步之後可能會產生時間跳躍，產生一些後遺症(如資料庫寫紀錄的跳針導致資料不一致)&lt;/li>
&lt;li>Monotonic clocks：&lt;br>
適合用來測量時間區間，「實際上他指的是系統啟動後流逝的時間，這是由變數jiffies來紀錄的。系統每次啟動時jiffies初始化為0，每來一個timer interrupt，jiffies加1，也就是說他代表系統啟動之後流逝tick數**」&lt;br>
**(出處：&lt;a class="link" href="https://blog.csdn.net/peterlin666/article/details/32344355" target="_blank" rel="noopener"
>[Timer学习]wall time和monotonic time&lt;/a>)但也因為如此，所以跨系統間比較Monotonic clocks是沒有意義的。&lt;/li>
&lt;/ol>
&lt;h3 id="timestamps-for-orderingevents">Timestamps for ordering events&lt;/h3>
&lt;p>假想系統有2個Node，當兩個客戶A、B同時對同一筆資料做改寫，但是A的Request先到Node 1而 B先到Node 2，再處理併發時分散式系統通常採用LWW(Last-Write-Win)，所以更新後Node 1與Node 2資料就會不同步&lt;/p>
&lt;h3 id="process-pauses">Process Pauses&lt;/h3>
&lt;p>試想一個危險的情況，資料庫採用Single-Leader架構，Leader需要固定一段時間通知所有Follower Leader還活著，但如果Leader的執行卡住了過一段時間沒有通知，其餘Follower選出新的Leader後同時舊Leader復活，產生了雙Leader的分歧局面&lt;/p>
&lt;p>在以下情況會產生程式執行被無預期卡住，如垃圾回收(GC)，這會導致程式運作直接卡死直到垃圾回收結束；&lt;br>
在虛擬機中VM也有可能被暫時終止執行、又或是在CPU切換任務時系統負載過多而延遲等等因素&lt;/p>
&lt;h3 id="response-time-guarantees">Response time guarantees&lt;/h3>
&lt;p>上述問題產生於 應用程式不知道執行時會遇到怎樣的突發終止狀況，所以如果可以保證突發終止的時間是可預測的，就可以透過設計避免問題，但問題就是如何保證回應時間?&lt;/p>
&lt;p>RTOS(real-time Operating System)保證CPU的時間切割是固定的，所以可以得知最糟狀況應用程式會被終止多久；&lt;br>
但RTOS開發很貴，通常用於高度安全的系統設計如飛行系統，而且RTOS會限制應用程式可用的Library、寫法等，不適用於一般資料庫系統。&lt;/p>
&lt;h3 id="the-truth-is-defined-by-themajority">The Truth Is Defined by the Majority&lt;/h3>
&lt;p>分散式系統中，每個節點只能透過網路收發資料來確認彼此的狀態，但有時候節點運作正常但在與其他節點的網路溝通上出了問題，或是遇上GC整個節點卡住等，就有一樣會被其他節點誤認為「死亡」&lt;/p>
&lt;p>正因為分散式系統解決了單一節點失效的問題，失效的決定則依賴多數的節點的決定。&lt;/p>
&lt;h3 id="byzantine-faults">Byzantine Faults&lt;/h3>
&lt;p>先前描述都是以節點失效為主，但如果節點會「說謊」呢? Byzantine Generals Problem 拜占庭將軍問題即是描述多節點在不知道彼此的情況下如何確保叛徒不會影響正確性&lt;/p>
&lt;p>&lt;a class="link" href="https://zh.wikipedia.org/wiki/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98" title="https://zh.wikipedia.org/wiki/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98"
target="_blank" rel="noopener"
>拜占庭将军问题 - 维基百科，自由的百科全书&lt;/a>&lt;/p>
&lt;p>結論大致是只要出錯的結點不超過 1/3即可保證整體的正確性。&lt;/p></description></item><item><title>[技術筆記] Designing Data-Intensive Applications 上</title><link>https://yuanchieh.page/posts/2018/2018-03-28-%E6%8A%80%E8%A1%93%E7%AD%86%E8%A8%98-designing-data-intensive-applications-%E4%B8%8A/</link><pubDate>Wed, 28 Mar 2018 10:23:52 +0000</pubDate><guid>https://yuanchieh.page/posts/2018/2018-03-28-%E6%8A%80%E8%A1%93%E7%AD%86%E8%A8%98-designing-data-intensive-applications-%E4%B8%8A/</guid><description>&lt;p>隨著軟體應用程式的發展，應用的侷限(bottleneck)從CPU移轉至資料的處理，資料的巨量、複雜性與改變的速度變成棘手的問題，也就是作者所定義的「Data-Intensive」資料密集的應用程式；&lt;br>
作者前言提及 在現今Buzzword滿天飛 Big Data / NoSQL / Web Scale blablabla，身為技術人員應該更透徹的了解資料儲存的基本觀念，這些才是永恆不變的基石；&lt;br>
有了清楚的概念，才能在不同的應用場景套用最適合的解法，老話一句&lt;/p>
&lt;blockquote>
&lt;p>沒有銀彈&lt;/p>
&lt;/blockquote>
&lt;p>此書切成三大部分：資料系統的基本組成(Foundation of Data Systems)、分散式資料儲存(Distributed Data)、取得資料(Derived Data)；&lt;br>
作者章節設計循序漸進，先定義基本用語與資料系統的設計理念與實作方式，接著加深內容且不斷的引用前面所述說的觀念；&lt;br>
以下是我簡單筆記本書2/3的內容，Derived Data目前有點看不懂所以就先暫時跳過 OTZ&lt;/p>
&lt;h2 id="ch-1-reliable--scalable--maintainable">Ch 1. Reliable / Scalable / Maintainable&lt;/h2>
&lt;p>再討論系統設計時，就必須先反問「想要設計出符合怎樣需求的系統」&lt;br>
作者提出三大軟體設計的核心&lt;/p>
&lt;h3 id="reliable">Reliable&lt;/h3>
&lt;ol>
&lt;li>運作需與使用者預期的相同&lt;/li>
&lt;li>可以容忍用戶以非預期方式操作系統&lt;/li>
&lt;li>效能需好到可以應付用戶需求&lt;/li>
&lt;li>防止非授權登入與濫用&lt;/li>
&lt;/ol>
&lt;p>基本上就是要能夠在一定的錯誤容忍下運作正常，常見的錯誤有&lt;/p>
&lt;ol>
&lt;li>硬體錯誤：&lt;br>
作者提及像硬碟的 MTTF(平均時間出錯)是10~50年，如果你的資料中心有10,000顆硬碟基本上預期是每天都會壞一顆! &lt;br>
=&amp;gt; 常見解法是：增加硬體冗余、使用RAID、額外供電設備、異地備份等&lt;/li>
&lt;li>軟體錯誤&lt;/li>
&lt;li>人為錯誤&lt;/li>
&lt;/ol>
&lt;h3 id="scalable">Scalable&lt;/h3>
&lt;p>隨著用戶增加，系統需要負擔的資料也成幾何增長，所以需要系統的擴充性去回答「我們如何增加運算資源來應付增長的流量?」&lt;br>
再回答此問題之前，必須先知道如何描述「&lt;strong>此刻系統的負載量&lt;/strong>」，根據不同的系統設計有不同的衡量方式，例如常見的 request per seconds / 資料庫讀寫比 / 最大同時上線人數等等，也就是要找出不同的「&lt;strong>關鍵附載係數(Key Load Parameters)」&lt;/strong>；&lt;/p>
&lt;p>衡量性能部分可以透過 percentile追蹤，分析回應速度的百分比圖，Amazon有做一個有趣的分析指出 最慢的Request意外發現是最有價值的客戶，因為往往他們的Request夾帶最多的資訊，所以也導致速度最慢；&lt;/p>
&lt;p>作者舉 Twitter在2012年做用戶發送訊息為例：&lt;br>
Twitter 有兩個主要操作&lt;br>
1. 發 tweet：&lt;br>
用戶發送新訊息(4.6K req/sec，高峰超過 12K req / sec)&lt;br>
2. Home timeline：&lt;br>
用戶查看他們追蹤的對象消息列 (300k req/sec)&lt;/p>
&lt;p>在設計上有兩種方式：&lt;br>
1. 發tweet時就是單純插入新的一筆紀錄，如果有用戶要讀home timeline就做 DB Join取出所有追蹤對象的訊息&lt;br>
2. 針對每位用戶都Cache home timeline，如果有用戶新增tweet就加到對應追蹤用戶的cache中&lt;/p>
&lt;p>Twitter後來從方法一轉至方法二，原因是因為方法二的讀取timeline速度快了兩個級別，所以傾向於 &lt;strong>花多點時間在寫入以節省龐大的讀取時間。&lt;/strong>&lt;/p>
&lt;p>對於Twitter來說，用戶的追蹤數就是關鍵附載係數 **，**但每位用戶的追蹤數與被追蹤數差異十分的大，尤其是名人，所以Twitter後來採用兩種方法混用，一般用戶採用方法二，而名人則另外處理。&lt;/p>
&lt;h3 id="maintainable">Maintainable&lt;/h3>
&lt;p>軟體最大的花費不在於建置，而在於維護，此處又拆成三個子項目&lt;/p>
&lt;ol>
&lt;li>Operability&lt;br>
透過一些方式可以讓軟體更好維運，例如 監控系統健康、錯誤追蹤系統、定期更新系統、隔離不同系統等&lt;/li>
&lt;li>Simpilicity&lt;br>
隨著系統營運不可避免功能一直加，系統也相對跟著複雜，這裡的簡易性不是說要去削減功能，而是**避免不必要的複雜性，**這裏複雜性的定義是「企圖加入實作層面的解法而跟解決問題無關」，要避免複雜性就必須透過 **抽象化(Abstraction)，**例如說高階語言理當不需要理會CPU的暫存器等操作，因為語言本身已經透過抽象化隱藏了不必要的實作複雜性。&lt;/li>
&lt;li>Evolvability&lt;br>
需求會加、功能會改，所以系統必須保留彈性面對改變。&lt;/li>
&lt;/ol>
&lt;h2 id="ch-2-data-models-and-query-languages">Ch 2. Data Models and Query Languages&lt;/h2>
&lt;p>這一章探討資料儲存的形式，也就是 Relation / Document / Graph Data Model，資料儲存的形式很重要，這會決定性影響了應用程式的編寫以及底層儲存方式的不同；&lt;/p>
&lt;p>Relation Data Model最為常見，將資料的關聯以tuple的集合儲存(也就是SQL的row)，但是現今的程式語言都是物件導向，所以要在應用程式中操作資料就必須透過ORM將資料轉換為物件形式；&lt;br>
這也是為什麼會有 Document Data Model，因為資料(在沒有複雜關聯下)的本身就是個文本物件，這裡的Document偏向於描述可以用 JSON / XML 結構化語言描述的資料格式，例如 履歷 {name: “hello”, age: 25, ….}。&lt;/p>
&lt;p>但現實上資料本身有不同的關聯性，有One to Many 也有 Many to Many，基本上採用何種Data Model可以從資料集多對多的關聯性複雜度來決定；&lt;br>
如果資料僅有少部分多對多關聯，可以選擇採用Document Data Model，因為相對應用程式的代碼比較好寫，不需多一層ORM轉換、少有的多對多可以用應用程式代碼自己實踐Join功能；&lt;br>
如果注重物件的多對多關聯性則可用 Relation Data Model；&lt;br>
如果物件的關聯性相當複雜可以考慮 Graph Data Model，這也是我第一次接觸到此觀念，資料模型改以圖形化方式呈現，資料可分成vertice與edge，vertice比較像是儲存單體的資料，而edge則儲存vertice間的關係，透過圖形化的特性可以表達相當複雜、遞迴的關係，這部分可以參考我之前嘗試 &lt;a class="link" href="http://sj82516-blog.logdown.com/post/5823130" target="_blank" rel="noopener"
>neo4j的筆記&lt;/a>。&lt;/p>
&lt;p>當然上述只是單純以資料關聯與對應的模型來衡量，現實的技術採納需要有更全面通盤的考量。&lt;/p>
&lt;p>這一章比較是在講古，把過去曾出現過的資料模型與對應的Query語言都稍微帶到。&lt;/p>
&lt;p>最後筆記一點蠻有趣的觀點，作者提到 Document Database都會被誤稱為 schemaless，但其實更準確說法是 schema-on-read，雖然DB沒有顯性的資料欄位，但是在應用程式讀取時一樣會有資料的架構，對應的是Relation Database的schema-on-write；&lt;br>
schema-on-read有點像是動態語言，資料的檢查在應用程式本身；而schema-on-write像靜態語言的型別檢查，在寫入時就先檢查了。&lt;/p>
&lt;h2 id="ch-3-storage-and-retrieval">Ch 3. Storage and Retrieval&lt;/h2>
&lt;p>這章節算是我覺得最有趣的一章，主要談到資料庫底層如何將資料存入硬碟中，以及如何快速的透過索引 Index 從硬碟取出資料；&lt;/p>
&lt;p>首先作者用shell script編寫最簡單的資料庫&lt;/p>
&lt;blockquote>
&lt;p>db_set () { echo “$1, $2” &amp;raquo; database}&lt;br>
db_get () { grep “^$1,” database | sed -e “s/^$1,//” | tail -n 1}&lt;br>
$ db_set 123 ‘{name: “123”}’&lt;br>
$ db_get 123&lt;/p>
&lt;/blockquote>
&lt;p>採用類似 CSV格式的 鍵-值儲存，將新的資料不斷append到文件上，最後搜尋時從文件最末的資料開始找起；&lt;br>
這樣寫的效能很好，因為單純append資料速度非常快，但是讀取則需要O(n)的時間；&lt;/p>
&lt;p>為了增加讀取的效能，我們可以建立索引，在記憶體中用Hash Table資料結構，儲存鍵對應欄位在硬碟的儲存位置，加速讀取的效能。&lt;/p>
&lt;p>雖然這看起來很簡單，但實際上卻也有資料庫是採用此設計方式，如 Bitcask。&lt;/p>
&lt;p>先前提到這種做法是不斷將新資料append到硬碟文件上，即使同樣的鍵也是，但是這樣文件總不能無止盡的增加下去，所以會有所謂的 compact process 壓實程序，也就是重整舊的文件，將冗余重複的鍵去除只保留最新的紀錄，減少不必要的過時資料儲存空間。&lt;/p>
&lt;p>但上述方式有兩個缺點 &lt;/p>
&lt;ol>
&lt;li>索引必須小於記憶體總量否則性能會很差&lt;/li>
&lt;li>不支援範圍讀取&lt;/li>
&lt;/ol>
&lt;h3 id="sorted-stringtable">Sorted String Table&lt;/h3>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/1__1AvQY5KBV2mRADK07aq4BA.png"
loading="lazy"
alt="圖片來源：https://tech.liuchao.me/2017/11/ddia-3/"
>
圖片來源：&lt;a class="link" href="https://tech.liuchao.me/2017/11/ddia-3/" target="_blank" rel="noopener"
>https://tech.liuchao.me/2017/11/ddia-3/&lt;/a>&lt;/p>
&lt;p>所以後來有提出新的作法 Sorted String Table (簡稱 SSTable)，差別在於索引改透過 依照字串順序排序後的資料結構儲存，這有點像是字典索引，當我們要查一個單字 hello 我們可以透過前後的字去找到相近的位置；&lt;/p>
&lt;p>所以如果在記憶體中所以只有 he / hola，那我們至少知道 hello 勢必在此兩個位置中間，透過 順序讀 sequential read 可以非常快的在硬碟中找到資料。&lt;/p>
&lt;blockquote>
&lt;p>作者強調 順序讀寫對於硬碟的效能有很大的幫助，即使是SSD&lt;/p>
&lt;/blockquote>
&lt;h3 id="b-tree">B Tree&lt;/h3>
&lt;p>但是SSTable並不是最常用的資料系統儲存的方式，而是B Tree，B Tree是個平衡二叉樹，母節點紀錄多個區間值與對應的子節點，每個子節點則紀錄一段連續值。&lt;/p>
&lt;p>&lt;img src="https://yuanchieh.page/post/img/1__sGWCREWf3auzlU2H1j6LEw.png"
loading="lazy"
alt="圖片連結：https://tech.liuchao.me/2017/11/ddia-3/"
>
圖片連結：&lt;a class="link" href="https://tech.liuchao.me/2017/11/ddia-3/" target="_blank" rel="noopener"
>https://tech.liuchao.me/2017/11/ddia-3/&lt;/a>&lt;/p>
&lt;p>在儲存方式上不是採用append only，而是將儲存空間切割固定大小的 Page，並把節點的資料放入，如果有新的資料產生會覆寫舊的Page，這點與SSTable大大不同。&lt;/p>
&lt;p>在實作上，B Tree因為會先將Page資料暫存在記憶體中，為了避免資料遺失會在資料寫入時先將資料紀錄到append-only 的WAL(Write-Ahead Log)，所以一筆資料寫入其實會有兩次寫入硬碟動作。&lt;/p>
&lt;p>B Tree 對比 SSTable 好處在於&lt;/p>
&lt;ol>
&lt;li>資料冗餘少&lt;/li>
&lt;li>找尋不存在的鍵值比較快(SSTable必須查完所有舊資料才可以確定)&lt;/li>
&lt;li>不需要 compact process去重整資料，作者提到雖然 compact process通常在背景執行，但你永遠無法預期何時系統會爆量，也就是說好死不死大量讀寫時卡到系統在 compact process就欲哭無淚，相對來說 B Tree的系統附載比較可預期；&lt;br>
SSTable好處在於 B Tree切割Page容易有空間的破碎化與浪費，且部分資料更新也必須更動對應的Page；&lt;/li>
&lt;/ol>
&lt;h3 id="column-base">Column-Base&lt;/h3>
&lt;p>一般資料庫在OLTP中都是以row-based為導向的；&lt;br>
但是在OLAP中，我們常會將多個DB資料彙整到統一的資料倉儲中，所以資料量非常龐大，且每筆request也都要運算非常大量的資料，這時候有個新的做法以column-base儲存資料，這樣最大好處在於同一個column通常資料重複性高，例如顏色就那幾種、產品ID可能也會重複，這種特性可以使 &lt;strong>資料壓縮&lt;/strong> 得到非常好的效果；&lt;br>
但缺點就是寫入很麻煩。&lt;/p>
&lt;p>在底層紀錄上，B Tree無法套用在壓縮欄位上，因為索引是紀錄row-based的鍵，所以多個column欄位更動會導致過多的Page都要一并刷新；&lt;br>
所以會採用 SSTable當作寫入硬碟的資料儲存方式，每次寫入都產生新檔案。&lt;/p>
&lt;h2 id="ch-4-encoding-and-evolution">Ch 4. Encoding and Evolution&lt;/h2>
&lt;p>在系統的演進上，需要注意相容性問題，可分成&lt;br>
・向後相容：新的code可能讀取到舊資料&lt;br>
・向前相容：舊的code可能讀取到新資料&lt;/p>
&lt;p>程式在處理資料上會有兩種形式&lt;br>
一種是 in memory，像是 object / array / int等，主要是方便CPU做運算；&lt;br>
另一種在需要寫入檔案或是透過網路傳輸時，需要重整成字串的形式，也就是encode&lt;/p>
&lt;p>常見的 encode形式有非常多種，包含JSON / XML /CSV，為了讓資料可以用最小容量傳遞，作者介紹了數種基於JSON的encode / decode技術，在encode的過程中要注意資料格式與型別需要可以decode。&lt;/p>
&lt;p>原本JSON原始資料 66 bytes，透過不同的binary encode技術最終可以壓縮到 34 bytes!&lt;/p>
&lt;h3 id="下集">下集&lt;/h3>
&lt;p>&lt;a class="link" href="https://yuanchieh.page/posts/2018/2018-04-19-%E6%8A%80%E8%A1%93%E7%AD%86%E8%A8%98-designing-data-intensive-applications-%E4%B8%8B/" target="_blank" rel="noopener"
>技術筆記 Designing Data-Intensive Applications 下&lt;/a>，第二部分主要探討分散式儲存資料會遇到的問題與解法，分散式系統有幾大優點&lt;/p></description></item></channel></rss>