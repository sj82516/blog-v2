<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="AWS Aurora 是 AWS 託管的兼容於 MySQL/PostgreSQL 的雲端關聯式資料庫，我一直誤以為他就是個託管服務與管理跨區域 Replica，但為了因應雲端與效能改善，底層儲存架構與自駕的 MySQL 截然不同"><meta name=keywords content="Aurora,MySQL"><title>AWS Aurora 架構研究以及與自駕 MySQL 的差異</title><link rel=canonical href=https://yuanchieh.page/posts/2021/2021-07-02-aws-aurora-%E6%9E%B6%E6%A7%8B%E7%A0%94%E7%A9%B6%E4%BB%A5%E5%8F%8A%E8%88%87%E8%87%AA%E9%A7%95-mysql-%E7%9A%84%E5%B7%AE%E7%95%B0/><link rel=stylesheet href=/scss/style.min.ff300df33b80e2ac49809c825614392ed1c7b27591d65d3c4043602cd162e25f.css><meta property="og:title" content="AWS Aurora 架構研究以及與自駕 MySQL 的差異"><meta property="og:description" content="AWS Aurora 是 AWS 託管的兼容於 MySQL/PostgreSQL 的雲端關聯式資料庫，我一直誤以為他就是個託管服務與管理跨區域 Replica，但為了因應雲端與效能改善，底層儲存架構與自駕的 MySQL 截然不同"><meta property="og:url" content="https://yuanchieh.page/posts/2021/2021-07-02-aws-aurora-%E6%9E%B6%E6%A7%8B%E7%A0%94%E7%A9%B6%E4%BB%A5%E5%8F%8A%E8%88%87%E8%87%AA%E9%A7%95-mysql-%E7%9A%84%E5%B7%AE%E7%95%B0/"><meta property="og:site_name" content="Yuanchieh"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:published_time" content="2021-07-02T01:21:40+00:00"><meta property="article:modified_time" content="2021-07-02T01:21:40+00:00"><meta name=twitter:title content="AWS Aurora 架構研究以及與自駕 MySQL 的差異"><meta name=twitter:description content="AWS Aurora 是 AWS 託管的兼容於 MySQL/PostgreSQL 的雲端關聯式資料庫，我一直誤以為他就是個託管服務與管理跨區域 Replica，但為了因應雲端與效能改善，底層儲存架構與自駕的 MySQL 截然不同"><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-82837682-4","auto"),ga("send","pageview"))</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-82837682-4"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-82837682-4")</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src="https://avatars0.githubusercontent.com/u/6858460?s=460&amp;v=4" width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Yuanchieh</a></h1><h2 class=site-description>生命是長期而持續的累積</h2></div></header><ol class=social-menu><li><a href=https://github.com/sj82516 target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archives</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#mysql-儲存的基本原理>MySQL 儲存的基本原理</a><ol><li><a href=#binlog>Binlog</a></li><li><a href=#undo-log>Undo log</a></li></ol></li><li><a href=#aurora-架構>Aurora 架構</a></li><li><a href=#2-durability-at-scale>2. DURABILITY AT SCALE</a><ol><li><a href=#21-replication-and-correlated-failures>2.1 Replication and Correlated Failures</a></li><li><a href=#22-segmented-storage>2.2 Segmented Storage</a></li></ol></li><li><a href=#the-log-is-the-database>THE LOG IS THE DATABASE</a><ol><li><a href=#31-the-burden-of-amplified-writes>3.1 The Burden of Amplified Writes</a></li><li><a href=#32-offloading-redo-processing-to-storage>3.2 Offloading Redo Processing to Storage</a></li><li><a href=#33-storage-service-design-points>3.3 Storage Service Design Points</a></li></ol></li><li><a href=#4-the-log-marches-forward>4. THE LOG MARCHES FORWARD</a><ol><li><a href=#41-solution-sketch-asynchronous-processing>4.1 Solution sketch: Asynchronous Processing</a></li><li><a href=#42-normal-operation>4.2 Normal Operation</a><ol><li><a href=#read>Read</a></li></ol></li><li><a href=#replica>Replica</a></li><li><a href=#43-recovery>4.3 Recovery</a></li></ol></li><li><a href=#5-putting-it-all-together>5. PUTTING IT ALL TOGETHER</a></li><li><a href=#aurora-對比-mysql-有什麼隱憂>Aurora 對比 MySQL 有什麼隱憂</a></li><li><a href=#結語>結語</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/%E6%9E%B6%E6%A7%8B/>架構</a>
<a href=/categories/%E8%B3%87%E6%96%99%E5%BA%AB/>資料庫</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/posts/2021/2021-07-02-aws-aurora-%E6%9E%B6%E6%A7%8B%E7%A0%94%E7%A9%B6%E4%BB%A5%E5%8F%8A%E8%88%87%E8%87%AA%E9%A7%95-mysql-%E7%9A%84%E5%B7%AE%E7%95%B0/>AWS Aurora 架構研究以及與自駕 MySQL 的差異</a></h2><h3 class=article-subtitle>AWS Aurora 是 AWS 託管的兼容於 MySQL/PostgreSQL 的雲端關聯式資料庫，我一直誤以為他就是個託管服務與管理跨區域 Replica，但為了因應雲端與效能改善，底層儲存架構與自駕的 MySQL 截然不同</h3></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Jul 02, 2021</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>5 minute read</time></div></footer></div></header><section class=article-content><p>公司使用 MySQL，近日遇到一些讀取的瓶頸，有了使用 AWS Aurora 的討論，剛好上一週看到 <a class=link href=https://plaid.com/blog/exploring-performance-differences-between-amazon-aurora-and-vanilla-mysql target=_blank rel=noopener>Exploring performance differences between Amazon Aurora and vanilla MySQL</a> 才赫然發現 AWS Aurora 底層儲存架構會影響使用場景，跟預期的自駕 MySQL 搭配 Replica 有不同的效果</p><p>以下這篇將探討</p><ol><li>MySQL 儲存的基本原理</li><li>Aurora 的儲存架構</li></ol><p>資料源自於</p><ol><li><a class=link href=https://plaid.com/blog/exploring-performance-differences-between-amazon-aurora-and-vanilla-mysql target=_blank rel=noopener>Exploring performance differences between Amazon Aurora and vanilla MySQL</a></li><li><a class=link href=https://www.amazon.science/publications/amazon-aurora-design-considerations-for-high-throughput-cloud-native-relational-databases target=_blank rel=noopener>Amazon Aurora: Design Considerations for High Throughput Cloud-native Relational Databases</a></li></ol><h2 id=mysql-儲存的基本原理>MySQL 儲存的基本原理</h2><p>關聯式資料庫最基本要保障 ACID，其中 Durability 是最基本的核心功能，保證寫入成功的資料不會因為系統 crash 等問題而遺失，在 MySQL 寫入的流程大概是</p><ol><li>將更新寫入 Redo Log buffer (WAL)，等待 commit 確定就刷新到硬碟保存紀錄避免遺失資料</li><li>如果資料有被讀取到 memory 中，則更新 Page 內容並標記為 dirty</li><li>背景運行的程序在 checkpoint 時機觸發時將 dirty page 與 redo log 的內容更新於硬碟上的 data file</li></ol><p>其中有幾個目的</p><ol><li>減少 disk I/O 並保障連續性寫入：<br>如果每一筆資料進來就馬上更新硬碟上的儲存，這會拖垮 DB 效能，所以 MySQL 讀寫時是以 <code>page</code> 為單位，如果發現更新的 page 在記憶體中會標記為 dirty page，後續再 checkpoint 統一更新到硬碟中</li><li>Redo Log 避免系統 Crash 而資料遺失：<br>為了避免資料遺失，所以會先寫入 Redo Log，所以又稱作 Write Ahead Log 先寫入 log 再操作，Redo Log 是一個順序性持續寫入的 Log，所以寫入效能比隨機性更新還要好，當系統 crash 後，會來檢查 Redo Log 中是否存在沒有更新到資料庫硬碟的資料；<br>具體寫入硬碟時機看 <code>innodb_flush_log_at_trx_commit</code>，預設 1 為每一筆都及時寫入硬碟中</li><li>定期同步到硬碟中：<br>每個操作都有先寫入 Redo Log，但這是為了災難復原而用，資料庫的資料會以 Page 形式儲存於硬碟中，所以定期到 checkpoint 會把 dirty page 從記憶體更新到硬碟中</li></ol><h3 id=binlog>Binlog</h3><p>Binlog 適用於系統異地恢復/建立 Replica，Binlog 不像 Redo Log 會保存所有的操作，只會保存對於資料有異動的行為，例如 update / delete 等</p><p>寫入時機在 commit 完成時，會在 commit 結束前 / lock 釋放前寫入硬碟，避免資料異常，具體的寫入頻率要看 <code>sync_binlog</code>，預設為 1 代表每一筆 commit 就寫一次，可以設定為 n 代表 n 筆 commit 才寫入但就會有遺失資料的風險</p><h3 id=undo-log>Undo log</h3><p>如果 isolation level 開到 repeatable read，則 MySQL 採用 MVCC，讓每個 transaction 只會讀取到自己 transaction 開始前的最新資料，而不被並行的 transaction 所影響</p><p>之所以需要 undo log 是當 transaction rollback 時，需要知道自己要回滾的狀態，所以 undo log 必須保存到 transaction 執行完畢才可以刪除，長度會是 <code>執行最久的 transaction</code></p><h2 id=aurora-架構>Aurora 架構</h2><p>Aurora 是 AWS 基於雲端建構的關聯式資料庫服務，兼容於 MySQL / PostgreSQL，主要想解決幾個問題</p><ol><li>容錯能力：<br>硬碟可能會壞 / 主機可能會有問題 / 甚至 Data Center 都會出意外，尤其是在雲端分散式系統中，機器數增加帶來更高的出錯機會，Aurora 每一個 replica 都會對應 3 個 AZ 各 2 個 node 總共 6 個 node 儲存資料，大幅增加容錯能力</li><li>擴展性：<br>傳統的資料庫架設於單一主機上，讀取會受限於 Disk I/O 的貧頸，Aurora 將 Compute / Storage 分離，可以針對需求獨立升級，並增加跨區域、跨 AZ 的 Read Replica</li></ol><p>但有這麼多好處卻不用受到太多的性能影響，聽起來有點美好的不切實際，例如備份到多個儲存 node 就需要擔心資料一致性/效能的問題，除了原本的 Disk I/O 又多了一段 Network I/O，Aurora 在不同的地方作出了對應的調整</p><h2 id=2-durability-at-scale>2. DURABILITY AT SCALE</h2><h3 id=21-replication-and-correlated-failures>2.1 Replication and Correlated Failures</h3><p>Aurora 跟很多分散式儲存的服務很像，採用多數讀寫的機制，只要確保</p><ol><li>Vw + Vr > V</li><li>Vw > V / 2</li></ol><p>V 代表節點數量，如果 Vw 寫入節點數量超過 1/2 節點都成功才成功，且 Vr 讀取數量是讀取多數則</p><p>最基本的數量會取 3，則 Vw / Vr 只要有 2 個 node 存活則可以繼續運作，容錯率是 33%，但文件中說到 Aurora 選擇 6 個 node分散在 3 個 AZ，這樣可以預防一個 AZ 以及一個額外錯誤下讀取還不會中斷</p><h3 id=22-segmented-storage>2.2 Segmented Storage</h3><p>為了降低同時機器故障而導致破壞多數的可能，要盡可能降低 MTTF(平均錯誤時間)與 MTTR(平均復原時間)，Aurora 以 10GB 當作一個區段，產生 6 個備份並分散到 3 個 AZ 稱之為 PG(Protection Group)，一個 Storage Volume 就是由多個 PG 所組成，實體上就是由 EC2 加上一群分割的 SSD 組成，最大可支援到 64TB</p><p>Segment 是最小獨立單位 (也就是會壞掉是獨立一個 Segment 壞)，AWS 會負責持續監控與復原，目前復原一個 Segment 約 10秒鐘 (網路帶寬為 10Gbps 下)，所以出現破壞多數的場景：兩個 node 在 10秒鐘內同時壞掉且一個 AZ 掛掉又不包含同時壞掉的 node 機率就微乎其微</p><blockquote><p>小結：這邊談的是 AWS 在持久性上的優化，將最小的儲存單位定在 10GB，讓復原速度變快 / 產生 6 組備份增加容錯</p></blockquote><h2 id=the-log-is-the-database>THE LOG IS THE DATABASE</h2><h3 id=31-the-burden-of-amplified-writes>3.1 The Burden of Amplified Writes</h3><p><img src=/post/2021/img/0702/mysql-old.png loading=lazy>
先看第一版 Aurora 嘗試的架構 - 傳統的鏡像同步架構，一台 Primary Instance 負責寫入儲存於 EBS 並同時備份到另一份 EBS 中，有一台 Replica Instance 同步 Primary 的寫入並儲存於兩份 EBS 中，可以看到一個 MySQL 寫入最多會觸發五個 I/O binlog / redo log / frm(metadata) / double-write，要等到全部寫入結束才算是操作成功，這會拉長回應時間，更糟糕的是圖片中步驟 1,3,5 (為什麼有5?) 是同步且順序寫入</p><h3 id=32-offloading-redo-processing-to-storage>3.2 Offloading Redo Processing to Storage</h3><p><img src=/post/2021/img/0702/aurora.png loading=lazy>
相反的 Aurora 透過 Redo Log 同步，讓 Storage level 負責 Redo Log 寫入與更新 Data file，同時分送給 Replica 更新記憶體中 page 的資料；<br>不像過往 MySQL 需要在 Checkpoint / background / cache 空間不足時刷新資料到硬碟中，全部由 Storage Service 負責，大幅降低了 Network I/O</p><p><img src=/post/2021/img/0702/perf.png loading=lazy>
從 Benchmark 可以看到，每筆 Transaction 所需的 I/O 從 7.4 變成 0.9，完成的 Transaction 數也提升了 35 倍</p><p>這同時也降低了復原的時間，傳統 DB 需要從 Redo Log 上一次的 checkpoint 開始逐條執行，但 Aurora 的復原是從 Storage level 向其他備份拉 Segment，復原速度可以在一分鐘以內</p><h3 id=33-storage-service-design-points>3.3 Storage Service Design Points</h3><p>Storage Service 核心設計要降低寫入請求的延遲，所以把大部分的儲存工作都移至背景執行，尤其是更好地利用 CPU 去換取 Disk 寫入時間，例如舊的 Page 要垃圾回收可以在背景用 CPU 執行而不要延遲前景在處理寫入請求，所以 Aurora 的背景運作不會影響前景，不同於傳統 DB 如果背景在 Checkpoint 刷新硬碟則會造成前景寫入的延遲</p><p><img src=/post/2021/img/0702/storage.png loading=lazy>
Storage Service 收到請求會執行</p><ol><li>放入 Memory 中</li><li>寫入硬碟，寫入請求成功</li><li>排序，並確認寫入紀錄是否有遺漏</li><li>透過 gossip 跟其他節點要遺漏的紀錄</li><li>更新到 page 中</li><li>定期同步到 s3</li><li>定期清除舊的 page</li><li>定期檢查 page 的驗證碼</li></ol><p>除了步驟 1, 2 會影響前景寫入，其餘步驟都可以非同步且於背景執行</p><h2 id=4-the-log-marches-forward>4. THE LOG MARCHES FORWARD</h2><p>接著要確保 rumtime、replica 都保持一致性，究竟是如何不使用昂貴的 2pc 卻又能保持一致性</p><h3 id=41-solution-sketch-asynchronous-processing>4.1 Solution sketch: Asynchronous Processing</h3><p>前面提過 Aurora 是透過 redo log 同步，每一筆 log 都有 持續遞增的 LCN (Log Sequence Number)，因為寫入成功只要多數的 node 同意即可，所以有些 node 可能會缺少幾個 log，可以透過 LCN 去跟其他 node 索取遺失的 log</p><p>考量到多 transaction 的情況，每個 transaction 執行順序有所不同，在過程會陸續把 commit 送到 storage service 儲存 (到 complete) 階段，但如果發生了系統故障時，重新恢復後需要把沒有 commit 的 transaction 都 rollback，假設 DB 目前最高完成寫入的 LCN 稱為 VCL (Volume Complete LSN))，在復原中任何 LCN 高於 VCL 都會被遺棄，因為代表沒有被 complete</p><p>更進階這些高於 VCL 的 LCN 會被標記成 CPL (Consistency Point LSNs)，接著定義出 VDL 為那些在低於 VCL 中最高的 CPL，例如 CPL 有 900,1000, 1100 但是 VCL 為 1007，則 VDL 為 1000，這代表 storage service complete 到 1007 但是持久化儲存到 1000</p><blockquote><p>這一整段沒有到非常理解，待之後慢慢思考</p></blockquote><h3 id=42-normal-operation>4.2 Normal Operation</h3><p>Aurora 會同時處理大量的寫入請求，每一筆 redo log 都會產生一個大於 VDL(被持久化保存的 LCN)的 LCN，但為了不要讓 LCN 的遞增遠大於 Storage Service 所能保存的速度，LSN Allocation Limit (LAL) 預設為 10萬筆，意即 Aurora 最多並行 10 萬筆進行中的 transaction 避免寫入速度跟不上</p><p>每一個 PG 中的每一個 Segment 只會保存部分的 redo log，但會有一個 link 指向上一份 log 所在的 PG，這用來追蹤目前所完成最大的 LCN，並且在與其他 node gossip 時可以知道缺漏的 log</p><h4 id=read>Read</h4><p>如同大多數的 DB，Aurora 會在 buffer 中 cache page ，如果 cache miss 則從 disk 讀取，此時傳統 DB 會優先移除 dirty page 並寫回硬碟中；但 Aurora 並不需要刷新 dirty page (因為 storage service 已經獨立更新)，相反的是把 page LCN 大於等於 VDL 的 page 移除並讀取最新被持久化的page</p><p>前面提到 Aurora 透過多數讀取確保一致性，但大多數時機並不需要，Aurora 會在 Page 讀取時紀錄 Page LCN 當作 read point，接著只要讀取的 storage node VDL 確定在 read point 之後，就代表該 node 有該 page 完整最新的資料，而且因為每個 segment 都有紀錄 LCN 與 link，所以能很快知道資料要到哪一個 segment 讀取</p><p>同時每個 PG 會維護一份目前最低的 Protection Group Min Read Point LSN (PGMRPL)，這代表低於此數字的 LCN 的 page 都不會再被讀取，這樣垃圾回收就能移除過舊的 log</p><h3 id=replica>Replica</h3><p>一個 write node 可以搭配 16 個 read replica 並共用相同的 storage service，writer 會把 redo log 也同步給 reader，如果 log 有在 cache 中則更新，否則就直接丟棄</p><p>因為 reader 跟 storage service 的 redo log 更新是錯開，所以 reader 在更新 log 時要確保 LCN 是小於等於 VDL / 如果 log 是 mini-transaction 的一部分則更新，確保跟所有的 database 看到相同內容</p><p>預期 reader 的延遲會在 20ms 以內</p><h3 id=43-recovery>4.3 Recovery</h3><p>傳統 DB 在災難復原時，會去讀取 redo log 中還沒被 checkpoint 執行的 log，搭配 undo log 將失敗的 transaction rollback，但這執行過程蠻花時間，而 Aurora 沒有這方面困擾</p><p>首先會檢查每一個 PG，找出讀取多數中可以確保已經完成的寫入多數紀錄 VDL，高於 VDL 的 LCN 全部捨棄，接著一樣需要透過 undo log 去 rollback，整個過程約 10秒以內</p><h2 id=5-putting-it-all-together>5. PUTTING IT ALL TOGETHER</h2><p>接著看完整的架構圖
<img src=/post/2021/img/0702/architech.png loading=lazy>
社群版的 MySQL InnoDB 引擎在寫入操作時會修改 buffer 中的 page 與寫入 WAL redo log buffer，等到 commit 時再把 redo log buffer 寫入硬碟中；而被修改的 page 要則透過 double-write buffer 避免只更新部分 page，page 寫入會發生在背景 / checkpoint / cache 移除時；
此外還有一些 B+Tree 操作與相關的 mini trasaction (MTR) 如拆分、合併 B+Tree page 需要是原子性操作</p><p>在 Aurora 版本中，redo log record 就代表每一個 MTR 操作，最新的一筆 log 被標記成 consistency point；Aurora 提供相同的 isolation level</p><p>其餘就是架構的說明，以及各方面的性能表現，就不贅述了</p><hr><h2 id=aurora-對比-mysql-有什麼隱憂>Aurora 對比 MySQL 有什麼隱憂</h2><p>因為 Aurora 如果 primary 跟 read replica 在同一個 region 下，則會共用 storage service，這也就代表 undo log 會是同一份，如果今天 read replica 有一筆執行非常久的 transaction，則 undo log 也會跟變大導致 primary 效能下降</p><p>這個在傳統 MySQL 不會發生，因為如 3.1 提到 MySQL 是透過 binlog 同步各自的 MySQL 維護各自的 redo log / undo log 所以 read replica 不會有任何影響 primary 的時候</p><p>最後作者指出有幾個解法</p><ol><li>調整 read replica 預設 isolation level 為 read commited，就不會用到 undo log(需注意預設為 repeatable read)</li><li>Aurora 選擇 binlog relica，就跟傳統的 mysql 一樣</li><li>拿在 S3 的備份資料，用其他大數據工具分析</li><li>Aurora 支援 clone，備份一組新的設定</li></ol><h2 id=結語>結語</h2><p>翻整個 Aurora 架構有很多生硬的地方沒有完全搞懂，但是看到這種解 bug 追根究底到底層架構還是覺得很過癮，之後會持續的優化文章內容，如果有哪裡有建議跟指教再麻煩留言～</p></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/posts/2023/2023-05-05-mongodb-clustered-collection-%E8%88%87-benchmark-%E5%AF%A6%E9%A9%97/><div class=article-details><h2 class=article-title>MongoDB Clustered Collection 與 Benchmark 實驗</h2></div></a></article><article><a href=/posts/2022/2022-04-25-mysqllock-%E8%88%87-index-%E9%97%9C%E4%BF%82%E5%92%8C-deadlock-%E5%88%86%E6%9E%90/><div class=article-details><h2 class=article-title>【MySQL】Lock 與 Index 關係和 Deadlock 分析</h2></div></a></article><article><a href=/posts/2022/2022-04-02-ddia03-%E8%B3%87%E6%96%99%E5%BA%AB%E5%84%B2%E5%AD%98%E5%8E%9F%E7%90%86%E7%A0%94%E7%A9%B6/><div class=article-details><h2 class=article-title>【DDIA】03 - 資料庫儲存原理研究</h2></div></a></article><article><a href=/posts/2022/2022-01-14-%E9%A0%98%E5%9F%9F%E9%A9%85%E5%8B%95%E8%A8%AD%E8%A8%88%E8%88%87%E7%B0%A1%E6%BD%94%E6%9E%B6%E6%A7%8B%E5%85%A5%E9%96%80%E5%AF%A6%E4%BD%9C%E7%8F%AD%E4%B8%8A%E8%AA%B2%E7%AD%86%E8%A8%98%E8%88%87%E5%BF%83%E5%BE%97%E9%97%9C%E6%96%BC%E6%95%8F%E6%8D%B7-ddd-%E8%88%87-event-storming-%E4%B8%8A/><div class=article-details><h2 class=article-title>「領域驅動設計與簡潔架構入門實作班」上課筆記與心得：關於敏捷、 DDD 與 Event Storming - 上</h2></div></a></article><article><a href=/posts/2021/2021-12-05-%E5%96%AE%E9%AB%94%E5%BC%8F%E7%B3%BB%E7%B5%B1%E5%88%B0%E5%BE%AE%E6%9C%8D%E5%8B%99%E8%AE%80%E5%BE%8C%E5%88%86%E4%BA%AB-%E4%B8%8B/><div class=article-details><h2 class=article-title>《單體式系統到微服務》讀後分享 - 下</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//yuanchieh.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2023 Yuanchieh</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.17.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>